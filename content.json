{"meta":{"title":"风向标 | 分享与创造","subtitle":null,"description":null,"author":"ai0by","url":"https://sbcoder.cn","root":"/"},"pages":[{"title":"api","date":"2019-04-03T02:17:31.000Z","updated":"2020-07-27T06:47:48.314Z","comments":true,"path":"api/index.html","permalink":"https://sbcoder.cn/api/index.html","excerpt":"","text":"风向标API合集 名称 作用 接口 微博图床api 远程图片上传到微博图床 https://sbcoder.cn/api/sinaImg.html 生成二维码 将地址转换为二维码图片 https://sbcoder.cn/api/qrcode.html 抖音直播流解析 解析直播流真实地址 https://sbcoder.cn/api/douyin.html 网易云音乐解析 解析网易云音乐真实地址 https://sbcoder.cn/api/neteasy.html 更多api请持续关注…"},{"title":"api","date":"2019-04-04T07:27:21.000Z","updated":"2020-08-08T06:24:20.338Z","comments":true,"path":"api/douyin.html","permalink":"https://sbcoder.cn/api/douyin.html","excerpt":"","text":"抖音直播api介绍打开APP直播界面，分享直播间链接，得到一串 https://v.douyin.com/JNUDPVo/ 类似地址提交 参数到 api 返回一个 json格式的直播流地址 参数说明以 GET/POST 的方式提交到：https://api.46wz.com/douyin.php 参数 数值类型 示例 是否必传 url String https://sbcoder.cn 是 返回值类型 : json 示例1&#123;\"hls_pull_url\":\"http://pull-hls-l1.douyincdn.com/stage/stream-683443806729404446/playlist.m3u8\",\"rtmp_pull_url\":\"http://pull-flv-l1.douyincdn.com/stage/stream-683443806729404446.flv\"&#125; 演示直接访问以下地址 1https://api.46wz.com/douyin.php?url=https://v.douyin.com/JNUDPVo/"},{"title":"api","date":"2019-04-04T07:27:21.000Z","updated":"2020-08-08T06:24:51.709Z","comments":true,"path":"api/qrcode.html","permalink":"https://sbcoder.cn/api/qrcode.html","excerpt":"","text":"二维码生成介绍使用场景很多，简单来讲，给我地址，我给你图，直接将地址放在img标签内即可~ 参数说明以GET的方式提交到：https://api.46wz.com/qrcode.php 参数 数值类型 示例 是否必传 url String https://sbcoder.cn 是 err String L (L,M,Q,H四种对应容错级别，不传默认L) 否 size String 7 (可以选择1~9999之间的值，对应不同大小，默认7) 否 logo String https://sbcoder.cn/img/avatar.jpg 否 返回值类型 : 直接返回图片 演示直接访问以下地址 12https://api.46wz.com/qrcode.php?url=https://sbcoder.cnhttps://api.46wz.com/qrcode.php?url=https://sbcoder.cn&amp;err=L&amp;size=7&amp;logo=https://sbcoder.cn/img/avatar.jpg 示例图片"},{"title":"categories","date":"2019-03-21T07:11:04.000Z","updated":"2019-03-21T07:11:32.000Z","comments":false,"path":"categories/index.html","permalink":"https://sbcoder.cn/categories/index.html","excerpt":"","text":""},{"title":"api","date":"2019-04-04T07:27:21.000Z","updated":"2020-08-08T06:25:08.127Z","comments":true,"path":"api/sinaImg.html","permalink":"https://sbcoder.cn/api/sinaImg.html","excerpt":"","text":"微博图床-远程图片上传api（已失效）介绍我们在使用爬虫相关内容的时候，存放图片时往往会遇到图片尺寸过大，存储不方便等问题，这时候，存放在一个永久存储的云上面就很有必要，微博是一个不限流量，全球CDN的图床~微博也是有缺点的，他并不是一个易于管理的图床，仅限于存放图片但不能管理图片，如果希望使用可以管理的图床，可以参考使用自建图床，参考我的:0161 IMG 参数说明以GET的方式提交到：https://api.46wz.com/sinaimg/sinaImg.php 传递参数类型：GET POST 参数 数值类型 示例 是否必传 url String https://sbcoder.cn/img/avatar.jpg 是 返回参数类型 ： JSON 演示示例:1&#123;\"large\":\"http://ww2.sinaimg.cn/bmiddle/0062WdSely1g1p8mlciyrg30390120jl.gif\"&#125; PHP DEMO12345678910111213141516171819$data = array( 'url' =&gt; \"https://sbcoder.cn/img/avatar.jpg\", );echo curlPost(\"https://api.46wz.com/sinaimg/sinaImg.php\",$data);function curlPost($url,$res)&#123; $curl = curl_init(); curl_setopt($curl, CURLOPT_URL, $url); curl_setopt($curl, CURLOPT_SSL_VERIFYPEER, 0); curl_setopt($curl, CURLOPT_FOLLOWLOCATION, 1); curl_setopt($curl, CURLOPT_AUTOREFERER, 1); curl_setopt($curl, CURLOPT_POST, 1); curl_setopt($curl, CURLOPT_POSTFIELDS, http_build_query($res)); curl_setopt($curl, CURLOPT_TIMEOUT, 30); curl_setopt($curl, CURLOPT_HEADER, 0); curl_setopt($curl, CURLOPT_RETURNTRANSFER, 1); $result = curl_exec($curl); curl_close($curl); return $result;&#125;"},{"title":"api","date":"2020-07-21T07:27:21.000Z","updated":"2020-08-08T06:24:32.954Z","comments":true,"path":"api/neteasy.html","permalink":"https://sbcoder.cn/api/neteasy.html","excerpt":"","text":"网易云音乐解析介绍使用URL或者音乐id解析出音乐真实地址，真实地址具有时效性，尽可能当时使用 参数说明以GET/POST的方式提交到：https://api.46wz.com/neteasy.php 参数 数值类型 示例 是否必传 url String https://music.163.com/song?id=1438116717&amp;userid=36276027 是 返回值类型 : json 演示直接访问以下地址 1https://api.46wz.com/neteasy.php?url=http://music.163.com/song?id=27506983&amp;userid=36276027 返回示例1&#123;\"src\":\"http://m10.music.126.net/20200727150722/407150eee50229ec961c8fcc076264dc/ymusic/4eaf/b0c1/5dfa/83c3b3868df7c381230b3df71beaff32.mp3\",\"code\":1,\"msg\":\"\\u6210\\u529f\"&#125; 教程参考 简单制作网易云音乐解析接口"},{"title":"tags","date":"2019-03-21T05:14:24.000Z","updated":"2019-03-21T05:14:52.000Z","comments":false,"path":"tags/index.html","permalink":"https://sbcoder.cn/tags/index.html","excerpt":"","text":""},{"title":"Links","date":"2019-04-22T12:14:24.000Z","updated":"2020-07-23T09:03:47.694Z","comments":true,"path":"custom/index.html","permalink":"https://sbcoder.cn/custom/index.html","excerpt":"","text":"我的朋友 - 排名不分先后 - songsong’s Blog - 猫爪导航🐱 - Huas Leung’s Blog 申请友情链接 直接在下面留言即可！ 要求： - 正规站点 - 博客类优先 - 技术类站点优先 本站链接格式 - 风向标博客 - https://sbcoder.cn"}],"posts":[{"title":"利用CPU的特性开发更高效的代码","slug":"利用CPU-Cache的特性开发更高效的代码","date":"2021-11-29T08:31:34.000Z","updated":"2021-11-29T09:27:57.024Z","comments":true,"path":"2021/11/29/CPU-Cache-Optimization.html","link":"","permalink":"https://sbcoder.cn/2021/11/29/CPU-Cache-Optimization.html","excerpt":"","text":"CPU Cache是什么CPU Cache是在内存的基础上，可以被CPU直接读取的缓存，分为 L1,L2,L3 三层缓存级别，他的读取速度，是内存的100倍以上，我们都知道基于内存的数据库Redis，仅仅是使用了内存存储就很快了，CPU Cache则更快，利用好CPU Cache则可以让你编写的程序更快。 相比较各类IO操作，CPU Cache则是最底层的，分级一般为 L1 Cache &gt; L2 Cache &gt; L3 Cache &gt; MEM &gt; SSD &gt; HDD，按照现在市场上面的定价，相对应的价格也是梯形下降 相对于CPU Cache昂贵的价格，带来的收益自然也要更高，可以通过如下命令查看所在机器的CPU Cache分别是多少，从而更有利于优化代码 1234567891011# 获取L1 数据缓存大小cat /sys/devices/system/cpu/cpu0/cache/index0/size# 获取L1 指令缓存大小cat /sys/devices/system/cpu/cpu0/cache/index1/size# 获取L2 Cache 大小cat /sys/devices/system/cpu/cpu0/cache/index2/size# 获取L3 Cache 大小cat /sys/devices/system/cpu/cpu0/cache/index3/size 一般来说 L3 的容量 &gt; L2 &gt; L1数据 = L1指令 oMLjgI.png 越靠近 CPU 核心的缓存其访问速度越快，CPU 访问 L1 Cache 只需要 2~4 个时钟周期，访问 L2 Cache 大约 10~20 个时钟周期，访问 L3 Cache 大约 20~60 个时钟周期，而访问内存速度大概在 200~300 个 时钟周期之间。 时钟周期是CPU主频的倒数，例如 2GHZ主频的CPU，一个时钟周期是 0.5ns CPU Cache LineCPU Cache Line 是每次CPU载入缓存的大小，CPU在读取缓存信息时并非是一次一字节读取而是每次读一个固定字节长度的数据 1cat /sys/devices/system/cpu/cpu0/cache/index0/coherency_line_size oMOIRs.png 由于他每次是读一块儿数据，那么我们在编写代码时则可以避免多次读取内存，可以将数据内容压缩到64位以内，避免重复读 当我们在使用数组时，例如一个 数据 A 长度 65，则会缓存前64位数组内容，例如从下标0读到63，则不会重复读取内容，那么如果读0 然后 读 64呢？ 答案是会重复读内存，他会自动缓存从0开始的一共长度64的数据，那么下标64已经超出这个长度则会重复读内存 那么如果读 0 然后读 2呢，还会重复读内存吗？ 答案也是肯定的，如果跳着读他会重复缓存，必须是一个连续的数值才可以利用上这个长度 1234567p : = [3][3]int&#123;&#123;1, 2, 3&#125;, &#123;4 ,5, 6&#125;, &#123;7, 8, 9&#125;&#125;for i := 0; i &lt; 3; i++ &#123; for j := 0; j &lt; 3; i++ &#123; fmt.Println(\"echo : \" ,p[i][j]) // fmt.Println(\"echo : \" ,p[j][i]) &#125;&#125; 上述Go代码中 fmt.Println(&quot;echo : &quot; ,p[i][j])是在内存中读取连续的数值，而 fmt.Println(&quot;echo : &quot; ,p[j][i]) 则并非是在读连续数据，他会不断地请求内存，从而会发现前者的效率更高一些 总结 ： 抛开一切因素，读取数据时按照存储顺序来读一定要比任意读效率要高，如果有条件控制数据长度那么可以结合CPU Cache Line 的长度来做一些优化 CPU分支预测CPU本身是有一个分支预测功能，它相当于一个CPU自带的优化器，当我们在代码中使用if判断的时候，CPU会自行预测他的结果并缓存，那么CPU预测的结果就一定是准确的么，当然不是~ 既然CPU的分支预测可以在不知道结果的情况下缓存他认为正确的数据，那么我们在编写代码时则可以适当地让CPU的分支预测更准确，那么也就避免了继续从内存读取数据，避免了多余的操作 代码实现该如何做呢，当一个if语句大多数时间都是 真 的情况下，那么CPU的分支预测将在后续预测中更容易缓存 真 的数据，也可以说，我们的代码尽量让数据保持在一个分支中，可以避免重复读取操作 除了这种CPU自动的分支预测，C语言也提供了一个方法可以告诉CPU大概的结果，从而使CPU更多的缓存某个分支的数据 123456789#define likely(x) __builtin_expect(!!(x),1)#define unlikely(x) __builtin_expect(!!(x),0)if (likely(a == 1))&#123; /* code */&#125;else&#123; /* code */&#125;","categories":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/categories/优化/"}],"tags":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/tags/优化/"}]},{"title":"frp+Nginx内网穿透远程桌面","slug":"frp-Nginx内网穿透远程桌面","date":"2020-07-27T08:41:31.000Z","updated":"2020-07-27T08:51:35.693Z","comments":true,"path":"2020/07/27/frp-nginx.html","link":"","permalink":"https://sbcoder.cn/2020/07/27/frp-nginx.html","excerpt":"","text":"说明基于 fatedier/frp 的内网穿透服务参考文档 frp中文文档参考文档 使用frp进行内网穿透 服务端直接下载 Releases · fatedier/frp找到对应版本下载即可，我这里服务端选用的是 frp_0.33.0_linux_386 国内机器速度慢可以使用我的个人镜像地址1wget https://api.0161.org/resources/frp_0.33.0_linux_386.tar.gz 修改配置文件 frps.ini 文件，建议增加Token验证 关于服务端配置可以参照官方给出的完全版配置文件及注释查看 frps_full.ini 文件 配置示例12345678[common]bind_port = 7000token = 123456dashboard_port = 7500dashboard_user = admindashboard_pwd = 123456vhost_http_port = 10088vhost_https_port = 10443 1nohup ./frps -c ./frps.ini &amp; 查看后台进程1jobs 删除进程示例12ps -ef | grep frps | grep -v grepkill &lt;进程id&gt; 根据上述配置好的端口 7500 使用 IP+端口 访问frp面板 输入面板用户名+密码该面板无实际性作用，仅用来做探针以及查看当前服务的状态，如未配置dashboard则无法使用dashboard 1.png 客户端下载 客户端 可以直接在github下载或者使用我的1wget https://api.0161.org/resources/frp_0.33.0_windows_amd64.zip 解压后修改 frpc.ini 12345678910111213[common]server_addr = &lt;你的服务器IP地址&gt;server_port = 7000token = 123456[rdp]type = tcplocal_ip = 127.0.0.1 local_port = 3389remote_port = 7001[web]type = httplocal_port = 80custom_domains = &lt;你的远程解析域名 例如: xxx.0161.org&gt; 上述使用Windows开启3389后可以访问远程桌面，Linux同理，只需要修改为 SSH 即可 2.png 值得注意的是 custom_domains 这个参数需要配合 vhost_http_port 这个参数使用，由于跟Nginx冲突所以上述端口我开启的是 10088可以使用域名解析的方式 架设游戏服务器 或者网络云盘 群晖 你懂得网站等 Nginx反向代理使用上述配置必须要使用 域名+端口 的形式才能访问，如果要用正式环境则不美观，且我们希望它与Nginx共存，因此，可以通过Nginx反向代理的形式去解析配置Nginx配置文件123456789101112server &#123; listen 80; server_name xxx.0161.org; location / &#123; proxy_pass http://127.0.0.1:10088; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header REMOTE-HOST $remote_addr; &#125;&#125; 流程图解 3.png 至此，可以直接访问 xxx.0161.org 无需携带端口号","categories":[{"name":"折腾","slug":"折腾","permalink":"https://sbcoder.cn/categories/折腾/"}],"tags":[{"name":"运维","slug":"运维","permalink":"https://sbcoder.cn/tags/运维/"},{"name":"内网穿透","slug":"内网穿透","permalink":"https://sbcoder.cn/tags/内网穿透/"},{"name":"frp","slug":"frp","permalink":"https://sbcoder.cn/tags/frp/"}]},{"title":"简单制作网易云音乐解析接口","slug":"简单制作网易云音乐解析接口","date":"2020-07-27T02:44:29.000Z","updated":"2020-07-27T06:33:58.069Z","comments":true,"path":"2020/07/27/neteasy-music.html","link":"","permalink":"https://sbcoder.cn/2020/07/27/neteasy-music.html","excerpt":"","text":"官方接口网易云是有一个官方的音乐解析接口的，只是隐藏的比较深（其实也还好），可以选择使用官方的解析接口也可以使用我的，可能官方的有时效性 Step1. 找到一张无版权歌曲点击生成外链播放器 aPDuNR.png Step2. 选择flash播放器开启F12 审查元素 选择flash播放器 aPDnE9.png Step3. 搜索接口直接在F12 搜索 song 找到如下接口 aPDZB4.png Step. 复制接口地址302直接跳转，我们可以直接获取到直链地址 aPDeHJ.png 找到官方接口1https://music.163.com/song/media/outer/url?id=&lt;歌曲ID&gt; 根据官方内容自制接口1234567891011121314151617181920212223242526272829303132&lt;?php$params = $_REQUEST;$returnData = [];$returnData['src'] = 'error 500';$returnData['code'] = 0;$returnData['msg'] = '无状态';if (!isset($params['url']) || empty($params['url'])) &#123; $returnData['msg'] = '5001 URL或者ID参数不存在'; echo json_encode($returnData,JSON_UNESCAPED_SLASHES); exit();&#125;$url = $params['url'];$pattern = '/(\\d&#123;5,20&#125;)/i';preg_match($pattern, $url, $matches);if (!$matches) &#123; $returnData['msg'] = '5002 URL或者ID格式有误'; echo json_encode($returnData,JSON_UNESCAPED_SLASHES); exit();&#125;$getParameterUrl = 'https://music.163.com/song/media/outer/url?id=' . $matches[0];var_dump($getParameterUrl);exit();$headers = get_headers($getParameterUrl, TRUE);//输出跳转到的网址if ($headers['Location']) &#123; $returnData['msg'] = '成功'; $returnData['src'] = $headers['Location']; $returnData['code'] = 1;&#125;echo json_encode($returnData,JSON_UNESCAPED_SLASHES);exit(); 二次封装之后可以使用注意：网易云的这个接口无法使用国外IP访问，如IP不符可能会返回404 可以使用我的API接口获取最新版解析","categories":[{"name":"折腾","slug":"折腾","permalink":"https://sbcoder.cn/categories/折腾/"}],"tags":[{"name":"音乐","slug":"音乐","permalink":"https://sbcoder.cn/tags/音乐/"}]},{"title":"使用Rancher快速部署k8s集群","slug":"使用Rancher快速部署k8s集群","date":"2020-07-24T03:32:57.000Z","updated":"2020-07-24T03:34:48.050Z","comments":true,"path":"2020/07/24/rancher-install.html","link":"","permalink":"https://sbcoder.cn/2020/07/24/rancher-install.html","excerpt":"","text":"安装Rancher注意：最低配置为 2H4G1M 本教程使用 2H8G5M Ubuntu18.04卸载旧版Docker1sudo apt-get remove docker docker-engine docker.io containerd runc 脚本安装Docker1curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun 更换阿里云源登录 https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors 找到 加速地址，或者使用我的12345678sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-&apos;EOF&apos;&#123; &quot;registry-mirrors&quot;: [&quot;https://p4sew3ge.mirror.aliyuncs.com&quot;]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart docker 安装Rancher1sudo docker run -d --restart=unless-stopped -v /home/rancher:/var/lib/rancher/ -p 80:80 -p 443:443 rancher/rancher:stable 打开 https://&lt;你的IP&gt;忽略掉证书提示，继续进入 1.png 添加集群Step1.设置语言 2.png Step2.选择右上角添加集群，选择自定义 3.png Step3.设置好集群名字后直接点击下一步 Step4.配置节点按照需要配置，我这里选择全部 4.png Step5.配置公网IP云主机需要配置 5.png Step6.复制命令执行 6.png 执行后会启动一个容器 7.png Step7.集群部署节点完成准备中… 8.png 完成部署 9.png 增加节点选择主机 - 编辑集群 11.png 拉到最下面，与上面添加节点方式一样，修改为子节点的ip，然后在子节点运行该命令等待添加完成 10.png","categories":[{"name":"架构","slug":"架构","permalink":"https://sbcoder.cn/categories/架构/"}],"tags":[{"name":"运维","slug":"运维","permalink":"https://sbcoder.cn/tags/运维/"},{"name":"Docker","slug":"Docker","permalink":"https://sbcoder.cn/tags/Docker/"}]},{"title":"Ubuntu18.04部署Kubernetes(k8s)集群可视化界面Dashboard","slug":"Ubuntu18-04部署Kubernetes-k8s-集群可视化界面Dashboard","date":"2020-07-23T01:12:57.000Z","updated":"2020-07-23T06:03:37.256Z","comments":true,"path":"2020/07/23/Kubernetes-Ubuntu.html","link":"","permalink":"https://sbcoder.cn/2020/07/23/Kubernetes-Ubuntu.html","excerpt":"","text":"k8s概念架构 Kubernetes是一个完备的分布式系统支撑平台。Kubernetes具有完备的集群管理能力，包括多层次的安全防护和准入机制/多租户应用支撑能力、透明的服务注册和服务发现机制、内建智能负载均衡器、强大的故障发现和自我修复功能、服务滚动升级和在线扩容能力、可扩展的资源自动调度机制，以及多粒度的资源配额管理能力。同时kubernetes提供了完善的管理工具，这些工具覆盖了包括开发、测试部署、运维监控在内的各个环节；因此kubernetes是一个全新的基于容器技术的分布式架构解决方案，并且是一个一站式的完备的分布式系统开发和支撑平台 Kubernetes简易.png Kubernetes Service Service的服务进程目前都基于Socker通信方式对外提供服务，比如redis、memcache、MySQL、Web Server，或者是实现了某个具体业务的一个特定的TCP Server进程。虽然一个Service通常由多个相关的服务进程来提供服务，每个服务进程都有一个独立的Endpoint(IP+Port)访问点，但Kubernetes 能够让我们通过Service虚拟Cluster IP+Service Port连接到指定的Service上。有了Kubernetes内建的透明负载均衡和故障恢复机制，不管后端有多少服务进程，也不管某个服务进程是否会由于发生故障而重新部署到其他机器，都不会影响到我们对服务的正常调用。更重要的是这个Service本身一旦创建就不再变化，这意味着Kubernetes集群中，我们再也不用为了服务的IP地址变来变去的问题而头疼。 service可以通过访问点去访问不同的子节点下面的Pod上，类似一个Proxy的概念，个人理解为他本身类似集群，通过service分发与swarm集群中的service类似，可以保持容器启动数量，由于权限相关问题，用户手动命令要大于service控制的权限级别，因此如果在使用service控制Pod时，有可能导致报错，不推荐使用 Kubernetes Service.png Kubernetes Pod Pod运行在一个我们称之为节点Node的环境中，可以是私有云也可以是公有云的虚拟机或者物理机，通常在一个节点上运行几百个Pod;其次，每个Pod里运行着一个特殊的被称之为Pause的容器，其他容器则为业务容器，这些业务容器共享Pause容器的网络栈和Volume挂载卷，因此他们之间的通讯和数据交换更为高效。在设计时我们可以充分利用这一特征将一组密切相关的服务进程放入同一个Pod中。并不是每个Pod和它里面运行的容器都能映射到一个Service 上，只有那些提供服务(无论是对内还是对外)的一组Pod才会被映射成一个服务。 Kubernetes Pod.png Pod &amp; Container 容器（Container）是一种高度隔离的封装程序 容器1.png 非所有的应用都适合选择容器，开发者可以根据自己应用的特点和需求选择最适合的计算单元。例如，你的应用是高性能、互信的，且处于同一个管理区域，那么用线程或者进程就可以满足；但如果你的应用是多租户的，并且和其他应用运行在同一个空间，那么你就需要考虑如何将这些应用安全地隔离开，使得数据不会被泄露或性能受到影响。那么这时，容器也许就是一个不错的选择了。容器便于管理，因为现在市场上有着完全完善的生态以及Docker的支持度愈发增加，越来越多的公司（个人）选择Docker，我个人也更倾向于Docker，有了Docker就可以非常完美的管理Images以及Container 容器2.png 容器是只占用很少的空间的，真正占用空间大的是Images，也可以说 Container 依赖 Images Pod，一种增强型容器Pod是一种组合的多容器运行单元，也是Kubernetes里的一个基础单元。你可以把它看作是一种容器的扩展或者增强型的容器。Pod里面包括一个主容器和数个辅助容器，它们共同完成一个特定的功能。把多个进程（容器也是一种隔离的进程）打包在一个Name Space里的时候，就构成了一个Pod。Pod里面不同进程的应用包装仍然是独立的（每个容器都会有自己的镜像）。Pod的意义在于，它可以既保持主容器和辅助容器的的密切关系，又保持主容器的独立性。由于主容器和辅助容器的生命周期相同，可以同时被创建和销毁，因此把它们放在一个Pod中，可以使他们的交互更加高效。 参考文档Aholiab - 云原生的基石，一文读懂容器、Docker、Pod到底是什么！ abcdocker编写k8s中文文档Ubuntu18.04使用kubeadm部署v1.18 HA集群 部署k8s机器选择这里我只做学习用途，因此开通的是阿里的按量计费机器以及低配置机器 master01 2H8G 阿里云 Ubuntu18.04 node01 2H8G 阿里云 Ubuntu18.04 部署环境Ubuntu修改仓库镜像12345678910111213141516sudo cat &gt; /etc/apt/sources.list &lt;&lt; EOFdeb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverseEOF 关闭防火墙1sudo ufw disable 时间同步12345678sudo apt-get install chrony -y &amp;&amp; sudo systemctl start chrony &amp;&amp; sudo systemctl enable chrony#查看chrony连接的公网服务器cat /etc/chrony/chrony.conf pool ntp.ubuntu.com iburst maxsources 4pool 0.ubuntu.pool.ntp.org iburst maxsources 1pool 1.ubuntu.pool.ntp.org iburst maxsources 1pool 2.ubuntu.pool.ntp.org iburst maxsources 2 禁用swap1sudo swapoff -a 上述命令可以临时禁用掉swap，如果想要永久禁止，需要编辑 /etc/fstab 文件,将swap那一行注释掉，如果没有则不管 禁用SELinux如果安装了则需要禁止掉，如果没有安装则可以跳过此步骤123sudo setenforce 0 #临时关闭sudo vi /etc/selinux/config #永久关闭SELINUX=permissive 修改内核123456sudo cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt; EOFnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1net.ipv4.ip_forward = 1 #开启ipv4转发，允许内置路由EOFsudo sysctl --system 修改时区12sudo ln -snf /usr/share/zoneinfo/Asia/Shanghai /etc/localtimesudo bash -c &quot;echo &apos;Asia/Shanghai&apos; &gt; /etc/timezone&quot; 安装DockerStep 1: 安装必要的一些系统工具12sudo apt-get updatesudo apt-get -y install apt-transport-https ca-certificates curl software-properties-common Step 2: 安装GPG证书1sudo curl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - Step 3: 写入软件源信息1sudo add-apt-repository &quot;deb [arch=amd64] https://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable&quot; Step 4: 查找Docker-CE的版本1sudo apt-cache madison docker-ce Step 5: 安装指定版本的Docker-CE,docker-ce=VERSION1sudo apt-get -y install docker-ce Setp 6: 安装完成后Docker默认就已经启动和加入开机自启了，这点我们不需要再做了，不过可以检查一下12sudo systemctl status dockersudo systemctl is-enabled docker Setp 7: 配置Docker镜像加速以及指定cgroup驱动为systemd123456789sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-&apos;EOF&apos;&#123; &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;], &quot;registry-mirrors&quot;: [&quot;https://81z69sad.mirror.aliyuncs.com&quot;]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart docker Setp 8: 配置完成后使用 docker info 可以看到修改的配置信息 配置主机名1234cat &gt;&gt; /etc/hosts &lt;&lt; EOF172.26.147.37 master01172.26.147.36 node01EOF 安装Kubeadm Kubelet KubectlStep 1: 安装必要的程序包1apt-get update &amp;&amp; apt-get install -y apt-transport-https Step 2: 导入Kubernetes官方包签名密钥1sudo curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - Step 3: 添加Kubernetes仓库123cat &gt; /etc/apt/sources.list.d/kubernetes.list &lt;&lt; EOFdeb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial mainEOF Step 4: 更新仓库1apt-get update Step 5: 查找kubeadm kubelet kubectl版本123apt-cache madison kubeadm | grep 1.18apt-cache madison kubelet | grep 1.18apt-cache madison kubectl | grep 1.18 目前1.18发布了1.18.0-00 1.18.1-00 1.18.2-00 三个版本 Step 6: 指定版本安装kubelet kubeadm kubectl(如果安装最新版本则无需带版本号)1apt-get install kubeadm kubelet kubectl -y Master节点部署根据需要修改的参数更换以下内容123456789kubeadm init \\--image-repository registry.aliyuncs.com/google_containers \\--kubernetes-version v1.18.0 \\--control-plane-endpoint master01 \\--pod-network-cidr=10.244.0.0/16 \\--service-cidr=10.96.0.0/12 \\--apiserver-advertise-address=0.0.0.0 \\--ignore-preflight-errors=Swap \\--token-ttl 30m 参数说明 image-repository：初始化过程中会去docker仓库拉去镜像，默认指定的为docker hub(国内访问网速不堪)，所以在此使用–image-repository参数指定阿里云镜像。 kubernetes-version：指定正在使用的 Kubernetes 程序组件的版本号，需要与 kubelet kubeadm kubectl 的版本号一致。 control-plane-endpoint: 指定控制平面的固定访问端点，可以是IP地址或DNS名称，会被用于集群管理员及集群组件的kubeconfig配置文件API Server的访问地址；单控制平面部署时可以不使用该选项(如果是单个Master部署则不需要使用该选项，因为等会我们要再加入其它两个Master节点到控制平面，所以这里加上此参数)。 pod-network-cidr：Pod 网络的地址范围，其值为 CIDR 格式的网络地址，使用 flannel 网络插件时，其默认地址为 10.244.0.0/16。 service-cidr：Service 的网络地址范围，其值为 CIDR 格式的网络地址，默认地址为 10.96.0.0/12。 apiserver-advertise-address：API Server 通告给其它组件的IP地址，一般为 Master 节点的IP地址，0.0.0.0 标识节点上所有可用的地址。ignore-preflight-errors：忽略哪些运行时的错误信息，其值为 Swap 时，表示忽略因 swap 未关闭而导致的错误。 token-ttl：token令牌自动删除时间，默认为24小时，指定为 0 表示永不过期，指定单位可以使 秒s 分m 时h，在node加入Kubernetes集群时需要指定token。初始化过程 01.png 02.png 03.png 初始化完成12345678910111213141516171819202122232425#您的Kubernetes控制平面初始化成功!Your Kubernetes control-plane has initialized successfully!#要开始使用您的集群，您需要作为一个普通用户运行以下程序:To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config#你需要部署一个网络插件到集群中才能够使Kubernetes网络运转起来You should now deploy a pod network to the cluster.Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/#如果要添加其它控制平面到集群中使用以下命令You can now join any number of control-plane nodes by copying certificate authoritiesand service account keys on each node and then running the following as root: kubeadm join k8s-devops.io:6443 --token 8r7sjk.9a31rmcjot9650fe \\ --discovery-token-ca-cert-hash sha256: \\ --control-plane#如果要添加数据平面节点到集群中使用以下命令Then you can join any number of worker nodes by running the following on each as root:kubeadm join k8s-devops.io:6443 --token 8r7sjk.9a31rmcjot9650fe \\ --discovery-token-ca-cert-hash sha256: 创建用户12345root@master01:~# useradd -m -s /bin/bash k8s # 创建用户root@master01:~# passwd k8s # 设置密码Enter new UNIX password:Retype new UNIX password:passwd: password updated successfully 为普通用户提权1root@master01:~# echo &apos;k8s ALL=(ALL:ALL) NOPASSWD:ALL&apos; &gt;&gt; /etc/sudoers.d/k8s 创建权限123456root@master01:~# su k8s # 切换用户k8s@master01:/root$ k8s@master01:/root$ cd / # 切换目录k8s@master01:/$ mkdir -p $HOME/.kube #在当前用户家目录下创建.kube目录k8s@master01:/$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config #复制config命令配置文件到当前用户.kube目录下k8s@master01:/$ sudo chown $(id -u):$(id -g) $HOME/.kube/config #修改config文件权限 部署网络插件Step 1: 可以直接在线部署(如果网络下载不了的情况下,也可以先试用浏览器下载后上传到服务器上)1k8s@master01:/$ kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml Step 2: 如果上述方法还是不行，则可以尝试使用我的1kubectl apply -f https://api.0161.org/resources/kube-flannel.yml Step 3: 上传完后修改文件的属性信息(如上述1,2步骤已完成则直接跳过)1k8s@master01:/$ sudo chown -Rf k8s.k8s kube-flannel.yml Step 4: 然后指定文件部署网络插件(如上述1,2步骤已完成则直接跳过)1234567891011k8s@master01:/$ kubectl apply -f kube-flannel.ymlpodsecuritypolicy.policy/psp.flannel.unprivileged createdclusterrole.rbac.authorization.k8s.io/flannel createdclusterrolebinding.rbac.authorization.k8s.io/flannel createdserviceaccount/flannel createdconfigmap/kube-flannel-cfg createddaemonset.apps/kube-flannel-ds-amd64 createddaemonset.apps/kube-flannel-ds-arm64 createddaemonset.apps/kube-flannel-ds-arm createddaemonset.apps/kube-flannel-ds-ppc64le createddaemonset.apps/kube-flannel-ds-s390x created Step 5: 查看网络插件是否部署完成(下面有一个叫kube-flannel-ds-amd64的Pod)如果发现你的 flannel Pod 处于 ImagePullBackOff 状态，那么就是 flannel 镜像未拉取成功，而正常的则为 Running状态12k8s@master01:/$ kubectl get pods -n kube-system | grep flannelkube-flannel-ds-amd64-hx9cr 1/1 Running 0 2m3s Step 6: 查看目前k8s节点信息123k8s@master01:/$ kubectl get nodesNAME STATUS ROLES AGE VERSIONmaster01 Ready master 65m v1.18.6 子节点加入到集群master节点查看join参数1kubeadm token create --print-join-command 子节点运行1kubeadm join master01:6443 --token 8z8ot9.ylyj39j1po0hgyun --discovery-token-ca-cert-hash sha256:e0bb3c41**********************************813c84472f65c 04.png 安装Dashboard官方文档方式启动(不建议)与端口+ip只能选择一种使用！！！1kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.3/aio/deploy/recommended.yaml 如遇到无法访问或者网络连接问题可以使用我的备份文件1kubectl apply -f https://api.0161.org/resources/recommended.yaml 代理方式启动1kubectl proxy 05.png 端口+IP启动(推荐)环境部署下载文件1wget https://k8s-1252147235.cos.ap-chengdu.myqcloud.com/dashboard/dashboard.yaml 拉取镜像1sudo docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kubernetes-dashboard-amd64:v1.10.1 创建服务1sudo kubectl apply -f dashboard.yaml 浏览器输入 https://IP:30001 打开 （可以使用Safari或者火狐，Chrome无法访问） 06.png 绑定用户12sudo kubectl create serviceaccount dashboard-admin -n kube-systemkubectl create clusterrolebinding dashboard-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard 获取Token1kubectl describe secrets -n kube-system $(kubectl -n kube-system get secret | awk &apos;/dashboard-admin/&#123;print $1&#125;&apos;) 按Token启动 07.png 赋予用户权限单命名空间权限文件及绑定创建 role.yaml123456789101112kind: RoleapiVersion: rbac.authorization.k8s.io/v1metadata: namespace: kube-system name: role-dashboard-adminrules:- apiGroups: [&quot;&quot;] resources: [&quot;pods&quot;,&quot;services&quot;] verbs: [&quot;get&quot;, &quot;watch&quot;, &quot;list&quot;]- apiGroups: [&quot;extensions&quot;, &quot;apps&quot;] resources: [&quot;deployments&quot;] verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;update&quot;, &quot;patch&quot;, &quot;delete&quot;] 创建 role-bind.yaml12345678910111213kind: RoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: role-bind-dashboard-admin namespace: kube-systemsubjects:- kind: ServiceAccount name: dashboard-admin namespace: kube-systemroleRef: kind: Role name: role-dashboard-admin apiGroup: rbac.authorization.k8s.io 集群权限配置及绑定创建 cluster-role.yaml12345678kind: ClusterRoleapiVersion: rbac.authorization.k8s.io/v1metadata: name: cluster-role-dashboard-adminrules:- apiGroups: [&quot;&quot;] resources: [&quot;pods&quot;] verbs: [&quot;get&quot;, &quot;watch&quot;, &quot;list&quot;] 创建 cluster-role-bind.yaml123456789101112kind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: cluster-role-bind-dashboard-adminsubjects:- kind: ServiceAccount name: dashboard-admin apiGroup: rbac.authorization.k8s.ioroleRef: kind: ClusterRole name: cluster-role-dashboard-admin apiGroup: rbac.authorization.k8s.io 执行命令1234kubectl create -f role.yamlkubectl create -f role-bind.yamlkubectl create -f cluster-role.yamlkubectl create -f cluster-role-bind.yaml 完成权限配置，可根据自身情况增加配置！ 常用k8s命令 查看pod列表 12kubectl get pods --all-namespaces # 查看所有sudo kubectl get pod -n kube-system # 查看指定命名空间 查看service列表 1kubectl get service --all-namespaces # 查看所有 删除指定命名空间下的service 1kubectl delete service serviceName --namespace=namespaceName 删除指定命名空间下的pod 1kubectl delete pod podName --namespace=namespaceName 查看所有deployment 1kubectl get deployment -A 删除指定deployment 1kubectl delete deployment podName 查看指定命名空间端口 1sudo kubectl get pod,svc -n kube-system","categories":[{"name":"架构","slug":"架构","permalink":"https://sbcoder.cn/categories/架构/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://sbcoder.cn/tags/Docker/"},{"name":"架构","slug":"架构","permalink":"https://sbcoder.cn/tags/架构/"}]},{"title":"Redis持久化及数据备份","slug":"Redis持久化及数据备份","date":"2020-06-10T08:14:42.000Z","updated":"2020-07-23T07:15:15.894Z","comments":true,"path":"2020/06/10/Redis-Backup.html","link":"","permalink":"https://sbcoder.cn/2020/06/10/Redis-Backup.html","excerpt":"","text":"Redis持久化Redis作为内存数据库，数据的安全性一定要得到确切的保障，很多情况下，Redis是作为存储数据库来用的，如果遇到断电，关机等突发情况，则容易丢失关键数据，对此，Redis的持久化就显得尤为关键，甚至某些情况下，需要定时去做备份 RDB可以在每隔一段时间执行一次备份操作，性能比AOF方式更好，RDB是紧凑型文件，但是最多可以执行到5分钟左右，如果再低可能会影响性能RDB相当于 备份数据 恢复数据快 性能更好 可以分时间节点备份文件 容易丢失数据 AOF可以按秒级存储数据，由于长期存储，如果发生崩溃事件，它可能只会丢失几秒的数据，相比较来说，可能更安全AOF相当于 备份执行语句 数据安全性更高 存储时不占用资源 可自定 fsync 策略 恢复速度慢 Docker安装12docker pull redis:latestdocker run -itd --name redis01 -p 6379:6379 redis 1.png 未完！！！","categories":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/categories/优化/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://sbcoder.cn/tags/数据库/"},{"name":"Redis","slug":"Redis","permalink":"https://sbcoder.cn/tags/Redis/"}]},{"title":"MySQL主从同步 读写分离 集群部署","slug":"MySQL-主从同步-读写分离","date":"2020-06-10T06:25:42.000Z","updated":"2020-06-10T06:28:17.018Z","comments":true,"path":"2020/06/10/MySQL-Cluster-MySQLProxy.html","link":"","permalink":"https://sbcoder.cn/2020/06/10/MySQL-Cluster-MySQLProxy.html","excerpt":"","text":"简介可以使用之前写的Canal阿里巴巴增量订阅更新做简单的主从备份，由于Canal只读取 binary log 日志做增量更新 canal工作流程图.png 通过canal可以做简单的按更新备份也可以通过canal做数据更新，根据更新的内容去更新数据库中其他的字段值也可以通过canal客户端发送消息给 ElasticSearch 等服务，适合多样化复杂的MySQL主从操作通过伪造slave的方式请求binary log消息 阿里巴巴也为我们提供了更好的基于Canal的分布式数据库同步系统 otter otter工作原理.jpg 本文所用Docker目的是一台机器搞定集群功能，实际生产环境中不建议使用Docker 参考项目：alibaba/otter - 阿里巴巴分布式数据库同步系统(解决中美异地机房)alibaba/canal - 阿里巴巴 MySQL binlog 增量订阅&amp;消费组件 通过MySQL配置主从备份主从备份，通过配置MySQL做主从备份 主从备份流程图.jpg 注意事项 主从数据库版本保持一致 需要单独的两台服务器（单台机器可使用Docker，没有测试过） 需要网络相连，保证主从服务器通信 表结构不使用外键，使用外键容易造成同步失败 主键使用无意义自增字段 同步数据库所用的账号拥有一定的权限，也可以使用root 安装MySQL参照之前的文章 MySQL Docker启动启动两个不同的 MySQL 映射不同的端口123docker run --restart=always --name mysql5.7-1 -p 3307:3306 -v /Users/XXX/Downloads/Docker/mysql5.7-1:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7 --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_cidocker run --restart=always --name mysql5.7 -p 3306:3306 -v /Users/XXX/Downloads/Docker/mysql5.7:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7 --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci 进入容器内部 安装vim 或者映射 使用参数 -v 映射位置 /etc/mysql/my.cnf 配置文件亦可 安装 vim 方式 编辑 my.cnf12apt-get installapt-get install vim 挂载 本地文件 内容123456789101112131415161718192021222324# Copyright (c) 2016, Oracle and/or its affiliates. All rights reserved.## This program is free software; you can redistribute it and/or modify# it under the terms of the GNU General Public License, version 2.0,# as published by the Free Software Foundation.## This program is also distributed with certain software (including# but not limited to OpenSSL) that is licensed under separate terms,# as designated in a particular file or component or in included license# documentation. The authors of MySQL hereby grant you an additional# permission to link the program and your derivative works with the# separately licensed software that they have included with MySQL.## This program is distributed in the hope that it will be useful,# but WITHOUT ANY WARRANTY; without even the implied warranty of# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the# GNU General Public License, version 2.0, for more details.## You should have received a copy of the GNU General Public License# along with this program; if not, write to the Free Software# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA!includedir /etc/mysql/conf.d/!includedir /etc/mysql/mysql.conf.d/ 配置主从备份主节点 使用root 用户 配置 修改配置文件 /etc/mysql/my.cnf123[mysqld]log-bin=mysql-binserver-id=1 执行命令 input123GRANT REPLICATION SLAVE ON *.* to &apos;root&apos;@&apos;%&apos; identified by &apos;123456&apos;;FLUSH PRIVILEGES;SHOW MASTER STATUS; output12345+------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+------------------+-------------------+| mysql-bin.000001 | 589 | | | |+------------------+----------+--------------+------------------+-------------------+ 从节点 使用root 用户 配置修改配置文件 /etc/mysql/my.cnf123[mysqld]log-bin=mysql-binserver-id=2 执行命令 input123change master to master_host=&apos;172.17.0.2&apos;,master_user=&apos;root&apos;,master_password=&apos;123456&apos;,master_log_file=&apos;mysql-bin.000001&apos;,master_log_pos=589;start slave;show slave status\\G; output1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 172.17.0.2 Master_User: root Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000001 Read_Master_Log_Pos: 589 Relay_Log_File: f919535d2d58-relay-bin.000002 Relay_Log_Pos: 320 Relay_Master_Log_File: mysql-bin.000001 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 589 Relay_Log_Space: 534 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 1 Master_UUID: 380e925e-a645-11ea-a304-0242ac110004 Master_Info_File: /var/lib/mysql/master.info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: Executed_Gtid_Set: Auto_Position: 0 Replicate_Rewrite_DB: Channel_Name: Master_TLS_Version:1 row in set (0.00 sec) 测试 创建一个 test数据库 主从数据库同步.png 监控状态可以使用crontab 配合钉钉通知 使用 curl命令通知 主从同步是否成功 12345678# !/bin/basharray=($(mysql -uroot -p -e \"show slave status\\G\" | grep \"Running\" | awk '&#123;print $2&#125;'))if [ \"$&#123;array[0]&#125;\" == \"Yes\" ] || [ \"$&#123;array[1]&#125;\" == \"Yes\" ] then echo \"Slave is OK\" else echo \"Slave is error\"fi 读写分离master数据库处理写操作，slave数据库处理读操作。利用上面配置的主从数据库，使master数据库的变更实时更新到slave节点上，支持事务，但可能会因为某些原因有阻塞现象发生，不可避免的可能会出现数据同步慢的情况 读写分离.png 使用 MySQLProxy 做读写分离 MySQLProxy实际上是在客户端请求与MySQLServer之间建立了一个连接池。所有客户端请求都是发向MySQLProxy，然后经由MySQLProxy进行相应的分析，判断出是读操作还是写操作，分发至对应的MySQLServer上。对于多节点Slave集群，也可以起做到负载均衡的效果。 MySQLProxy.png 为何要使用MySQLProxy？其实可以不使用，但为了减少代码量，减少开发成本，可以通过运维的手段去做分发处理。常见的开发框架实际上很多是支持读写分离操作不同数据库的，而代理服务器做的则是将这些框架封装好的东西通过代理分发的方式，分别给不同的数据库发送请求，主库只修改，从库只读 缺点 目前MySQLProxy仍然是 alpha（内测） 版 通过lua脚本做的读写分离，MySQL官方并不建议使用 配置MySQLProxy读写分离假定 上述两台服务器 分别为 master slave 那么我们现在需要第三台服务器 proxyproxy需要做中转代理，将接收到的数据库请求分别指向 master 和 slave 下载 MySQLProxy下载地址：MySQL Product Archives 由于我的环境为MAC新版，对 MySQLProxy 的支持度并不好，因此并不在本机使用可以参照下面引用的文章参考配置 参考文章 Mysql 主从备份完整版 MySQL主从备份配置 MySQL读写分离介绍及搭建 MySQL Proxy","categories":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/categories/优化/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://sbcoder.cn/tags/MySQL/"},{"name":"运维","slug":"运维","permalink":"https://sbcoder.cn/tags/运维/"}]},{"title":"ElasticSearch & ELK日志分析 从零开始搭建到使用","slug":"ElasticSearch-Kibana-从零开始搭建到使用","date":"2020-05-27T12:34:16.000Z","updated":"2020-06-04T08:31:49.232Z","comments":true,"path":"2020/05/27/ELK_Stack.html","link":"","permalink":"https://sbcoder.cn/2020/05/27/ELK_Stack.html","excerpt":"","text":"引言介绍基于Lucene的搜索服务器，它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。更适用于集群部署，适合各类 分词，全文搜索，通过建立索引（分片，按节点分片）来实现更快的搜索Elasticsearch是与Logstash的数据收集和日志解析引擎以及Kibana的分析和可视化平台一起开发的。这三个产品被设计成一个集成解决方案，称为“Elastic Stack”（以前称为“ELK stack”）。本文只做单节点运行 ELK.png 官方介绍 Elasticsearch 是一个分布式、RESTful 风格的搜索和数据分析引擎，能够解决不断涌现出的各种用例。 作为 Elastic Stack 的核心，它集中存储您的数据，帮助您发现意料之中以及意料之外的情况。 注意事项 单点服务器维持稳定可能需要常驻内存 4G 以上 单点ELK维持稳定可能需要CPU 4核心 以上 参考文章 Docker安装部署ELK教程 (Elasticsearch+Kibana+Logstash+Filebeat) 零门槛！基于Docker快速部署ES集群 下载集群所需镜像 zookeeper kafka12docker pull zookeeperdocker pull wurstmeister/kafka 单节点无内网IP使用1docker network create elkwork 创建内部网络后在每次 docker run 的时候 增加参数 --net elkwork elastic相关 旧版本 123docker pull docker.elastic.co/elasticsearch/elasticsearch:5.6.8docker pull docker.elastic.co/kibana/kibana:5.6.8docker pull docker.elastic.co/logstash/logstash:5.6.8 新版本 1234docker pull docker.elastic.co/elasticsearch/elasticsearch:7.7.0docker pull docker.elastic.co/kibana/kibana:7.7.0docker pull docker.elastic.co/logstash/logstash:7.7.0docker pull store/elastic/filebeat:7.7.0 启动elasticsearch 自行替换版本&quot;discovery.type=single-node&quot; 单节点1docker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot; docker.elastic.co/elasticsearch/elasticsearch:5.6.8 默认用户名 默认密码elastic changeme 测试是否已经连通-u elastic:changeme 验权1curl -u elastic:changeme localhost:9200 浏览器端口访问测试 elasticsearch.png elasticsearch 各类语法基本浏览器访问http://xxx.xx.xxx.xx:9200/_cat/indices?v 查看当前节点的所有 Indexhttp://xxx.xx.xxx.xx:9200/_mapping?pretty=true 列出每个 Index 所包含的 Type 验权机制增加参数 -u elastic:changeme 验权 命令行访问curl -u elastic:changeme -X PUT &#39;localhost:9200/weather&#39; 可以直接向 Elastic 服务器发出 PUT 请求curl -u elastic:changeme -X DELETE &#39;localhost:9200/weather&#39; 发出 DELETE 请求，删除这个 Index 插入数据123456curl -X POST &apos;localhost:9200/account/person&apos; -d &apos;&#123; &quot;user&quot;: &quot;李四&quot;, &quot;title&quot;: &quot;工程师&quot;, &quot;desc&quot;: &quot;系统管理&quot;&#125;&apos; 读取数据1curl &apos;localhost:9200/account/person/1?pretty=true&apos; 示例 123456789101112&#123; \"_index\" : \"accounts\", \"_type\" : \"person\", \"_id\" : \"1\", \"_version\" : 1, \"found\" : true, \"_source\" : &#123; \"user\" : \"张三\", \"title\" : \"工程师\", \"desc\" : \"数据库管理\" &#125;&#125; 删除记录1curl -X DELETE &apos;localhost:9200/accounts/person/1&apos; 更新记录123456curl -X PUT &apos;localhost:9200/accounts/person/1&apos; -d &apos;&#123; &quot;user&quot; : &quot;张三&quot;, &quot;title&quot; : &quot;工程师&quot;, &quot;desc&quot; : &quot;数据库管理，软件开发&quot;&#125;&apos; 返回所有记录1curl &apos;localhost:9200/accounts/person/_search&apos; 索引 ：/Index/Type/_search total：返回记录数，本例是2条。 max_score：最高的匹配程度，本例是1.0。 hits：返回的记录组成的数组。 查询记录123456curl &apos;localhost:9200/accounts/person/_search&apos; -d &apos;&#123; &quot;query&quot; : &#123; &quot;match&quot; : &#123; &quot;desc&quot; : &quot;软件 系统&quot; &#125;&#125;, &quot;from&quot;: 1 &quot;size&quot;: 1&#125;&apos; size 返回数量 from 开始位置 OR搜索，当前搜索的示例是 软件或系统 AND搜索示例12345678910&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123; &quot;match&quot;: &#123; &quot;desc&quot;: &quot;软件&quot; &#125; &#125;, &#123; &quot;match&quot;: &#123; &quot;desc&quot;: &quot;系统&quot; &#125; &#125; ] &#125; &#125;&#125; 参考文章 全文搜索引擎 Elasticsearch 入门教程 启动kibana 自行替换版本1docker run -d --name kibana -p 8001:5601 docker.elastic.co/kibana/kibana:5.6.8 kibana 容器内部修改配置ip1Vi ./config/kibana.yml 重启容器使配置生效 kibana.png 配置 logstash123mkdir /home/tjy/docker/logstash/mkdir /home/tjy/docker/logstash/conf.d/vi /home/tjy/docker/logstash/logstash.yml 12path.config: /usr/share/logstash/conf.d/*.confpath.logs: /var/log/logstash 1vi /home/tjy/docker/logstash/conf.d/test.conf 123456789101112131415input &#123; beats &#123; port =&gt; 5044 codec =&gt; &quot;json&quot;&#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; [&quot;xxx.xx.xxx.xx:9200&quot;] user =&gt; elastic password =&gt; changeme &#125; stdout &#123; codec =&gt; rubydebug &#125;&#125; 启动logstash并挂载1docker run -it -d -p 8011:5044 -p 9600:9600 --name logstash -v /home/tjy/docker/logstash/logstash.yml:/usr/share/logstash/config/logstash.yml -v /home/tjy/docker/logstash/conf.d/:/usr/share/logstash/conf.d/ docker.elastic.co/logstash/logstash:5.6.8 配置 filebeat下载 通用配置文件 1234mkdir /Users/XXX/Downloads/Docker/filebeat/cd /Users/XXX/Downloads/Docker/filebeatwget https://raw.githubusercontent.com/elastic/beats/7.1/deploy/docker/filebeat.docker.ymlvi filebeat.docker.yml 配置监听 Nginx log 123456789101112131415161718192021filebeat.config: modules: path: $&#123;path.config&#125;/modules.d/*.yml reload.enabled: falsefilebeat.autodiscover: providers: - type: docker hints.enabled: trueprocessors:- add_cloud_metadata: ~filebeat.inputs:- type: log enabled: true paths: - /var/log/nginx/*.logoutput.logstash: hosts: [&apos;logstash:5044&apos;] filebeat 配合 logstash 挂载并启动以下映射的路径为我自己电脑的路径，需要自行修改！1docker run --name filebeat --user=root -d --net elkwork -v /usr/local/var/log/nginx/:/var/log/nginx/ -v /Users/XXX/Downloads/Docker/filebeat/filebeat.docker.yml:/usr/share/filebeat/filebeat.yml -v /var/run/docker.sock:/var/run/docker.sock store/elastic/filebeat:7.7.0 success.png","categories":[{"name":"架构","slug":"架构","permalink":"https://sbcoder.cn/categories/架构/"}],"tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://sbcoder.cn/tags/ElasticSearch/"},{"name":"kibana","slug":"kibana","permalink":"https://sbcoder.cn/tags/kibana/"},{"name":"Logstash","slug":"Logstash","permalink":"https://sbcoder.cn/tags/Logstash/"}]},{"title":"Docker 安装 PHP-fpm","slug":"Docker-安装-PHP-fpm","date":"2020-05-17T04:54:47.000Z","updated":"2020-06-05T09:10:42.132Z","comments":true,"path":"2020/05/17/Docker_PHP_fpm.html","link":"","permalink":"https://sbcoder.cn/2020/05/17/Docker_PHP_fpm.html","excerpt":"","text":"创建 uploads.ini12345file_uploads = Onmemory_limit = 64 Mupload_max_filesize = 20Mpost_max_size = 20Mmax_execution_time = 600 创建 Dockerfile1234567891011121314151617FROM php:7.3-fpmRUN apt-get updateRUN apt-get install -y libwebp-dev libjpeg-dev libpng-dev libfreetype6-devEXPOSE 9000#上传配置成20MCOPY uploads.ini /usr/local/etc/php/conf.dRUN docker-php-ext-install mysqliRUN docker-php-ext-install pdoRUN docker-php-ext-install pdo_mysqlRUN pecl install redis-4.2.0 &amp;&amp; docker-php-ext-enable redisRUN docker-php-ext-install bcmathRUN docker-php-ext-configure gd --with-webp-dir=/usr/include/webp --with-png-dir=/usr/include --with-jpeg-dir=/usr/include --with-freetype-dir=/usr/include/freetype2RUN docker-php-ext-install gd Docker build1docker build -t ai0by/php-fpm73:v1 . 运行容器挂载物理机内容到 容器内部 可以修改下方的 /var/www/html/workspace 为你的项目地址 1docker run -v /var/www/html/workspace:/var/www/html/workspace -p 9002:9000 -d php73:0.1 Nginx配置修改 fastcgi_pass 后面的 值为 127.0.0.1:9002 LNMP用户 修改 /usr/local/nginx/conf/enable-php-pathinfo.conf 将 fastcgi_pass unix:/tmp/php-cgi.sock; 修改为 fastcgi_pass 127.0.0.1:9002; 其他环境与此类似，直接改即可 MySQL Docker启动自行修改 挂载路径 以及 密码1docker run --restart=always --name mysql5.7 -p 3306:3306 -v /Users/XXX/Downloads/Docker/mysql5.7:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7 --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci Nginx 个人不习惯扔Docker中，因此暂时不管","categories":[{"name":"PHP","slug":"PHP","permalink":"https://sbcoder.cn/categories/PHP/"}],"tags":[{"name":"fpm","slug":"fpm","permalink":"https://sbcoder.cn/tags/fpm/"},{"name":"nginx","slug":"nginx","permalink":"https://sbcoder.cn/tags/nginx/"}]},{"title":"Workerman 适合PHPer使用的Socket通讯框架","slug":"Workerman-适合PHPer使用的Socket通讯框架","date":"2020-05-14T13:48:33.000Z","updated":"2020-05-14T13:51:53.699Z","comments":true,"path":"2020/05/14/workerman.html","link":"","permalink":"https://sbcoder.cn/2020/05/14/workerman.html","excerpt":"","text":"简介适用于 客户端-服务端 客户端-客户端 一对多 多对多的关系，多个客户端之间的长连接通信，聊天室，在线客服，服务端反向推送播报消息 特性：多进程，长连接，高并发，常驻内存… 客户端与worker进程 客户端与worker进程.png 主进程与worker子进程 主进程与worker子进程.png 使用Workerman可以做很多有趣的事。（工业自动化，互联网工业，PLC机械报警…），通过长连接取数据，操作数据等，但PHP并不适用于工业领域。做一个仿im聊天工具，除了前端展示界面，后端也要考虑全面，更多的依赖于长连接。 本文参考 workerman官方文档本文参考 thinksocketio - 基于socketio的聊天室Demo 安装Workerman框架服务端创建一个文件夹 我这里使用 testWebSocket12mkdir testWebSocketcd testWebSocket git形式安装(推荐)1git clone https://github.com/walkor/Workerman 根据官方文档创建一个示例 在 testWebSocket 下创建一个 PHP文件 test.php12345678910111213141516171819&lt;?phpuse Workerman\\Worker;require_once __DIR__ . '/Workerman/Autoloader.php';// 注意：这里与上个例子不同，使用的是websocket协议$ws_worker = new Worker(\"websocket://0.0.0.0:2000\");// 启动4个进程对外提供服务$ws_worker-&gt;count = 4;// 当收到客户端发来的数据后返回hello $data给客户端$ws_worker-&gt;onMessage = function($connection, $data)&#123; // 向客户端发送hello $data $connection-&gt;send('hello ' . $data);&#125;;// 运行workerWorker::runAll() 前端测试前端测试例子代码 直接在Google浏览器执行123456789ws = new WebSocket(\"ws://127.0.0.1:2000\");ws.onopen = function() &#123; alert(\"连接成功\"); ws.send('tom'); alert(\"给服务端发送一个字符串：tom\");&#125;;ws.onmessage = function(e) &#123; alert(\"收到服务端的消息：\" + e.data);&#125;; 效果展示 执行界面.png 服务端界面.png Workermen框架支持的协议1234567891011$websocket_worker = new Worker('websocket://0.0.0.0:2345');// text协议$text_worker = new Worker('text://0.0.0.0:2346');// frame协议$frame_worker = new Worker('frame://0.0.0.0:2347');// tcp Worker，直接基于socket传输，不使用任何应用层协议$tcp_worker = new Worker('tcp://0.0.0.0:2348');// udp Worker，不使用任何应用层协议$udp_worker = new Worker('udp://0.0.0.0:2349');// unix domain Worker，不使用任何应用层协议$unix_worker = new Worker('unix:///tmp/wm.sock'); 整合ThinkPHP说明Workermen是一个成熟的单独框架，在ThinkPHP中也可以使用Composer安装对应的扩展来使用，这里使用了针对PHP开发的扩展 PHPSocket.IO。PHPSocket.IO设计的目标是利用PHP构建能够在不同浏览器和移动设备上良好运行的实时应用，如实时分析系统、在线聊天室、在线客服系统、评论系统、WebIM等。 PHPSocket.IO与workerman的区别是，PHPSocket.IO基于workerman开发，workerman有的特性PHPSocket.IO都支持。 PHPSocket.IO最大的优势是对各种浏览器的兼容性更好。 安装及引用使用Composer 安装对应的扩展1composer require workerman/phpsocket.io 在编辑代码时引用对应的扩展即可12use Workerman\\Worker;use PHPSocketIO\\SocketIO; 服务端创建一个服务端 application\\socketio\\controller\\server.php12345678910111213141516171819202122232425262728293031&lt;?phpnamespace app\\socketio\\controller;use Workerman\\Worker;use PHPSocketIO\\SocketIO;use think\\Db;class Server&#123; public function index()&#123; // 在2021端口创建服务 $io = new SocketIO(2021); $io-&gt;on('connection', function($socket)use($io)&#123; $socket-&gt;on('chat message', function($msg)use($io)&#123; $io-&gt;emit('chat message', $msg); &#125;); // 监听到新的客户端连接即在服务端输出'new connection' echo 'new connection'.\"\\n\"; // 并向服务端发送'连接成功' $socket-&gt;emit('success', '连接成功'); // 服务端发送消息过来 $socket-&gt;on('sendMsg', function($msg)use($io)&#123; // 在服务端输出消息 echo $msg.\"\\n\"; // 在收到的消息前面拼接'收到'后向客户端发送回去 $io-&gt;emit('sendMsg', '收到\"'.$msg.'\"'); &#125;); &#125;); // 启动服务 Worker::runAll(); &#125;&#125; 由于 Workermen 是一个独立于PHP程序使用的单一文件，需要单独用一个命令行来启动的，他完全可以独立使用，因此并不推荐使用TP框架来整合，但如果有这个需求，也可以在 /public目录下生成一个文件来绑定控制器，例如绑定 到 socketio/Server创建文件 public/server.php , 输入以下内容123456789&lt;?php// [ 应用入口文件 ]namespace think;// 加载基础文件require __DIR__ . '/../thinkphp/base.php';// 执行应用并响应（绑定）Container::get('app')-&gt;bind('socketio/Server')-&gt;run()-&gt;send(); 执行时 直接在Shell中运行该PHP文件即可，剩下的交给TP的机制12cd /publicphp server.php 执行结果.png 结语根据通信行为可以衍生出各类应用，目前websocket已经是各大公司都需要的技术，会websocket就多了一份机会！","categories":[{"name":"PHP","slug":"PHP","permalink":"https://sbcoder.cn/categories/PHP/"}],"tags":[{"name":"socket","slug":"socket","permalink":"https://sbcoder.cn/tags/socket/"},{"name":"通讯","slug":"通讯","permalink":"https://sbcoder.cn/tags/通讯/"},{"name":"workerman","slug":"workerman","permalink":"https://sbcoder.cn/tags/workerman/"}]},{"title":"UnblockNeteaseMusic 解锁网易云音乐灰色歌曲","slug":"UnblockNeteaseMusic-解锁网易云音乐灰色歌曲","date":"2020-05-09T13:52:19.000Z","updated":"2020-05-09T13:53:34.444Z","comments":true,"path":"2020/05/09/UnblockNeteaseMusic.html","link":"","permalink":"https://sbcoder.cn/2020/05/09/UnblockNeteaseMusic.html","excerpt":"","text":"Docker 安装运行服务端基于nondanee/UnblockNeteaseMusic的音乐解锁代理服务 1docker run --name=unblockneteasemusic -d -p 8888:8080 nondanee/unblockneteasemusic 日志界面 配置客户端 平台 基础设置 Windows 设置 &gt; 工具 &gt; 自定义代理 (客户端内) UWP Windows 设置 &gt; 网络和 Internet &gt; 代理 Linux 系统设置 &gt; 网络 &gt; 网络代理 macOS 系统偏好设置 &gt; 网络 &gt; 高级 &gt; 代理 Android WLAN &gt; 修改网络 &gt; 高级选项 &gt; 代理 iOS 无线局域网 &gt; HTTP 代理 &gt; 配置代理 Windows配置截图 将ip设置为服务器ip即可，映射内部的8080到外部8888端口 效果 当播放或者下载时，日志会记录，解析过程","categories":[{"name":"折腾","slug":"折腾","permalink":"https://sbcoder.cn/categories/折腾/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://sbcoder.cn/tags/Docker/"},{"name":"音乐","slug":"音乐","permalink":"https://sbcoder.cn/tags/音乐/"}]},{"title":"Aria2 + Rclone + Goindex 实现离线下载在线观看","slug":"Aria2-Rclone-Goindex-实现离线下载在线观看","date":"2020-01-21T23:32:33.000Z","updated":"2020-01-23T00:48:01.000Z","comments":true,"path":"2020/01/22/aria_goindex.html","link":"","permalink":"https://sbcoder.cn/2020/01/22/aria_goindex.html","excerpt":"","text":"准备工作 云阀 5R NAT小鸡 Google Drive 账号一枚 CloudFlare 账号 关于云阀的小鸡，性价比高，只提供ipv6和ipv4端口，因此下面的教程可能某些地方做了多余的动作，例如修改端口号等 安装Aria2一键脚本执行下面的命令1wget -N git.io/aria2.sh &amp;&amp; chmod +x aria2.sh &amp;&amp; ./aria2.sh 进入下载脚本的目录运行脚本123456789101112131415161718192021222324252627./aria2.shAria2 一键安装管理脚本 [vX.X.X]-- P3TERX.COM --1. 升级脚本————————————1. 安装 Aria22. 更新 Aria23. 卸载 Aria2————————————4. 启动 Aria25. 停止 Aria26. 重启 Aria2————————————7. 修改 配置8. 查看 配置9. 查看 日志10. 清空 日志————————————11. 手动更新 BT-Tracker12. 自动更新 BT-Tracker————————————当前状态: 已安装 并 已启动请输入数字 [0-12]: 输入 1 回车 1.png 等待安装完成 再执行1./aria2.sh 输入 7 回车 2.png 如需要可修改 RPC 密码，也建议修改 安装 LNMP 一键安装包 / Nginx我这里安装LNMP，其实只需要 Nginx就行了安装教程参考 安装 - LNMP一键安装包 或者 直接执行1wget http://soft.vpser.net/lnmp/lnmp1.6.tar.gz -cO lnmp1.6.tar.gz &amp;&amp; tar zxf lnmp1.6.tar.gz &amp;&amp; cd lnmp1.6 &amp;&amp; ./install.sh lnmp 我这里安装的是 1.6 ，可自行修改版本号 安装 Aria2NG 界面管理打开地址 Releases · mayswind/AriaNg选择最新版本下载到 网站 目录下，如果不知道网站目录配置，建议存放在 LNMP的默认目录 /home/wwwroot/ 按照如下操作12345mkdir /home/wwwroot/Xcd /home/wwwroot/Xwget https://github.com/mayswind/AriaNg/releases/download/1.1.4/AriaNg-1.1.4.zipunzip AriaNg-1.1.4.ziprm AriaNg-1.1.4.zip 配置 Nginx12cd /usr/local/nginx/conf/vhost/vi X.conf 输入以下配置123456789101112131415161718192021222324252627282930313233343536373839404142server &#123; listen 10002 default_server reuseport; #listen [::]:80 default_server ipv6only=on; server_name _; index index.html index.htm index.php; root /home/wwwroot/x; #error_page 404 /404.html; # Deny access to PHP files in specific directory #location ~ /(wp-content|uploads|wp-includes|images)/.*\\.php$ &#123; deny all; &#125; include enable-php.conf; location /nginx_status &#123; stub_status on; access_log off; &#125; location ~ .*\\.(gif|jpg|jpeg|png|bmp|swf)$ &#123; expires 30d; &#125; location ~ .*\\.(js|css)?$ &#123; expires 12h; &#125; location ~ /.well-known &#123; allow all; &#125; location ~ /\\. &#123; deny all; &#125; access_log /home/wwwlogs/access.log; &#125; 主要就是把端口改为 10002，其他的就是lnmp默认配置不动 配置完毕后，打开 网址 http://virt-nat-eu-1.cloudraft.cn:1XXX5将XX替换成你的 内网IP最后一位 例如 2 则访问 http://virt-nat-eu-1.cloudraft.cn:10025 3.png 点击 Aria2NG配置 - RPC(XXXX) 4.png 修改 RPC 别名 RPC 地址 RPC 秘钥其他不动，按图填写即可 免费申请一个Google无限团队盘打开地址 创建Google TeamDriveGmail必须填写正确！ 等待创建即可！ 安装Rclone执行12curl https://rclone.org/install.sh | sudo bashrclone config 配置说明如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148e) Edit existing remoten) New remoted) Delete remoter) Rename remotec) Copy remotes) Set configuration passwordq) Quit confige/n/d/r/c/s/q&gt; n # 选择n，新建name&gt; Google # 输入名称，类似于标签，用于区分不同的网盘。Type of storage to configure.Enter a string value. Press Enter for the default (&quot;&quot;).Choose a number from below, or type in your own value 1 / A stackable unification remote, which can appear to merge the contents of several remotes \\ &quot;union&quot; 2 / Alias for a existing remote \\ &quot;alias&quot; 3 / Amazon Drive \\ &quot;amazon cloud drive&quot; 4 / Amazon S3 Compliant Storage Providers (AWS, Ceph, Dreamhost, IBM COS, Minio) \\ &quot;s3&quot; 5 / Backblaze B2 \\ &quot;b2&quot; 6 / Box \\ &quot;box&quot; 7 / Cache a remote \\ &quot;cache&quot; 8 / Dropbox \\ &quot;dropbox&quot; 9 / Encrypt/Decrypt a remote \\ &quot;crypt&quot;10 / FTP Connection \\ &quot;ftp&quot;11 / Google Cloud Storage (this is not Google Drive) \\ &quot;google cloud storage&quot;12 / Google Drive \\ &quot;drive&quot;13 / Hubic \\ &quot;hubic&quot;14 / JottaCloud \\ &quot;jottacloud&quot;15 / Local Disk \\ &quot;local&quot;16 / Mega \\ &quot;mega&quot;17 / Microsoft Azure Blob Storage \\ &quot;azureblob&quot;18 / Microsoft OneDrive \\ &quot;onedrive&quot;19 / OpenDrive \\ &quot;opendrive&quot;20 / Openstack Swift (Rackspace Cloud Files, Memset Memstore, OVH) \\ &quot;swift&quot;21 / Pcloud \\ &quot;pcloud&quot;22 / QingCloud Object Storage \\ &quot;qingstor&quot;23 / SSH/SFTP Connection \\ &quot;sftp&quot;24 / Webdav \\ &quot;webdav&quot;25 / Yandex Disk \\ &quot;yandex&quot;26 / http Connection \\ &quot;http&quot;Storage&gt; 12 # 选择12，Google Drive** See help for drive backend at: https://rclone.org/drive/ **Google Application Client IdLeave blank normally.Enter a string value. Press Enter for the default (&quot;&quot;).client_id&gt; # 留空，回车Google Application Client SecretLeave blank normally.Enter a string value. Press Enter for the default (&quot;&quot;).client_secret&gt; # 留空，回车Scope that rclone should use when requesting access from drive.Enter a string value. Press Enter for the default (&quot;&quot;).Choose a number from below, or type in your own value 1 / Full access all files, excluding Application Data Folder. \\ &quot;drive&quot; 2 / Read-only access to file metadata and file contents. \\ &quot;drive.readonly&quot; / Access to files created by rclone only. 3 | These are visible in the drive website. | File authorization is revoked when the user deauthorizes the app. \\ &quot;drive.file&quot; / Allows read and write access to the Application Data folder. 4 | This is not visible in the drive website. \\ &quot;drive.appfolder&quot; / Allows read-only access to file metadata but 5 | does not allow any access to read or download file content. \\ &quot;drive.metadata.readonly&quot;scope&gt; 1ID of the root folderLeave blank normally.Fill in to access &quot;Computers&quot; folders. (see docs).Enter a string value. Press Enter for the default (&quot;&quot;).root_folder_id&gt; # 留空，回车Service Account Credentials JSON file pathLeave blank normally.Needed only if you want use SA instead of interactive login.Enter a string value. Press Enter for the default (&quot;&quot;).service_account_file&gt;Edit advanced config? (y/n)y) Yesn) Noy/n&gt; nRemote configUse auto config? * Say Y if not sure * Say N if you are working on a remote or headless machine or Y didn&apos;t worky) Yesn) Noy/n&gt; nIf your browser doesn&apos;t open automatically go to the following link: https://accounts.google.com/o/oauth2/auth?access_type=offline&amp;client_id=XXXXXXXXXXX.apps.googleusercontent.com&amp;redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&amp;response_type=code&amp;scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&amp;state=XXXXXXXXXXXXXXXXXXXXLog in and authorize rclone for access # 会弹出浏览器，要求你登录账号进行授权。如果没有弹出，复制上面的链接到浏览器中打开进行授权。Enter verification code&gt; # 在这里输入网页上显示的验证码Configure this as a team drive?y) Yesn) Noy/n&gt; yFetching team drive list...No team drives found in your account--------------------[Google]type = drivescope = drivetoken = &#123;&quot;access_token&quot;:&quot;XXXXXXXXXXXXXXXXXXXXX&quot;&#125;--------------------y) Yes this is OKe) Edit this remoted) Delete this remotey/e/d&gt; yCurrent remotes:Name Type==== ====Google driveOne onedrivee) Edit existing remoten) New remoted) Delete remoter) Rename remotec) Copy remotes) Set configuration passwordq) Quit confige/n/d/r/c/s/q&gt; q 参考:P3TERX - Rclone 安装配置教程 - 连接 OneDrive 和 Google Drive 配置 Aira2 自动上传执行 按图修改1vi /root/.aria2/autoupload.sh 5.png 执行 按图修改1vi /root/.aria2/aria2.conf 6.png 重启 Aria21service aria2 restart 使用Goindex + CloudFlare搞一个在线观看官方说明 donwa/Github 复制 index.js 里面的代码 打开 CloudFlare ，创建Workers 7.png 将上面复制的内容黏贴到Script中 执行 并 查看 rclone.conf 路径。1rclone config file 8.png 复制 root_folder_id 和 refresh_token 的值填入 CloudFlare Workers Script对应的代码位置里面 9.png 配置好后点击保存，然后打开CloudFlare Workers提供的域名即可看到对应的网盘内容 作者博客 风向标博客","categories":[{"name":"折腾","slug":"折腾","permalink":"https://sbcoder.cn/categories/折腾/"}],"tags":[{"name":"离线下载","slug":"离线下载","permalink":"https://sbcoder.cn/tags/离线下载/"},{"name":"Google","slug":"Google","permalink":"https://sbcoder.cn/tags/Google/"}]},{"title":"Canal 根据 binlog日志数据同步","slug":"Canal-根据-binlog日志数据同步","date":"2020-01-21T23:32:09.000Z","updated":"2020-01-21T23:33:46.000Z","comments":true,"path":"2020/01/22/canal_go.html","link":"","permalink":"https://sbcoder.cn/2020/01/22/canal_go.html","excerpt":"","text":"创建mysql账户如果使用的是root用户，则不需要操作这个步骤 grant all privileges on . to ‘jcc’@’%’ identified by ‘jcc’;flush privileges; 配置mysql (参见canal Quickstart)启用binlog日志打开 mysql.cnf 文件1234[mysqld] log-bin=mysql-bin binlog-format=ROW #选择row模式 server_id=9527 #配置mysql replaction需要定义，不能和canal的slaveId重复 添加slave权限如果使用的是root用户，则不需要操作这个步骤12CREATE USER canal IDENTIFIED BY 'canal'; GRANT SELECT, SHOW VIEW, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'canal'@'%';FLUSH PRIVILEGES; 创建canal server 服务端需要提前安装好Docker，如果不会安装，可以参考我之前写的文章 CentOS7 安装 Docker 1docker run -p 11111:11111 -e canal.auto.scan=false -e canal.instance.master.address=127.0.0.1:3306 -e canal.instance.dbUsername=test -e canal.instance.dbPassword=test -e canal.instance.connectionCharset=UTF-8 -e canal.instance.tsdb.enable=true -e canal.instance.gtidon=false -e canal.instance.filter.regex=.*\\\\..* -e canal.destinations=test -d canal/canal-server 需要替换以下参数 canal.instance.master.address=127.0.0.1:3306 地址ip更换（尽量用内网） canal.instance.dbUsername=test 数据库账户 canal.instance.dbPassword=test 数据库密码 canal.destinations=test test为名称 可以修改 11111:11111 服务器端口：docker端口 需要注意的是，所填写的数据库账户必须拥有数据库的操作权限，如果不知道权限如何配置，则建议直接使用root用户 canal 客户端我们这里使用Go客户端，因为Go语言的特性，可以很好的运行在Docker上 canal-go 文档: withlin/canal-go 开发过程可以参照文档 Docker启动canal客户端推荐使用Jenkins配置 canal-go构建成功后执行shell 12docker build -t canal_prod:v1 $&#123;WORKSPACE&#125;docker service update --image canal_prod:v1 --force --no-resolve-image canal_prod 如果看过我之前的 代码架构文章，可以在Portainer中看到打印在控制台的文字，也可以看到运行状态 FAQ问题解决Q:如果服务停止了，如何解决A:链接到canal-server的Docker内部，查看 canal-server - logs 中的日志 Q:如果数据同步失败了如何解决A:很大可能是由于改变了数据库结构导致的，需要重启客户端和服务端尝试 Q:一开始数据就不同步A:查看你的数据库账户是否有权限，如无权限则修改服务端启动时附带的数据库账户参数","categories":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/categories/优化/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://sbcoder.cn/tags/数据库/"},{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/tags/优化/"}]},{"title":"ThinkPHP使用RabbitMQ进行数据解耦 从安装到监听完全版","slug":"ThinkPHP使用RabbitMQ进行数据解耦-从安装到监听完全版","date":"2020-01-07T15:32:40.000Z","updated":"2020-01-07T15:33:42.000Z","comments":true,"path":"2020/01/07/rabbitmq_thinkphp.html","link":"","permalink":"https://sbcoder.cn/2020/01/07/rabbitmq_thinkphp.html","excerpt":"","text":"介绍分布式部署，RabbitMQ(简称MQ)作为消息中间件是一个非常不错的选择，可以实现异步互不干扰的解耦操作。 解决需求当有两套系统分别部署时，需要同步一部分数据，或者需要互不干扰解决异步独立运行时，可以使用RebbitMQ来给两套系统解耦，使用RebbitMQ作为中间件，只做消息传输使用，当系统A宕机或者因故障无法使用时，不会影响到系统B的正常运行！ 部署MQ使用Docker部署，安装Docker可以参照之前写的 CentOS7 安装 Docker，或者Ubuntu16.04/Ubuntu18.04 安装 Docker。 下载镜像镜像地址 rabbitmq1docker pull rabbitmq:management 1.png 1234# 创建容器并运行docker run -d -p 5672:5672 -p 15672:15672 --name rabbitmq rabbitmq:management# 查看 当前运行的容器docker ps 2.png 配置MQ安装MQ打开 http://IP:15672 3.png 使用默认用户名密码登录username:guest password:guest 4.png 红框内为你的rabbitmq版本号，我这里是3.8.2 创建一个管理员用户 5.png 修改guest的密码，请将123456修改为你需要修改的密码123docker exec -it rabbitmq /bin/bashrabbitmqctl list_usersrabbitmqctl change_password guest &apos;123456&apos; 修改guest默认密码以防止被人恶意利用 6.png 创建队列及交换机创建队列可以在mq页端创建也可以在代码中自动创建，我这里直接在页端创建 创建Queen 创建交换机，也在页端创建好 创建Exchange ThinkPHP实现过程Composer安装php-amqplib略 生产者实现 创建一个生产者类放置于 common 目录下，方便调用 123456789101112131415161718192021222324252627282930313233343536class RabbitMq&#123; protected $connection; protected $channel; //protected $exchange = 'router'; // //protected $queue = 'msgs'; public function __construct()&#123; $this-&gt;connection = new AMQPStreamConnection(config('rabbit_mq.host'), config('rabbit_mq.port'), config('rabbit_mq.user'), config('rabbit_mq.password')); $this-&gt;channel = $this-&gt;connection-&gt;channel(); &#125; /* * 向队列发送信息（生产者） * $data 向队列发送参数 * $code 路由名 * $queue 主题 * */ public function send($data,$exchange,$routing_key='order')&#123;// $this-&gt;channel-&gt;queue_declare($this-&gt;queue, false, true, false, false);// $this-&gt;channel-&gt;exchange_declare($this-&gt;exchange, AMQPExchangeType::DIRECT, false, true, false);// $this-&gt;channel-&gt;queue_bind($this-&gt;queue, $this-&gt;exchange); $messageBody = json_encode($data);//将要发送数据变为json字符串 $message = new AMQPMessage($messageBody, array('content_type' =&gt; 'text/plain', 'delivery_mode' =&gt; AMQPMessage::DELIVERY_MODE_PERSISTENT)); $this-&gt;channel-&gt;basic_publish($message,$exchange,$routing_key); $this-&gt;stop(); &#125; //关闭进程 public function stop()&#123; $this-&gt;channel-&gt;close(); $this-&gt;connection-&gt;close(); &#125;&#125; 实现过程如下 123456789101112131415161718192021222324252627class RabbitMq extends controller&#123; private $rabbitMq; /** * Unit constructor. * @param Request $request * @throws \\think\\db\\exception\\DataNotFoundException * @throws \\think\\db\\exception\\ModelNotFoundException * @throws \\think\\exception\\DbException */ public function __construct(Request $request)&#123; parent::__construct(); $this-&gt;rabbitMq = new \\app\\common\\RabbitMq(); &#125; /** * 添加 * @throws \\think\\db\\exception\\DataNotFoundException * @throws \\think\\db\\exception\\ModelNotFoundException * @throws \\think\\exception\\DbException */ public function add()&#123; $params = $this-&gt;request-&gt;param(); $this-&gt;rabbitMq-&gt;send($params,'testMq'); &#125;&#125; 消费者实现 创建一个RabbitMq类,方便之后调用 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768class RabbitMq extends controller&#123; protected $connection; protected $channel; protected $exchange; // protected $queue; protected $vhost; protected $consumerTag; protected $routeKey; // 此处使用配置文件配置，具体可自行配置 public function __construct() &#123; //连接RabbitMQ $this-&gt;queue = Config::get('database.RabbitMQ')['queue']; $this-&gt;exchange = Config::get('database.RabbitMQ')['exchange']; $this-&gt;vhost = Config::get('database.RabbitMQ')['vhost']; $this-&gt;consumerTag = 'AgentOrder'; $this-&gt;routeKey = 'addOrderAndSub'; $host = Config::get('database.RabbitMQ')['host']; $port = Config::get('database.RabbitMQ')['port']; $username = Config::get('database.RabbitMQ')['username']; $password = Config::get('database.RabbitMQ')['password']; $this-&gt;connection = new AMQPStreamConnection($host, $port, $username, $password); $this-&gt;channel = $this-&gt;connection-&gt;channel(); $this-&gt;logMqWright('MQ已连接'); &#125; // 消费信息 public function getMessage($callback) &#123; // 队列声明，创建队列，如果不存在则自动创建，如已创建则不需要使用 // $this-&gt;channel-&gt;queue_declare($this-&gt;queue, false, true, false, false); // 绑定交换机 $this-&gt;channel-&gt;exchange_declare($this-&gt;exchange, 'direct', false, true, false); $this-&gt;logMqWright('---MQ交换机绑定完成---'); // 绑定队列 $this-&gt;channel-&gt;queue_bind($this-&gt;queue, $this-&gt;exchange, $this-&gt;routeKey); $this-&gt;logMqWright('---MQ队列绑定完成---'); // 信息消费，no_ack 为true时为自动应答 $this-&gt;channel-&gt;basic_consume($this-&gt;queue, $this-&gt;consumerTag, false, true, false, false, $callback); $i = 0; while (count($this-&gt;channel-&gt;callbacks)) &#123; $this-&gt;logMqWright('---MQ执行次数统计[' . $i . ']---'); $i++; $this-&gt;channel-&gt;wait(); &#125; &#125; // 日志写入函数 目录/runtime/agent_log/当前年月/当前日期MQ.txt protected function logMqWright($msg) &#123; $val = \"\"; $currentDateTime = date('Y-m-d H:i:s', time()); $currentDate = date('Ymd', time()); $fileDir = __DIR__ . '/../../runtime/' . 'agentlog/' . date('Ym', time()); if (!file_exists($fileDir)) &#123; mkdir($fileDir, 0777, true); &#125; $fileName = $fileDir . '/' . $currentDate . \"MQ.txt\";//文件名称 $data = fopen($fileName, 'a+');//添加不覆盖，首先会判断这个文件是否存在，如果不存在，则会创建该文件，即每天都会创建一个新的文件记录的信息 $val = '[' . $currentDateTime . ']:' . $msg; $val .= \"\\n\"; fwrite($data, $val);//写入文本中 &#125; //关闭进程 public function stop() &#123; $this-&gt;channel-&gt;close(); $this-&gt;connection-&gt;close(); &#125;&#125; 消费者消费过程 1234567891011// CLI接口,需要开启守护进程 public function catch() &#123; //连接RabbitMQ $RabbitMq = new \\app\\common\\RabbitMq();//队列 $this-&gt;logAgentWrite('------------------MQ链接成功 开始整理MQ消息------------------'); $callback = function ($msg) &#123; echo $msg; // msg为队列内的信息流，在此处填写消费过程即可 &#125;; $RabbitMq-&gt;getMessage($callback); &#125; 消费者创建监听接口，用于守护进程调用 12345678class MqService&#123; public function __construct() &#123; &#125; public function mqAction() &#123; $this-&gt;catch(); // 调用上面的catch函数，自行修改 &#125;&#125; 至此所需要的代码就完成了 消费者脚本守护进程tips:只适用于Linux 我们在使用PHP作为消费者时，一般是使用PHP直接执行文件，使用nohup守护进程调用，但是当系统不稳定时，可能会出现各种问题导致mq队列失效，这时候就需要使用脚本监听，如果守护进程不存在，则自动重启守护进程 首先测试时可以先执行守护进程命令，例如1nohup /usr/bin/php7.2 /alidata/workspace/test/public/index.php /api_comm/mq_service/mqAction &amp; 路径请自行修改 监听信息编写Shell如下 1234567891011121314151617181920#!/bin/shfile_name=\"/root/restartMqService.log\" #重启脚本的日志，保证可写入，保险一点执行 chmod 777 restartMqService.logpid=0proc_num() &#123; num=`ps -ef | grep '/usr/bin/php7.2 /alidata/workspace/test/public/index.php /api_comm/mq_service/mqAction' | grep -v grep | wc -l` #此处'nohup /usr/bin/php7.2 /alidata/workspace/test/public/index.php /api_comm/mq_service/mqAction &amp;'替代为实际的，尽量准确，避免误kill return $num &#125;proc_id()&#123; pid=`ps -ef | grep '/usr/bin/php7.2 /alidata/workspace/test/public/index.php /api_comm/mq_service/mqAction' | grep -v grep | awk '&#123;print $2&#125;'` #此处'nohup /usr/bin/php7.2 /alidata/workspace/test/public/index.php /api_comm/mq_service/mqAction &amp;'也替代为实际的&#125; proc_num #执行proc_num()，获取进程数number=$? #获取上一函数返回值if [ $number -eq 0 ] #如果没有该进程，则重启then nohup /usr/bin/php7.2 /alidata/workspace/test/public/index.php /api_comm/mq_service/mqAction &amp; #启动程序的命令 proc_id echo $&#123;pid&#125;, `date` &gt;&gt; $file_name #把重启的进程号、时间 写入日志fi 将该脚本重命名为 mqMonitor.sh 配置Crontab在crontab配置文件下加上一行1*/2 * * * * sh /root/mqMonitor.sh 保存后重启生效，大致是2分钟监测一次，可自行修改","categories":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/categories/优化/"}],"tags":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/tags/优化/"},{"name":"消息队列","slug":"消息队列","permalink":"https://sbcoder.cn/tags/消息队列/"},{"name":"解耦","slug":"解耦","permalink":"https://sbcoder.cn/tags/解耦/"}]},{"title":"公司代码架构 - Docker + Jenkins + Gogs + Portainer(四)","slug":"公司代码架构-Docker-Jenkins-Gogs-Portainer-四","date":"2019-12-13T23:35:13.000Z","updated":"2019-12-18T12:51:18.000Z","comments":true,"path":"2019/12/14/docker_swarm.html","link":"","permalink":"https://sbcoder.cn/2019/12/14/docker_swarm.html","excerpt":"","text":"Portainer + Swarm 管理Docker集群介绍Portainer是一个Docker管理工具，它支持多种方式，我们这里只写，远程链接形式和本地形式 搭建环境 服务器1 ：Virmach 水牛城 RAM1.8G 2C 10GSSD（黑五机器） 操作系统 ：Ubuntu16.04 部署环境 ：LNMP1.6 （我是军哥铁粉） 服务器1：搭建Jenkins中转服务器，做代码自动构建使用服务器2：生产环境服务器，实则测试服务器，部署代码使用服务器3：Gogs服务器，Git版本库服务器，做代码版本控制使用 配置Portainer开放DockerAPI端口将需要加入Portainer管理的服务器（需要安装过Docker），打开2375端口，方便管理 创建一个备份，并编辑配置文件12cp /lib/systemd/system/docker.service /lib/systemd/system/docker.service.bak vi /lib/systemd/system/docker.service 方法一：在ExecStart整行后面添加 -H tcp://0.0.0.0:2375，有的时候他可能不止一行，则在最后面增加这一段即可，如下 2.png :wq 保存退出 方法二（推荐）：本方法并不适用于所有的Docker版本1vi /etc/docker/daemon.json 复制以下内容123456&#123; \"hosts\": [ \"tcp://0.0.0.0:2375\", \"unix:///var/run/docker.sock\" ]&#125; 配置完后重启Docker12systemctl daemon-reload systemctl restart docker 这里推荐大家使用iptables防火墙限制一下2375端口的访问，如果将2375暴露在公网则可能出现一系列安全问题，如果是国内的腾讯或者阿里，则可以直接在后台配置安全组，安全组里限制 指定IP访问指定端口即可，如果将2375暴露在外，则可能受到黑客恶意攻击！ 如果不是国内机器，也可以通过iptables限制访问1234iptables -I INPUT -s 107.173.XXX.XXX -p tcp --dport 2375 -j ACCEPTsystemctl iptables.service savesystemctl restart iptables.service# systemctl stop iptables.service 如果配置有误可以停止iptables尝试 非常不推荐直接将2375暴露在公网，秒被黑~ 配置后的效果如下图 3.png 安装Portainer创建数据1docker volume create portainer_data 创建Portainer并运行1docker run -d -p 8000:8000 -p 9000:9000 -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer 执行后访问 http://ip:9000即可看到 1.png 刚创建完会提示创建一个管理员用户，按照提示创建即可 选择创建Docker时使用Remote，远程连接，按下图填写 4.png 添加完成后如下图，点击访问创建好的节点则可以操作里面的内容 5.png 创建Swarm集群在管理节点上增加Swarm集群manager节点12docker swarm init --advertise-addr [IP ADDRESS]# 例如 docker swarm init --advertise-addr 107.173.XXX.XXX 返回结果如下，为了安全，关键位置已打码1234567Swarm initialized: current node (mjjrpuemaukx5a185iqd54mka) is now a manager.To add a worker to this swarm, run the following command: docker swarm join --token SWMTKN-1-1zd********2oci43nbf1jjhlng8k********fhfzqw2-1ywv79qnvmlb*******h3gs35r 107.173.XXX.XXX:2377To add a manager to this swarm, run &apos;docker swarm join-token manager&apos; and follow the instructions. 当Manager节点增加完成后，可以在子节点中输入上面提示的命令以worker形式加入集群1docker swarm join --token SWMTKN-1-1zd********2oci43nbf1jjhlng8k********fhfzqw2-1ywv79qnvmlb*******h3gs35r 107.173.XXX.XXX:2377 子节点加入成功后可以在父节点中查看子节点信息1docker node ls 6.png 如果在Portainer增加manager节点，则会自动出现 Swarm 和 Service选项，如图 7.png 结语本次搭建过程就基本完成了，我们可以通过Portainer管理之前搭建的一系列环境，至此，一套简单的公司架构就完成了，生产环境也可以做到实时构建，只需要在Gogs上面发布版本就可以了，选择手动构建，构建时选择版本号即可，这样做的好处是如果正式环境有bug时可以随时回滚到稳定版本，当然，发布版本也是建立在测试完后的场景！","categories":[{"name":"架构","slug":"架构","permalink":"https://sbcoder.cn/categories/架构/"}],"tags":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/tags/优化/"},{"name":"架构","slug":"架构","permalink":"https://sbcoder.cn/tags/架构/"},{"name":"版本控制","slug":"版本控制","permalink":"https://sbcoder.cn/tags/版本控制/"}]},{"title":"公司代码架构 - Docker + Jenkins + Gogs + Portainer(三)","slug":"公司代码架构-Docker-Jenkins-Gogs-Portainer-三","date":"2019-12-11T11:09:38.000Z","updated":"2019-12-11T11:10:26.000Z","comments":true,"path":"2019/12/11/jenkins_docker.html","link":"","permalink":"https://sbcoder.cn/2019/12/11/jenkins_docker.html","excerpt":"","text":"配置Jenkins实现自动构建介绍前面已经搭建好了基本环境，剩下的就是自动构建了，这里就需要使用我们的构建工具Jenkins，Jenkins是一个非常牛逼的东西，它可以实现代码同步构建，当你修改你的代码并传到git时，Jenkins可以自动将你的代码同步到服务器上面，当然这只是Jenkins的基本功能之一，他还有非常多的东西值得我们学习~ 搭建环境 服务器2 ：Pacificrack 洛杉矶 RAM2G 2C 35GSSD（圣诞机器）18刀 操作系统 ：CentOS7.5 部署环境 ：LNMP1.6 （我是军哥铁粉） + Java8 服务器1：搭建Jenkins中转服务器，做代码自动构建使用服务器2：生产环境服务器，实则测试服务器，部署代码使用服务器3：Gogs服务器，Git版本库服务器，做代码版本控制使用 生产环境搭建服务器2的生产环境搭建。 生产环境，主要就是LNMP和Java8，LNMP是可选的，看需要部署的程序环境，例如需要部署node.js则只需要node.js环境即可，其他同理，我这边是准备自动部署PHP程序，因此就还是使用LNMP； Java8是必须的，Jenkins使用SSH连接到服务器时是需要源服务器有Java环境的 安装LNMPLNMP环境安装教程 : LNMP一键安装包 - 安装教程 安装Java8Jenkins连接节点的服务器必须安装！其他服务器无需安装！ 首先更新 yum 源1yum update 安装 jdk1.81yum install java-1.8.0-openjdk java-1.8.0-openjdk-devel 这里注意，是可以选择Java版本的，我这里使用了8所以按照8的方式安装的 可以搜索yum选择需要安装的版本1yum search java | grep jdk 一般 使用上面方法安装的Java配置文件都在 /etc/profile 编辑配置1vi /etc/profile 在末尾添加 环境变量，注意修改自己的版本号12345JAVA_HOME=/user/lib/jvm/java-1.8.0-openjdk-1.8.0.191.b12-1.el7_6.x86_64JRE_HOME=$JAVA_HOME/jreCLASS_PATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libPATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binexport JAVA_HOME JRE_HOME CLASS_PATH PATH 重置 profile1source /etc/profile 查看Java版本1java -version Jenkins配置安装必要的插件打开Jenkins登录后 打开 系统管理 - 插件管理 - 可选插件 搜索 安装 以下插件 汉化语言包(可选) Locale plugin Localization: Chinese (Simplified) Docker容器(可选) Docker Pipeline 远程连接(必须) SSH plugin SSH Slaves plugin Oracle Java SE Development Kit Installer Plugin Git服务(推荐) GitHub plugin Gogs plugin 推荐安装(可选) bouncycastle API Plugin Branch API Plugin Command Agent Launcher Plugin 插件属于按需配置，不适合自己的插件无需安装 增加节点增加节点必须要先在节点服务器配置Java环境，参照上面的配置Java8环境配置！如果没有配置Java环境则会报错！ 增加节点必须要有SSH插件，因此如果界面与我不一样请检查自己是否安装了上面的插件 打开Jenkins 系统管理 - 节点管理 - 新建节点 1.png 新建节点页面如下 2.png 如果没有设置过凭证则选择添加，界面如下 3.png 全部设置完点保存，他会自动启动代理节点 首页左下角会显示状态 4.png 或者在节点管理里面也可以看到 配置Gogs WebHook根据上一节我们配置好的Gogs，新建一个仓库，这里不多说，直接点加号就行，用过Github的都懂 可以选择公有仓库或者私有仓库，我这里都是私有仓库，也可以使用Gogs的迁移外部仓库功能直接迁移，迁移时可能会出现504错误，这是因为Nginx的反向代理时有超时设置，超过指定时间则直接504，我们在迁移仓库时经常会超时，因此建议修改一下默认超时时间，具体配置可以自行搜索，不多赘述。 找到需要自动构建的仓库，选择 仓库设置 - 管理 Web 钩子 - 添加Web钩子 6.png 注意：图中红框处的test需要跟后面配置的Jenkins对应，例如我创建的Jenkins任务名为 test 则此处填写test，修改域名为你的Jenkins域名，其他格式一致 注意：图中秘钥可随便填写，记录下来，配置Jenkins任务时会用到 配置Jenkins任务打开 Jenkins 新建任务，如果以前没有任务则首页会显示 创建一个新任务 5.png 配置Jenkins任务 7.png 描述部分可随便填写，这里主要配置一下 Gogs Webhook 勾选 Use Gogs secret，Secret填写上面创建Gogs WebHook时的秘钥 勾选 限制项目的运行节点 ，标签表达式填写你的节点名字，例如我这里的节点名字就是我的服务器ip地址，直接填写ip地址即可 8.png 源码管理选择Git，Repository URL选择需要自动构建的Git项目地址，http形式的，Credentials处为验证，如果是公共仓库则无需配置，如果是私有库则需要填写登录到 Gogs 的账户和密码，配置与之前的节点配置凭据一样，不多赘述 指定分支填写需要自动构建的分支，我这里填写的是dev分支，用来做开发版测试使用，根据自己情况来即可 配置上线Nginx配置由于我创建的节点 目录地址是 /home/wwwroot 在项目自动构建时，则会自动创建目录 /home/wwwroot/workspace/[JOB NAME]JOB NAME 为 任务名，例如我的 test 则自动创建目录 /home/wwwroot/workspace/test Nginx则只需要配置 域名解析即可 1lnmp vhost add 9.png 按图上配置即可，建议增加SSL证书，增加证书前记得先把域名解析到指定服务器IP上，否则会生成证书失败 记得给文件夹加上权限，755 构建返回Jenkins，点击立即构建，第一次构建时间可能会长一些，等待即可! 构建完成后则会在 配置的目录下创建workspace目录，并将代码放入 /home/wwwroot/workspace/test 目录中，根据自己的配置自行修改目录 由于我的程序涉及到跨目录访问，因此需要更改 fastcgi.conf 文件，与本文无关这里不多说~ 附一张成功截图，由于我这是前后端分离项目，因此没有界面~ 10.png 自动构建上面已经配置好了自动构建，我们每次合并代码或者提交代码变更到dev分支时，Gogs则会以Webhook的形式将内容推送到Jenkins上面去，实现每次更新代码自动构建服务器代码。 结语目前搭建好的架构，适合还在开发测试程序的开发小组，配合测试人员使用，也能让产品们在汇报工作进度的时候更得心应手，了解开发进度，当然也不是特别准确的开发进度，摸鱼还是要摸的。后面应该会写一下 Portainer + Swarm 管理Docker集群，慢慢写~","categories":[{"name":"架构","slug":"架构","permalink":"https://sbcoder.cn/categories/架构/"}],"tags":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/tags/优化/"},{"name":"架构","slug":"架构","permalink":"https://sbcoder.cn/tags/架构/"},{"name":"版本控制","slug":"版本控制","permalink":"https://sbcoder.cn/tags/版本控制/"}]},{"title":"公司代码架构 - Docker + Jenkins + Gogs + Portainer(二)","slug":"公司代码架构-Docker-Jenkins-Gogs-Portainer-二","date":"2019-12-10T11:05:36.000Z","updated":"2019-12-10T11:07:02.000Z","comments":true,"path":"2019/12/10/gogs_docker.html","link":"","permalink":"https://sbcoder.cn/2019/12/10/gogs_docker.html","excerpt":"","text":"安装 Gogs + Docker常用命令介绍本节主要写一下Jenkins的配置与自动构建过程，包括使用Gogs作为git服务器，配置自动构建等。本节需要配合上一节的内容使用，即 安装 Docker + Jenkins 的服务器一台 搭建环境 服务器3 ：TencentCloud 北京 RAM4G 2C 40GSSD（新用户机器）998RMB/3Year 操作系统 ：CentOS7.5 部署环境 ：LNMP1.6 （我是军哥铁粉） 服务器1：搭建Jenkins中转服务器，做代码自动构建使用服务器2：生产环境服务器，实则测试服务器，部署代码使用服务器3：Gogs服务器，Git版本库服务器，做代码版本控制使用 配置无需对标，都是低配置小鸡，唯一一个腾讯云 2C4G 的机器是我之前放其他业务的机器，由于git经常需要使用因此搭建在国内套CloudFlare使用，实则Gogs只需要 2C1G 机器即可，官方推荐配置是2C512M，是一个不吃内存的程序，目前腾讯云的 1C2G 只需要99/年，属于大众所承受的起的价格，由于我不是专职AFFMAN，因此不贴链接 CentOS7 安装 Docker1yum -y install docker 1.png 12start dockerenable docker 2.png 查看版本号，查看是否安装成功！1docker -v 3.png Docker 常用命令记录一下安装时可能会出现的问题，以及常用的Docker命令 查看当前运行的容器1docker ps 查看所有容器1docker ps -a 停止容器12docker stop [DOCKER NAME] # 例如：docker stop gogs 删除容器(必须在Stop之后才可以删除)12docker rm [DOCKER NAME] # 例如：docker rm gogs 进入容器1234docker attach [DOCKER NAME] # 例如： docker attach gogsdocker exec -it [DOCKER IMAGE ID] /bin/bash# 例如： docker exec -it ef5cb0692b57 /bin/bash 退出容器1exit 查看容器变动日志12docker diff [DOCKER NAME]# 例如：docker diff gogs 查看容器或者镜像详细信息12sudo docker inspect [IMAGE NAME]:0.1 # 例如： sudo docker inspect gogs 向容器内部发送指令12docker exec [DOCKER NAME] [COMMAND]# 例如 docker exec gogs ls 安装 Gogs安装下载镜像 Gogs1docker pull gogs/gogs 4.png 创建目录12mkdir -p /home/Gogscd /home/Gogs 5.png 开启Docker1234# 直接启动docker run --name=gogs -p 10022:22 -p 10080:3000 -v /home/Gogs:/data gogs/gogs# 后台启动docker run --name=gogs -d -p 10022:22 -p 10080:3000 -v /home/Gogs:/data gogs/gogs 配置正常启动后直接打开 http://ip:10080即可 如图： 6.png 接下来按照提示配置即可，我们这里使用SQLite3 应用配置需要注意一下 域名填写你的服务器公网IP SSH端口号填写 映射的端口号 10022 HTTP端口号填写 3000 应用URL填写 ip + 映射的端口号 10080 访问 7.png 配置完成后如果设置好管理员账户的会自动登录进去，如果没有设置的可以自行注册。 注意：数据库中第一个用户就是管理员账户 8.png Tips：Gogs的配置文件存放在 Docker中的 /data/gogs/conf/app.ini 如果想要更改可以 反向代理绑定域名同 公司代码架构 - Docker + Jenkins + Gogs + Portainer(一)一样，在应用配置阶段修改或者修改配置文件都可以 结语Gogs 是一个轻量级的 Git服务器，适用于一些小公司小团队使用，大公司使用Gitlab的情况可能更多一些，但是东西实际都是差不多的，为了占用资源更小一些，我这里还是选用了比较轻量级的Gogs","categories":[{"name":"架构","slug":"架构","permalink":"https://sbcoder.cn/categories/架构/"}],"tags":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/tags/优化/"},{"name":"架构","slug":"架构","permalink":"https://sbcoder.cn/tags/架构/"},{"name":"版本控制","slug":"版本控制","permalink":"https://sbcoder.cn/tags/版本控制/"}]},{"title":"公司代码架构 - Docker + Jenkins + Gogs + Portainer(一)","slug":"公司代码架构 - Docker + Jenkins + Gogs + Portainer(一)","date":"2019-12-09T11:47:26.000Z","updated":"2019-12-10T11:07:37.000Z","comments":true,"path":"2019/12/09/code_build.html","link":"","permalink":"https://sbcoder.cn/2019/12/09/code_build.html","excerpt":"","text":"公司代码架构 - Docker + Jenkins + Gogs + Portainer(一)介绍公司研发项目时，遇到git作为版本控制时，很常见的问题是部署比较麻烦（相比较麻烦），需要先克隆在拉到服务器部署，代码提交频率过高时，就会出现一天很多次提交代码，部署代码，浪费了大量的人力物力，于是乎大量的架构师技术总监们开始研究各类解决方案，各种上线前review代码，这是一件非常痛苦的事情，这里简单记录一下公司代码架构的部署，来解决公司代码架构上的诸多问题，也是自己做一个笔记，文章内如有错误，还请各位指出。 Tips：该环境并不适用于个人用户以及小微企业，适用于项目众多且开发人员大于30人的公司 搭建环境 服务器1 ：Virmach 水牛城 RAM1.8G 2C 10GSSD（黑五机器） 操作系统 ：Ubuntu16.04 部署环境 ：LNMP1.6 （我是军哥铁粉） 这里说明一下，多台服务器是为了解耦，说是解耦，实则认为承受不住，且大部分公司已经有一套完整的git服务器了，本节要做的就是加个自动构建而已，git服务器可自选环境，后面会讲如何搭建Gogs，如果有高配置服务器的公司或个人，可以尝试使用单服务器多部署，本文所需共三台服务器。 服务器1：搭建Jenkins中转服务器，做代码自动构建使用服务器2：生产环境服务器，实则测试服务器，部署代码使用服务器3：Gogs服务器，Git版本库服务器，做代码版本控制使用 服务器1的配置属于中下配置，该机型一年 13刀，属于大部分人都承受的起的价格，请注意，本文标注的配置仅用于配置自动构建服务器，并不用于部署代码以及Git服务，个人用户小鸡多的可以尝试 Ubuntu16.04/Ubuntu18.04 安装 DockerDocker可以说是非常的牛X了，关于他的概念不多说，牛就牛在管理太方便了，就好像是 WHMCS 用母鸡开小鸡一样，母鸡永远不考虑小鸡的运作，只需要配合就好，Docker也一样，我们只需要创建容器，管理容器就够了，剩下的交给Docker来处理，且Docker可以做负载均衡，后续做架构的时候可以开多个Docker做集群，按需来做 安装删除旧版本，更新apt-get，安装docker123sudo apt-get remove docker docker-engine docker-ce docker.iosudo apt-get updatesudo apt install docker.io 启动Docker并查看版本启动docker123systemctl start dockersystemctl enable dockerdocker --version 我这里安装的是 18.09版本 Docker1.png 安装Jenkins安装安装Jenkins可以选择多种方式安装，我这里采用的是Docker的方式安装的，由于我们上面已经安装过Docker，按照Jenkins官方给的安装方案就可以了，首先pull一个稳定版本的 Jenkins 镜像镜像地址 : jenkinsci/blueocean12docker pull jenkinsci/blueoceandocker images Docker2.png 查看当前Jenkins版本1docker inspect [IMAGE ID] 这里的 IMAGE ID 则是上面 查看镜像的 IMAGE ID Jenkins1.png 红框内则是 对应版本号 123456# 创建一个存放Jenkins Docker的目录mkdir /home/root/Jenkins# 启动一个Dockerdocker run -d --name jenkins -p 8081:8080 -v /home/jenkins:/home/jenkins jenkins/jenkins:lts# 查看jenkins服务docker ps | grep jenkins Jenkins2.png 打开 http://IP:8081 Jenkins3.png 输入命令进入 Docker内部123docker exec -it jenkins bash# 获取密码cat /var/jenkins_home/secrets/initialAdminPassword 重启Docker1docker restart [CONTAINER ID] [CONTAINER ID] 为当前Jenkins的版本号 例如 2.164.3 则输入 docker restart 2.164.3 Nginx反代Jenkins，绑定域名由于众所周知的水牛城服务器卡，国内环境必须搭配CloudFlare才可以使用，否则太卡了，因此安装LNMP环境，后续自动构建时也可以构建到这里 安装方法一： LNMP环境安装教程 : LNMP一键安装包 - 安装教程 懒得打开的话，可以直接输入1wget http://soft.vpser.net/lnmp/lnmp1.6.tar.gz -cO lnmp1.6.tar.gz &amp;&amp; tar zxf lnmp1.6.tar.gz &amp;&amp; cd lnmp1.6 &amp;&amp; ./install.sh lnmp 我这里安装的是 1.6稳定版，需要其他版本的可以自行修改版本号安装 安装方法二： apt-get安装，建议先更新apt-get1apt-get install nginx 打开NGINX配置文件目录，创建一个新的配置文件(这里是lnmp环境的配置文件地址，apt-get安装的nginx配置文件存放于 /etc/nginx/conf.d 中) 1vi /usr/local/nginx/conf/vhost/jenkins.conf 输入以下内容，请注意替换掉下面的 jenkins.0161.org1234567891011121314server &#123; listen 80; server_name jenkins.0161.org; client_max_body_size 60M; client_body_buffer_size 512k; location / &#123; proxy_pass http://localhost:8081; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;&#125; 重启lnmp使配置生效1lnmp reload 打开CloudFlare绑定域名，增加CDN支持，此处比较简单，不多赘述 结语一个完整的架构，需要很多的付出，并非一朝一夕，本文所属架构并不适用于所有公司或者个人，大型公司还需要K8s集群，承受多少并发取决于很多因素，任何架构都不能通杀所有类型的公司","categories":[{"name":"架构","slug":"架构","permalink":"https://sbcoder.cn/categories/架构/"}],"tags":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/tags/优化/"},{"name":"架构","slug":"架构","permalink":"https://sbcoder.cn/tags/架构/"},{"name":"版本控制","slug":"版本控制","permalink":"https://sbcoder.cn/tags/版本控制/"}]},{"title":"开发中常见的MySQL数据库优化细节","slug":"开发中常见的MySQL数据库优化细节","date":"2019-06-20T10:17:03.000Z","updated":"2019-12-09T11:51:26.000Z","comments":true,"path":"2019/06/20/mysql_optimize.html","link":"","permalink":"https://sbcoder.cn/2019/06/20/mysql_optimize.html","excerpt":"","text":"前言以我的习惯来讲，每开始一个新的项目都需要先把思路完善，紧接着就需要建立数据库，在码代码的时候，就一般不会在修改数据库的构造了，因此，数据库的结构通常关乎着查询的速度以及程序的完善程度，一个好的结构可以让你少写很多代码，也能让程序的运行速度更加快，通常在大公司都是由DBA来做这件事，但是事无绝对，作为一名合格的后端，掌握一些少量的数据库优化也是很需要的。 MySQL优化 - 数据类型及CURDPROCEDURE ANALYSE()PROCEDURE ANALYSE() [prəˈsējər ˈænəlaɪz]是一个MySQL自带的给我们提供数据库优化建议的函数，他可以直接运行在MySQL中，直接在执行语句中加上这个函数即可1SELECT * FROM `list` WHERE 1 PROCEDURE ANALYSE ( ) 这段SQL执行过后，将会把list表中的数据分析一遍，并把他的分析结果展示出来 Field_nameMin_valueMax_valueMin_lengthMax_lengthEmpties_or_zerosNullsAvg_value_oravg_lengthstdOptimal_fieldtype 他将会把分析出来的 字段名 最短值 最大值 以及最后一列就是MySQL给出的分析结果，我们可以在有一定数据的时候使用这个函数来分析，这样给出的结果会更精确一些，只需要查看最后一列Optimal_fieldtype的值即可，这个函数并不适用于数据库设计阶段，它适用于后期使用 EXPLAINEXPLAIN是一个非常好用的MySQL语法，在我们功能测试阶段，如果发现某页面非常慢，排除静态资源问题后就可以试试使用EXPLAIN，我们可以在执行语句前面加上 EXPLAIN 来获得执行过程，通过该结果我们可以看到SQL如何改变会减少查询时间和次数。1EXPLAIN SELECT * FROM `list` WHERE 1 这段SQL执行后，将会返回如下格式的分析结果 idselect_typetabletypepossible_keyskeykey_lenrefrowsExtra 我们主要看rows就行，为了得到想要的结果，rows的值越小越好，使用EXPLAIN来调试简直是再好不过了！ ENUM(枚举)类型很多程序员往往喜欢统一一个数据类型，比如说 ‘varchar’ ，这可能是我见过最多的数据类型了，早些时期，的确是有很多的公司或者程序都是大面积使用，随着MySQL的革新换代，很多的类型都可以避免使用它。我在很多得程序上测试过（有数据）PROCEDURE ANALYSE()方法，他给出了很多 ‘varchar’ 替换为 ‘enum’ 的建议，这说明，enum类型的确是一个应该被重视的数据类型，但由于他是一个枚举类型，我们在定义数据类型的时候并不适合直接上手定义，所以很多时候都是在有一定的数据量的时候才想要换数据类型的。可以理解为枚举即时索引，枚举就相当于给这个字段的可能值都加上了一个索引，与我们为了优化查询加索引是一样的概念。enum更适用于选项卡类字段，例如性别，订单状态等，如果您字段中只有几个重复的值也是非常推荐使用的。 JOIN链接查询，这是我们在开发中非常常用的查询方式，首先要知道，我们在学校里学习的大多数是 AND 链接多表查询，虽然能够将结果无误的查询出来，但是速度就影响的非常多了，这里还是推荐大家使用JOIN来连接查询有些同学可能不太理解JOIN，简单说一下JOIN的内连接和外链接，左外链接和右外链接吧 内连接即是A B两表链接，只取两表共有的数据，假设 B 中 有的数据 A 表内没有对应的数据则无法查询到 1SELECT * FROM list1 INNER JOIN list2 on list1.id = list2.id 外连接（FULL JOIN 也称作全连接）即是A B两表链接，取两表所有的数据，即使 B 表中的某些数据无法匹配链接条件时，也正常链接 1SELECT * FROM list1 FULL JOIN list2 on list1.id = list2.id 左外连接，即是 A B两表链接，取两表所有数据，若A表中有B表不匹配的数据，同样展示出来，B表如果有A不匹配的数据，则不展示 1SELECT * FROM list1 LEFT OUTER JOIN list2 on list1.id = list2.id 右外连接，即是 A B两表链接，取两表所有数据，若B表中有A表不匹配的数据，同样展示出来，A表如果有B不匹配的数据，则不展示，与左外连接相反 VvmQFU.png MySQL优化 - 结构FULLTEXT INDEXFULLTEXT INDEX(全文索引)，更适用于文章内容搜索的索引，我们在作搜索功能的时候，很多人喜欢将文章内容(content)建立普通索引，但是实际上，这种做法并不会增加查询速度，通常我们做搜索的时候，执行下列语句。 1SELECT content FROM `list` WHERE content LIKE '%风向标%' 如果搜索功能权重比较高的网站，就需要将content这个字段建立索引。 1ALTER TABLE `list` ADD FULLTEXT (`content`) 如果是phpmyadmin用户，在phpmyadmin中直接点击’全文搜索’即可。 MyISAM OR InnoDB？就我现阶段写出来的东西来看（数据量小，查询次数少，用户量较少），MyISAM肯定是最适合我的，它更适用于小型网站，以及事务处理较少的网站InnoDB则与之相反，如果你的业务比较复杂，针对数据库的操作较多的时候，InnoDB就会更适合一些。使用INSERT插入数据时 MyISAM 就比 InnoDB 更快一些，而 UPDATE 时 InnoDB 就会比 MyISAM 快一些 如果您是轻度SQL用户，重功能不重视业务的项目，那么我个人以为 MyISAM 更适合一些如果您感觉业务逻辑复杂，经常使用SQL，那么可以尝试使用 InnoDB 最后也是见仁见智，没有好坏，如果您希望测试，也是可以通过直接修改数据库引擎来测试速度的 MySQL优化 - 小知识点 不要使用 SELECT * 查询 不要使用 NULL 频繁查询的字段建立索引 索引过多时会影响 UPDATE 和 INSERT 的执行速度 避免在 WHERE 时使用 != &lt;&gt; 等操作符，MySQL会自动放弃索引，直接全表扫描 避免使用 IN 和 NOT IN，尽量使用BETWEEN，MySQL会自动放弃索引，直接全表扫描 可以使用 EXISTS 来代替 IN 使用 某些情况下可以使用强制使用索引查询 SELECT * FROM list with(index(索引名)) WHERE …. 避免使用 OR 作为调件，可以使用 UNION 并集查询将两次查询结果合并 尽可能将表内容长度固定 查询时如果只查询一条信息，就使用 LIMIT 1 避免使用比较表达式 如 10000+1 = id 可以使用 id = 10000+1 记得将查询链接即时关闭掉 使用变量来给MySQL开启查询缓存，避免使用MySQL内置变量函数 设置的主键尽量使用长度短且最好是int类型 垂直分割，将大量的字段的表优化成多个少字段的表 INSERT 和 DELETE 是一个可以锁定数据表的SQL语句，必须等待执行完毕后才会解除锁定，如果这条语句执行起来过于缓慢，请谨慎使用 Object Relational Mapper Prepared Statements 参考: Top 20+ MySQL Best Practices参考: 廖雪峰的个人网站 - 链接查询","categories":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/categories/优化/"}],"tags":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/tags/优化/"},{"name":"MySQL","slug":"MySQL","permalink":"https://sbcoder.cn/tags/MySQL/"}]},{"title":"mm131全栈多线程爬虫","slug":"mm131全栈多线程爬虫","date":"2019-06-19T14:34:31.000Z","updated":"2019-06-19T14:56:33.000Z","comments":true,"path":"2019/06/19/mm131_spider.html","link":"","permalink":"https://sbcoder.cn/2019/06/19/mm131_spider.html","excerpt":"","text":"起因LOC的大佬们最近开始疯狂的爬取mm131，作为一个Python初心者，作为技术上的学习，也要与时俱进，简单写了一个图片下载爬虫，看到大佬们似乎是做了一个typechoo的对接接口，我这边回头有空也搞一个wordpress的接口（只在博客内发布），之前写过一个新浪远程上传的接口，由于种种原因，新浪已经不支持外链了，因此这个wordpress接口可能就有时间再做了，不然做出来也是个摆设，没地方放。 代码解析网址不发了，直接讲，或者大家直接百度谷歌都可以搜得到。打开网站,总共有如下六个分类 mm131.jpg 每个分类下面都有一堆的图集，有N个分页的图集，但是第一页跟第二页的地址还不太一样，这点跟192tt做的很相似，感觉这几个站长是不是都是用的同一套程序，如果是的话可以通杀了。。。首先遍历图集的地址，到目前更新文章截止，一共大概5000多套按分类给他搞一个分类循环 1234list = &#123;'xinggan':6,'qingchun':1,'xiaohua':2,'chemo':3,'qipao':4,'mingxing':5&#125; # list = &#123;'mingxing':5&#125; for key in list: getPageUrl(key,list[key]) 解析图片url，用正则获取就行，用bs4取到末页的地址，然后遍历循环取图集地址 1234567try: i.find('img').get('src')except Exception as e: for s in i.find_all('a'): endPage = s.get('href') endPage = rex('list_%s_(\\d+).html'%num,endPage) continue 获取图集地址12345678910nextUrl = \"%s/list_%s_%s.html\"%(url,num,i+2)response = requests.get(nextUrl, headers=headers)response.encoding = 'gb2312'soup = BeautifulSoup(response.text, 'html.parser')for i in soup.find('dl', &#123;'class': 'public-box'&#125;).find_all('dd'): try: i.find('img').get('src') except Exception as e: continue print(i.find('a').get('href')) 需要注意的是，mm131的图片是有防盗链的，根据referer判断，随便找一个图集的地址设置上即可1234headers = &#123; \"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36\", 'referer': \"http://www.mm131.com/xinggan/4995.html\",&#125; 线程池应用之前的爬虫除了Scrapy搞出来的之外都是单线程的爬虫，优点是比较稳定，但是缺点也很明显，太慢了，mm131这个站的图大都比较小，如果是一张一张下载确实是不太划算，于是搞了个线程池。Python的线程池很简单，只需要引入 threadpool 即可，如果报错，请 pip install threadpool,12345678910# 引入threadpoolimport threadpool# 创建线程池，设置为12线程，可以根据自身情况修改pool = threadpool.ThreadPool(12)# 创建callback函数，参数1 getSingleData 是需要调用的函数名，list是函数getSingleData的参数，该方法适用于单个参数的函数，list是一个一维数组或对象pageTask = threadpool.makeRequests(getSingleData, list)# 执行线程池[pool.putRequest(req) for req in pageTask]# 等待完成后退出pool.wait() 演示和下载演示图 多线程演示.jpg 下载结果.jpg 下载演示代码不全，直接上地址https://github.com/ai0by/ai0by-spider/tree/master/mm131","categories":[{"name":"Python","slug":"Python","permalink":"https://sbcoder.cn/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://sbcoder.cn/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://sbcoder.cn/tags/爬虫/"},{"name":"福利","slug":"福利","permalink":"https://sbcoder.cn/tags/福利/"}]},{"title":"Redis/Redis集群以及在Laravel中的使用方法","slug":"Redis-Redis集群以及在Laravel中的使用方法","date":"2019-06-17T13:19:37.000Z","updated":"2019-06-17T13:21:08.000Z","comments":true,"path":"2019/06/17/Redis_laravel_PHP.html","link":"","permalink":"https://sbcoder.cn/2019/06/17/Redis_laravel_PHP.html","excerpt":"","text":"Redis的数据类型Redis也算是一种数据的容器，承载在内存上，因此它的各方面性能都比较快，且作为非关系型数据库，面对各种索引也比普通的数据库查询快，不同的场景下使用不同的数据类型，适用于很多地方 字符串类型 String一一对应，使用场景比较多 key:value 形式 命令 描述 set key value 设置指定key值 get key 获取指定key的value值 mget key1 key2 获取多个key 的 value，按顺序返回value值 mset key1 ‘value1’ key2 ‘value2’ 批量设置多个key的value strlen key 返回对应value长度 getrange key start end 截取字符串 append key value 追加key关联的value值，返回长度 getset key value 设置key的value并返回原value值 setex key time value 设置value值，并加上一个过期时间，使用ttl key查看过期时间，秒为单位 setnx key value 当key不存在时，设置value msetnx key1 ‘value1’ key2 ‘value2’ 当所有的key都不存在时，批量设置多个key的value incr key 将key关联value的值加一，仅对数字有效 incrby key num 将key关联value的值加num，例如 10，仅对数字有效 incrbyflout key num 将key关联value的值加num，浮点类型 decr key 将key关联value的值减一，仅对数字有效 decrby key num 将key关联value的值减num，例如 10，仅对数字有效 哈希类型 Hash一对一对多，类似字符串，但又区别于字符串，它比字符串复杂一些，同样是key:value，但是他的value可以是一个map，同时，它也无法给单个属性赋予过期时间，但可以给单个属性设置值，某些情况下比String占用资源少，当需要缓存整张表时推荐使用 命令 描述 hset key field value 设置key关联的value hkeys key 获取所有的key hgetall key 获取key的所有对应field hvals key 获取hash表中所有的value hlen key 获取keyd的长度 hmget key field1 field2 获取多个field的值 hmset key field1 value1 field2 value2 设置多个field的值 hdel key field 删除单个field的单个属性 hsetnx key field value 当field不存在时存储数值 hincrby key field num 给指定字段增加数值，整数 hincrbyfloat key field num 给指定字段增加浮点数 列表类型 List类似栈，拥有栈的特性，也有链表的特性，亦可用作消息队列等场景，使用场景很广 命令 描述 lpush key value1 value2 将多个value插入到关联的key里面 头部 lpushx key value 将value插入到key中，需要key已经存在 头部 lpop key 删除并获取当前key里面的第一个元素 llen key 获取当前key关联的list长度 rpush key value1 value2 将多个value插入到关联的key里面 尾部 rpop key 删除并获取列表内的最后一个元素 rpushx key value 将value插入到key中，需要key已经存在 尾部 blpop key1 key2 timeout 删除并获取列表的第一个元素，key1存在时不执行key2，如果没有会一直阻塞到弹出为止，建议添加延时 brpop key1 key2 timeout 删除并获取列表的最后一个元素，key1存在时不执行key2，如果没有会一直阻塞到弹出为止，建议添加延时 lindex key 通过索引来获取list中的元素 lset key index value 通过索引来设置相应元素的值 lrange key start end 截取指定列表内元素 ltrim key start end 只保留开始和结束内的元素 集合 set数据池，无序，可计算差集交集等，之前写爬虫时用集合做过去重，Python使用redis也是非常方便的 命令 描述 sadd key member1 member2 向集合内添加元素 scard key 获取集合内元素数量 smembers key 获取集合内所有的元素 sismember key member 判断member是否是key集合的子元素 sdiff key1 key2 获取给定集合的差集 sinter key1 key2 获取给定集合的交集 sunion key1 key2 获取给定集合的并集 spop key 随机删除一个集合内元素并返回 srandmember key num 返回集合内的一个或者多个随机元素 srem key member1 member2 删除集合中一个或者多个指定元素 其他剩下的数据类型确实是没用过，这里不便多说 Laravel使用redis流程简单来说如下图所示 Laravel使用redis 程序将数据存储请求发送给Laravel内置的redis模块（PHPRedis，Predis等），并在config/database.php中配置好redis的端口密码等信息，通过内置模块调用已经安装好的redis即可使用redis存储使用数据了，然后redis内部处理数据我们如果不做底层的话，正常存储使用，只需要处理好程序与Laravel之间的过程就可以了，也就是说，了解PHPRedis和Predis就可以了，目前似乎大多数人使用的都是这两种，也不仅限于Laravel，原生PHP以及像Swoole这种的也是可以使用的。 关于Laravel中的Redis配置使用 可以参考 Laravel中文文档5.8 - redis 1234567// laravel 简单调用示例use Illuminate\\Support\\Facades\\Redis;class testRedis()&#123; Redis::set('username','风向标'); $username = Redis::get('username'); return $username;&#125; Laravel使用Redis集群仍然是在 config/database 中配置 clusters123456789101112131415161718192021222324252627282930313233'redis' =&gt; [ 'client' =&gt; env('REDIS_CLIENT', 'predis'), 'options' =&gt; [ 'cluster' =&gt; env('REDIS_CLUSTER', 'predis'), // 'cluster' =&gt; env('redis'), ], 'clusters' =&gt; [ 'vaneCache' =&gt; [ [ 'host' =&gt; env('REDIS_HOST', '127.0.0.1'), 'password' =&gt; env('REDIS_PASSWORD', null), 'port' =&gt; env('REDIS_PORT', 6379), 'database' =&gt; 1, ], [ 'host' =&gt; env('REDIS_HOST', '127.0.0.1'), 'password' =&gt; env('REDIS_PASSWORD', null), 'port' =&gt; env('REDIS_PORT', 6379), 'database' =&gt; 2, ], [ 'host' =&gt; env('REDIS_HOST', '127.0.0.1'), 'password' =&gt; env('REDIS_PASSWORD', null), 'port' =&gt; env('REDIS_PORT', 6379), 'database' =&gt; 3, ], ], ], ], 在使用时仅需要 使用 connection 即可 1234$redis1 = Redis::connection('vaneCache');$redis1-&gt;set('username','风向标');$username = $redis1-&gt;get('username');echo $username;","categories":[{"name":"PHP","slug":"PHP","permalink":"https://sbcoder.cn/categories/PHP/"}],"tags":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/tags/优化/"},{"name":"Redis","slug":"Redis","permalink":"https://sbcoder.cn/tags/Redis/"},{"name":"PHP","slug":"PHP","permalink":"https://sbcoder.cn/tags/PHP/"},{"name":"Laravel","slug":"Laravel","permalink":"https://sbcoder.cn/tags/Laravel/"}]},{"title":"tuwan（兔玩）全站妹子图爬虫可多窗口","slug":"tuwan全站妹子图爬虫可多窗口","date":"2019-05-13T15:01:00.000Z","updated":"2019-05-13T15:29:23.000Z","comments":true,"path":"2019/05/13/tuwan_spider.html","link":"","permalink":"https://sbcoder.cn/2019/05/13/tuwan_spider.html","excerpt":"","text":"前言兔玩是一个非常不错的妹子图网站，跟曾经的PR社有异曲同工之处，花少量的钱可以看Coser的图片，但是tuwan的妹子还是很正经的哟~兔玩官网 tuwanjun.com以下是网站截图 tuwan 兔玩的更新速度还是不错的呢~ 破解看到官网的套图打开后，一般是有几张可以看得图，也有一堆尺寸小的预览图，地址很相似，例如这张1http://img4.tuwandata.com/v3/thumb/jpg/YjAzYiwxNTgsMTU4LDksMywxLC0xLE5PTkUsLCw5MA==/u/GLDM9lMIBglnFv7YKftLBuvzpwYbEIoBh8ap84BsgXdniTdx80UqsXLdP5yaJZklUj09PvGO8IYpAC3nOanE0EHpB9bCnRKUnvdbAJH6CcXC.jpg YjAzYiwxNTgsMTU4LDksMywxLC0xLE5PTkUsLCw5MA==这一串很容易看的出是base64加密过的串，经过解密获得12base64.b64decode(imgurl)# b03b,158,158,9,3,1,-1,NONE,,,90 这里的158,158就是缩略图的尺寸了，我们尝试修改缩略图尺寸然后在base64加密后就可以取得地址，经过尝试，修改为 0，0即可还原原图尺寸~12base64.b64encode(base64.b64decode(imgurl.encode('utf-8')).replace('158','0'))# YjAzYiwwLDAsOSwzLDEsLTEsTk9ORSwsLDkw 组合成原图地址：1http://img4.tuwandata.com/v3/thumb/jpg/YjAzYiwwLDAsOSwzLDEsLTEsTk9ORSwsLDkw/u/GLDM9lMIBglnFv7YKftLBuvzpwYbEIoBh8ap84BsgXdniTdx80UqsXLdP5yaJZklUj09PvGO8IYpAC3nOanE0EHpB9bCnRKUnvdbAJH6CcXC.jpg 下载源代码已经开源到Github上了上一张测试图 测试图 下载地址：tuwan_spider","categories":[{"name":"Python","slug":"Python","permalink":"https://sbcoder.cn/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://sbcoder.cn/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://sbcoder.cn/tags/爬虫/"},{"name":"福利","slug":"福利","permalink":"https://sbcoder.cn/tags/福利/"}]},{"title":"Discuz会员数据与Wordpress互通","slug":"Discuz会员数据与Wordpress互通","date":"2019-04-11T12:06:06.000Z","updated":"2019-05-13T14:57:58.000Z","comments":true,"path":"2019/04/11/Discuz-Userinfo-To-Wordpress.html","link":"","permalink":"https://sbcoder.cn/2019/04/11/Discuz-Userinfo-To-Wordpress.html","excerpt":"","text":"情景这个情景可能遇到的也不在少数，不想舍弃用户数据，还想让用户无需注册在新站保留账号。实际当我们在迁移的时候，稍微了解数据库的同学应该明白想要迁移用户数据只需要迁移用户数据表即可。实际上我也是这么做的，但是中途遇到了几个小问题，这里我总结一下！ Discuz用户密码加密算法Discuz的用户信息都存放在 ‘pre_common_member‘ 表里，包含了我们需要转移的 邮箱,用户名,密码,积分,ip 等各类信息那么很简单了，便利这个表再插入到Wordpress表内即可但在导入表之前需要先测试一下用户数据是否匹配以示严谨~当我测试密码匹配的时候发现，这里的密码似乎并不匹配，首先我想到的就是应该是加盐了，但是纵观整个 ‘pre_common_member‘ 表，似乎并没有该有的字段网上找了一圈发现Discuz的用户真实密码是存在 ‘pre_ucenter_members‘ 表内的，’pre_common_member‘ 表内的密码我现在还不知道有什么用处，但至少跟我们需要迁移的数据没什么关联。从 ‘pre_ucenter_members‘ 表中找到了我们需要的 ‘salt‘ 字段，经过测试得出Discuz的密码加密算法为1md5(md5('password').'salt'); tips: Discuz里面的salt是一个6位的 数字+字母 随机数 Wordpress用户密码加密算法搞定了DZ的加密算法后，那么如何将DZ的用户信息插入到WP里面就很重要了，打开 Wordpress 的数据库找到 ‘wp-user‘表，找到 ‘user_pass‘ 字段，发现里面加密的内容似乎无迹可寻。实际上，Wordpress的加密是使用了 phpass 类来加密的，由 phpass 加密的密码具有不可逆性，所以想要破解是不可能了，这里简单说一下 phpass 的加密算法目前我们的PHP版本应该都在5以上，所以前缀是一样的 $P$B 大致写出来如下：12345$count = rand(1,8);$hash = md5($salt . $password, TRUE);while($count--)&#123; $hash = md5($hash . $password, TRUE);&#125; 看起来是不是很强，我们无法破解这样的密码，实际使用中，我们也可以使用 phpass 来做密码加密，让我们的数据库更加的安全~然而我们数据迁移时其实完全可以避免这种问题，Wordpress是保留了md5加密的形式的，如果 ‘user_pass‘ 字段里面存储的是md5加密的32值，wordpress也可以登录成功，并且再登陆后会将 ‘user_pass‘ 字段修改为 phpass 加密的格式，是不是很人性化呢。综上所述，我们无需解出来wordpress的加密算法，我们也解不出来~ 开始迁移用户数据关于迁移有很多细节，本来是打算写出来的，后来发现没什么技术含量，都是流水账，直接开源到github好了需要的朋友请直接点击 D2W - Github","categories":[{"name":"PHP","slug":"PHP","permalink":"https://sbcoder.cn/categories/PHP/"}],"tags":[{"name":"Discuz","slug":"Discuz","permalink":"https://sbcoder.cn/tags/Discuz/"},{"name":"Wordpress","slug":"Wordpress","permalink":"https://sbcoder.cn/tags/Wordpress/"}]},{"title":"192TT(192tb)套图吧整站爬虫","slug":"192TT-192tb-套图吧整站爬虫","date":"2019-03-28T08:15:16.000Z","updated":"2020-05-17T05:22:15.811Z","comments":true,"path":"2019/03/28/192tt_Spider.html","link":"","permalink":"https://sbcoder.cn/2019/03/28/192tt_Spider.html","excerpt":"","text":"观察目录结构目标网站：192tb.com网站结构复杂，但也不是太复杂，总体来说都写在导航栏上面了，本以为是new分类下就是所有的文章了，后来发现不是，需要遍历整个导航分类，由于每个分类都有很庞大的资源，因此我决定写成配置文件的形式，建立config.py 1234567891011121314# -*- coding: utf-8 -*-mt = 'https://www.192tb.com/listinfo-1-1.html' # 美图mt1 = 'https://www.192tb.com/meitu/xingganmeinv/' # 性感美女mt2 = 'https://www.192tb.com/meitu/siwameitui/' # 丝袜美腿mt3 = 'https://www.192tb.com/meitu/weimeixiezhen/' # 唯美写真mt4 = 'https://www.192tb.com/meitu/wangluomeinv/' # 网络美女mt5 = 'https://www.192tb.com/meitu/gaoqingmeinv/' # 高清美女mt6 = 'https://www.192tb.com/meitu/motemeinv/' # 模特美女mt7 = 'https://www.192tb.com/meitu/tiyumeinv/' # 体育美女mt8 = 'https://www.192tb.com/meitu/dongmanmeinv/' # 动漫美女mt9 = 'https://www.192tb.com/new/ugirlapp/' # 爱尤物APP/尤果网gc = 'https://www.192tb.com/gc/' # 国产gc1 = 'https://www.192tb.com/gc/bl/' # beautyleg1 顶级分类和二级分类不便多说，这里只是测试并没有收录所有的分类，有兴趣可以自己添加 进入分类页后既是套图封面，从这里可以爬取套图的链接，分类页的底部也是有下一页的选项，可以根据下一页来获取下一个分类页的链接，以此递归，并获取链接 获取到套图链接后发现每个单页面都是需要点击下一张图片来做的，单页面中的图片，使用BeautifulSoup即可轻松获取，由于不知道一套图里面有多少张，我这边使用递归的方式，走到最后一张，即退出递归。 核心代码获取单个套图并下载1234567891011121314151617def getSingleData(url,singleTitle,i = 1): response = requests.get(url) soup = BeautifulSoup(response.text,\"html.parser\") imgUrl = soup.find(id = 'p').find('center').find('img').get('lazysrc') print imgUrl try: j = i + 1 result = '_%s.html'%i in url if result: nextImg = response.url.replace('_%s.html'%i, '_%s.html'%j) else: nextImg = response.url.replace('.html', '_%s.html'%j) # print nextImg downImg(imgUrl,singleTitle,i) getSingleData(nextImg,j) except Exception,e: return 0 获取下一页页面信息123456789101112131415161718192021222324def getPage(url,new = 1,i = 1): print '开始采集第%s页'%i print url response = requests.get(url) soup = BeautifulSoup(response.text,\"html.parser\") for dataUrl in soup.find('div',&#123;'class':'piclist'&#125;).find('ul').find_all('li'): singleDataUrl = 'https://www.192tb.com/'+dataUrl.find('a').get('href') print singleDataUrl try: singleTitle = dataUrl.find('a').find('img').get('alt') except Exception,e: continue print singleTitle getSingleData(singleDataUrl,singleTitle) result = '_%s.html' % i in url j = i + 1 if new != 1: nextPageUrl = url.replace('listinfo-1-%s.html' % i, 'listinfo-1-%s.html' % j) else: if result: nextPageUrl = url.replace('index_%s.html' % i, 'index_%s.html' % j) else: nextPageUrl = url.replace(url, url+'/index_%s.html' % j) getPage(nextPageUrl,new,j) 演示及下载下载地址：Github 192tt演示图","categories":[{"name":"Python","slug":"Python","permalink":"https://sbcoder.cn/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://sbcoder.cn/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://sbcoder.cn/tags/爬虫/"},{"name":"福利","slug":"福利","permalink":"https://sbcoder.cn/tags/福利/"}]},{"title":"正则表达式应用，常用取值表（记录）","slug":"正则表达式应用，常用取值表（记录）","date":"2019-03-26T08:11:06.000Z","updated":"2019-03-27T03:50:12.000Z","comments":true,"path":"2019/03/26/Regex_match_note.html","link":"","permalink":"https://sbcoder.cn/2019/03/26/Regex_match_note.html","excerpt":"","text":"正则表达式 查询表 字符 描述 场景 \\ 转义 转义场景 \\ ^ 匹配输入字符串的开始位置。如果设置了 RegExp 对象的 Multiline 属性，^ 也匹配 ‘\\n’ 或 ‘\\r’ 之后的位置。 取a开头的字符串 ^a.* $ 匹配输入字符串的结束位置。如果设置了RegExp 对象的 Multiline 属性，$ 也匹配 ‘\\n’ 或 ‘\\r’ 之前的位置。 取a开头b结尾 ^a.*b$ * 匹配前面的子表达式零次或多次。 zo 能匹配 “z” 以及 “zoo”。 等价于{0,} + 匹配前面的子表达式一次或多次。 ‘zo+’ 能匹配 “zo” 以及 “zoo”，但不能匹配 “z”。+ 等价于 {1,} ? 匹配前面的子表达式零次或一次. “do(es)?” 可以匹配 “do” 或 “does” 中的”do” 。? 等价于 {0,1}。 {n} n 是一个非负整数。匹配确定的 n 次。 ‘o{2}’ 不能匹配 “Bob” 中的 ‘o’，但是能匹配 “food” 中的两个 o。 {n,} n 是一个非负整数。至少匹配n 次。 ‘o{2,}’ 不能匹配 “Bob” 中的 ‘o’，但能匹配 “foooood” 中的所有 o。’o{1,}’ 等价于 ‘o+’。’o{0,}’ 则等价于 ‘o*’ {n,m} m 和 n 均为非负整数，其中n &lt;= m。最少匹配 n 次且最多匹配 m 次。 “o{1,3}” 将匹配 “fooooood” 中的前三个 o。’o{0,1}’ 等价于 ‘o?’。请注意在逗号和两个数之间不能有空格。 ? 当 该字符紧跟在任何一个其他限制符 (*, +, ?, {n}, {n,}, {n,m}) 后面时，匹配模式是非贪婪的。 非贪婪模式尽可能少的匹配所搜索的字符串，而默认的贪婪模式则尽可能多的匹配所搜索的字符串。对于字符串 “oooo”，’o+?’ 将匹配单个 “o”，而 ‘o+’ 将匹配所有 ‘o’。 . 匹配除 “\\n” 之外的任何单个字符。 要匹配包括 ‘\\n’ 在内的任何字符，请使用象 ‘[.\\n]’ 的模式。 x&#124;y 匹配 x 或 y。 ‘z&#124;food’ 能匹配 “z” 或 “food”。’(z&#124;f)ood’ 则匹配 “zood” 或 “food”。 [xyz] 字符集合。匹配所包含的任意一个字符。 ‘[abc]’可以匹配 “plain” 中的 ‘a’。 [^xyz] 取反，匹配未包含的任意字符。 ‘?[^abc]’ 可以匹配 “plain” 中的’p’。 [a-z] 字符范围。匹配指定范围内的任意字符。 ‘[a-z]’ 可以匹配 ‘a’ 到 ‘z’ 范围内的任意小写字母字符。 \\b 匹配一个单词边界，也就是指单词和空格间的位置。 ‘er\\b’ 可以匹配”never” 中的 ‘er’，但不能匹配 “verb” 中的 ‘er’。 \\B 匹配非单词边界 ‘er\\B’ 能匹配 “verb” 中的 ‘er’，但不能匹配 “never” 中的 ‘er’。 \\cx 匹配由 x 指明的控制字符。 \\cM 匹配一个 Control-M 或回车符。x 的值必须为 A-Z 或 a-z 之一。否则，将 c 视为一个原义的 ‘c’ 字符。 \\d 匹配一个数字字符 等价于 [0-9]。 \\D 匹配一个非数字字符。 等价于 [^0-9]。 \\f 匹配一个换页符。 等价于 \\x0c 和 \\cL。 \\n 匹配一个换行符。 等价于 \\x0a 和 \\cJ。 \\r 匹配一个回车符。 等价于 \\x0d 和 \\cM。 \\s 匹配任何空白字符，包括空格、制表符、换页符等等。 等价于 [ \\f\\n\\r\\t\\v]。 \\S 匹配任何非空白字符。 等价于 [^ \\f\\n\\r\\t\\v]。 \\t 匹配一个制表符。 等价于 \\x09 和 \\cI。 \\v 匹配一个垂直制表符。 等价于 \\x0b 和 \\cK。 \\w 匹配包括下划线的任何单词字符。 等价于’[A-Za-z0-9_]’。 \\W 匹配任何非单词字符。 等价于 ‘[^A-Za-z0-9_]’。 \\xn 匹配十六进制数 ‘\\x41’ 匹配 “A”。’\\x041’ 则等价于 ‘\\x04’ &amp; “1”。正则表达式中可以使用 ASCII 编码。. \\num 匹配 一个正整数。对所获取的匹配的引用。 ‘(.)\\1’ 匹配两个连续的相同字符。 \\n 标识一个八进制转义值或一个向后引用。 如果 \\n 之前至少 n 个获取的子表达式，则 n 为向后引用。否则，如果 n 为八进制数字 (0-7)，则 n 为一个八进制转义值。 \\nm 标 识一个八进制转义值或一个向后引用。 如果 \\nm 之前至少有 nm 个获得子表达式，则 nm 为向后引用。如果 \\nm 之前至少有 n 个获取，则 n 为一个后跟文字 m 的向后引用。如果前面的条件都不满足，若 n 和 m 均为八进制数字 (0-7)，则 \\nm 将匹配八进制转义值 nm。 \\nml 匹配八进制数 如果 n 为八进制数字 (0-3)，且 m 和 l 均为八进制数字 (0-7)，则匹配八进制转义值 nml。 \\un 匹配 n，其中 n 是一个用四个十六进制数字表示的 Unicode 字符。 \\u00A9 匹配版权符号 。 常用案例演示123# -*- coding:utf-8 -*-import restr1 = 'ai0by123' 提取a开头的字符串1regexStr = \"^a.*\" 提取a开头b结尾字符串1regexStr = \"^a.*3$\" 提取最右边符合条件的值,贪婪1regexStr = \".*(a.*b).*\" # 贪婪，取a到b之间，右边开始取，取最右边符合条件的 提取最左边符合条件的值，非贪婪1regexStr = \".*?(a.*?b).*\" # 非贪婪，取a到b之间的值含a和b，从左往右只取一次 提取符合集合内的值，或运算1regexStr = \"((ai00000by|ai0by)123)\" # 或运算，符合其中一种即可 提取出生日期123456str1 = 'XXX 出生于2008年12月6日'str1 = 'XXX 出生于2008/12/6'str1 = 'XXX 出生于2008-12-6'str1 = 'XXX 出生于2008-12-06'str1 = 'XXX 出生于2008-12'regexStr = \".*出生于(\\d&#123;4&#125;[年/-]\\d&#123;1,2&#125;([月/-]\\d&#123;1,2&#125;|[月/-]$|$))\" 提取图片url,其他网站同理1234567str1 = '地址：https://www.ttbcdn.com/d/file/p/2018-02-17/g4edlvxmmyi9627.jpg'# 取整串地址regexStr = \".*https.*jpg$\"# 取XXX.jpg png gif 等regexStr = \".*/(.*.(jpg|gif|png))$\"# 取2018-02-17/g4edlvxmmyi9627.jpg png gif等regexStr = \".*/(\\d&#123;4&#125;-\\d&#123;2&#125;-\\d&#123;2&#125;/(.*.(jpg|gif|png)))$\" 收尾提取字符串12345reMatch = re.match(regexStr,str1)if reMatch: print (reMatch.group(1))else: print('No')","categories":[{"name":"note","slug":"note","permalink":"https://sbcoder.cn/categories/note/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"https://sbcoder.cn/tags/笔记/"},{"name":"正则表达式","slug":"正则表达式","permalink":"https://sbcoder.cn/tags/正则表达式/"}]},{"title":"博客迁移说明","slug":"博客迁移说明","date":"2019-03-25T05:12:58.000Z","updated":"2019-04-12T14:57:49.000Z","comments":true,"path":"2019/03/25/Hello_world.html","link":"","permalink":"https://sbcoder.cn/2019/03/25/Hello_world.html","excerpt":"","text":"关于迁移博客总是在起起伏伏，关了又开，开了又关中反复，这一次，我将风向标博客放在了Github Page上。程序采用了当下比较流行的静态博客程序 Hexo ，Hexo其实是一个非常好的程序，但由于我经常换电脑，以前用hexo搭建的博客数据丢失了很多次，后经过更换为Wordpress，Typecho之类的开源博客程序后，我又回到了 Hexo 的怀抱，可能是真的懒得折腾了，上了年纪？这次我将源代码都备份好了，应该会长期更新，有什么好的东西我应该会分享出来，主打原创~可能之前认识我的人也很少，但我这个域名还是很好记的，sb coder 也是一种自嘲吧，有想跟我交流技术或者有外包工作介绍给我的，我的微信与域名同号~多的不说了，我将尽我所能，一周至少写一篇文章，可能有时候晚上回家写一点，一天写一点，一周下来也能写不少，希望各位监督~ 关于我我是谁，职业是PHP，爱好Python，云服务器爱好者支付接口对接，可以定制各类免签约支付接口，微信支付宝，有想法的朋友可以联系我 Telegram : ai0by 承接业务支付相关业务，爬虫(几乎不要钱，练手)，PHP程序开发服务器环境配置，PHP程序修改，PHP BUG排查","categories":[],"tags":[{"name":"ai0by","slug":"ai0by","permalink":"https://sbcoder.cn/tags/ai0by/"}]},{"title":"岛国推特妹子图爬虫","slug":"岛国推特妹子图爬虫","date":"2019-03-22T03:54:58.000Z","updated":"2020-05-17T05:22:04.930Z","comments":true,"path":"2019/03/22/Japan_Twitter_Spider.html","link":"","permalink":"https://sbcoder.cn/2019/03/22/Japan_Twitter_Spider.html","excerpt":"","text":"LOC的大佬们分享了一个网站，收集了很多岛国的妹子图和她们的推特地址：岛国妹子推特推特不是很感兴趣，就爬一下图片好了~ 爬虫介绍爬虫环境： Python2.7.9 可更替为3，自行更替 BeautifulSoup4 requests 代码：12345678910111213141516171819202122232425262728293031323334# -*- coding: utf-8 -*-from bs4 import BeautifulSoupimport requestsimport urllib2import randomdef spy(url): req = urllib2.Request(url) req = urllib2.urlopen(req) page = req.read() soup = BeautifulSoup(page, \"html.parser\") for imgSoup in soup.find_all('div', &#123;\"class\": \"row\"&#125;): for i in imgSoup.find_all('div', &#123;'class': 'photo'&#125;): for j in i.find('div', &#123;'class': 'photo-link-outer'&#125;).find('a').find_all('img'): img = j.get(\"src\") print img str = random.sample('zyxwvutsrqponmlkjihgfedcba', 6) downImg(img, str) nexturl = soup.find('p',&#123;'class':'go-to-next-page'&#125;) nexturl = nexturl.find('a').get('href') pageurl = \"http://jigadori.fkoji.com\"+nexturl spy(pageurl)def downImg(img,m): try: r = requests.get(img) except Exception , e: print \"图片获取失败\" return with open('./img/good%s.jpg' % m, 'wb') as f: f.write(r.content)if __name__ == '__main__': url = \"http://jigadori.fkoji.com\" spy(url) 整体思路看一下，网页构造，发现首页底部有下一页标签，BeautifulSoup取Class取值递归获取下一页地址图片同上整体难度不高，有兴趣的可以拿这个网站练练手~ 演示截图 演示数据1 演示数据2","categories":[{"name":"Python","slug":"Python","permalink":"https://sbcoder.cn/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://sbcoder.cn/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://sbcoder.cn/tags/爬虫/"},{"name":"福利","slug":"福利","permalink":"https://sbcoder.cn/tags/福利/"}]}]}