{"meta":{"title":"风向标 | 分享与创造","subtitle":null,"description":null,"author":"ai0by","url":"https://sbcoder.cn","root":"/"},"pages":[{"title":"api","date":"2019-04-04T07:27:21.000Z","updated":"2020-08-08T06:24:20.338Z","comments":true,"path":"api/douyin.html","permalink":"https://sbcoder.cn/api/douyin.html","excerpt":"","text":"抖音直播api介绍打开APP直播界面，分享直播间链接，得到一串 https://v.douyin.com/JNUDPVo/ 类似地址提交 参数到 api 返回一个 json格式的直播流地址 参数说明以 GET/POST 的方式提交到：https://api.46wz.com/douyin.php 参数 数值类型 示例 是否必传 url String https://sbcoder.cn 是 返回值类型 : json 示例1&#123;\"hls_pull_url\":\"http://pull-hls-l1.douyincdn.com/stage/stream-683443806729404446/playlist.m3u8\",\"rtmp_pull_url\":\"http://pull-flv-l1.douyincdn.com/stage/stream-683443806729404446.flv\"&#125; 演示直接访问以下地址 1https://api.46wz.com/douyin.php?url=https://v.douyin.com/JNUDPVo/"},{"title":"api","date":"2019-04-03T02:17:31.000Z","updated":"2020-07-27T06:47:48.314Z","comments":true,"path":"api/index.html","permalink":"https://sbcoder.cn/api/index.html","excerpt":"","text":"风向标API合集 名称 作用 接口 微博图床api 远程图片上传到微博图床 https://sbcoder.cn/api/sinaImg.html 生成二维码 将地址转换为二维码图片 https://sbcoder.cn/api/qrcode.html 抖音直播流解析 解析直播流真实地址 https://sbcoder.cn/api/douyin.html 网易云音乐解析 解析网易云音乐真实地址 https://sbcoder.cn/api/neteasy.html 更多api请持续关注…"},{"title":"api","date":"2020-07-21T07:27:21.000Z","updated":"2020-08-08T06:24:32.954Z","comments":true,"path":"api/neteasy.html","permalink":"https://sbcoder.cn/api/neteasy.html","excerpt":"","text":"网易云音乐解析介绍使用URL或者音乐id解析出音乐真实地址，真实地址具有时效性，尽可能当时使用 参数说明以GET/POST的方式提交到：https://api.46wz.com/neteasy.php 参数 数值类型 示例 是否必传 url String https://music.163.com/song?id=1438116717&amp;userid=36276027 是 返回值类型 : json 演示直接访问以下地址 1https://api.46wz.com/neteasy.php?url=http://music.163.com/song?id=27506983&amp;userid=36276027 返回示例1&#123;\"src\":\"http://m10.music.126.net/20200727150722/407150eee50229ec961c8fcc076264dc/ymusic/4eaf/b0c1/5dfa/83c3b3868df7c381230b3df71beaff32.mp3\",\"code\":1,\"msg\":\"\\u6210\\u529f\"&#125; 教程参考 简单制作网易云音乐解析接口"},{"title":"api","date":"2019-04-04T07:27:21.000Z","updated":"2020-08-08T06:25:08.127Z","comments":true,"path":"api/sinaImg.html","permalink":"https://sbcoder.cn/api/sinaImg.html","excerpt":"","text":"微博图床-远程图片上传api（已失效）介绍我们在使用爬虫相关内容的时候，存放图片时往往会遇到图片尺寸过大，存储不方便等问题，这时候，存放在一个永久存储的云上面就很有必要，微博是一个不限流量，全球CDN的图床~微博也是有缺点的，他并不是一个易于管理的图床，仅限于存放图片但不能管理图片，如果希望使用可以管理的图床，可以参考使用自建图床，参考我的:0161 IMG 参数说明以GET的方式提交到：https://api.46wz.com/sinaimg/sinaImg.php 传递参数类型：GET POST 参数 数值类型 示例 是否必传 url String https://sbcoder.cn/img/avatar.jpg 是 返回参数类型 ： JSON 演示示例:1&#123;\"large\":\"http://ww2.sinaimg.cn/bmiddle/0062WdSely1g1p8mlciyrg30390120jl.gif\"&#125; PHP DEMO12345678910111213141516171819$data = array( 'url' =&gt; \"https://sbcoder.cn/img/avatar.jpg\", );echo curlPost(\"https://api.46wz.com/sinaimg/sinaImg.php\",$data);function curlPost($url,$res)&#123; $curl = curl_init(); curl_setopt($curl, CURLOPT_URL, $url); curl_setopt($curl, CURLOPT_SSL_VERIFYPEER, 0); curl_setopt($curl, CURLOPT_FOLLOWLOCATION, 1); curl_setopt($curl, CURLOPT_AUTOREFERER, 1); curl_setopt($curl, CURLOPT_POST, 1); curl_setopt($curl, CURLOPT_POSTFIELDS, http_build_query($res)); curl_setopt($curl, CURLOPT_TIMEOUT, 30); curl_setopt($curl, CURLOPT_HEADER, 0); curl_setopt($curl, CURLOPT_RETURNTRANSFER, 1); $result = curl_exec($curl); curl_close($curl); return $result;&#125;"},{"title":"api","date":"2019-04-04T07:27:21.000Z","updated":"2020-08-08T06:24:51.709Z","comments":true,"path":"api/qrcode.html","permalink":"https://sbcoder.cn/api/qrcode.html","excerpt":"","text":"二维码生成介绍使用场景很多，简单来讲，给我地址，我给你图，直接将地址放在img标签内即可~ 参数说明以GET的方式提交到：https://api.46wz.com/qrcode.php 参数 数值类型 示例 是否必传 url String https://sbcoder.cn 是 err String L (L,M,Q,H四种对应容错级别，不传默认L) 否 size String 7 (可以选择1~9999之间的值，对应不同大小，默认7) 否 logo String https://sbcoder.cn/img/avatar.jpg 否 返回值类型 : 直接返回图片 演示直接访问以下地址 12https://api.46wz.com/qrcode.php?url=https://sbcoder.cnhttps://api.46wz.com/qrcode.php?url=https://sbcoder.cn&amp;err=L&amp;size=7&amp;logo=https://sbcoder.cn/img/avatar.jpg 示例图片"},{"title":"categories","date":"2019-03-21T07:11:04.000Z","updated":"2019-03-21T07:11:32.000Z","comments":false,"path":"categories/index.html","permalink":"https://sbcoder.cn/categories/index.html","excerpt":"","text":""},{"title":"Links","date":"2019-04-22T12:14:24.000Z","updated":"2020-07-23T09:03:47.694Z","comments":true,"path":"custom/index.html","permalink":"https://sbcoder.cn/custom/index.html","excerpt":"","text":"我的朋友 - 排名不分先后 - songsong’s Blog - 猫爪导航🐱 - Huas Leung’s Blog 申请友情链接 直接在下面留言即可！ 要求： - 正规站点 - 博客类优先 - 技术类站点优先 本站链接格式 - 风向标博客 - https://sbcoder.cn"},{"title":"tags","date":"2019-03-21T05:14:24.000Z","updated":"2019-03-21T05:14:52.000Z","comments":false,"path":"tags/index.html","permalink":"https://sbcoder.cn/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"I/O 多路复用技术-epoll","slug":"I-O-多路复用技术-epoll","date":"2021-12-14T07:41:30.000Z","updated":"2021-12-16T08:06:12.792Z","comments":true,"path":"2021/12/14/Linux-IO-epoll.html","link":"","permalink":"https://sbcoder.cn/2021/12/14/Linux-IO-epoll.html","excerpt":"","text":"SocketLinux一切皆文件的概念，都可以用“打开open –&gt; 读写write/read –&gt; 关闭close”模式来操作。Socket就是该模式的一个实现，socket即是一种特殊的文件，一些socket函数就是对其进行的操作（读/写IO、打开、关闭），这些函数我们在后面进行介绍。 想要客户端和服务端在网络间通信则必须使用Socket，支持跨主机通信 在建立两端通信时，需要将客户端和服务端都创建一个Socket，像一条线通过Socket连接起两端主机，Socket创建时可以指定使用的网络协议，通常情况下是使用TCP 和UDP，而相对来说TCP的场景偏多一些 如何创建两端通信呢？首先，服务端调用 socket()函数，创建网络协议IPV4，传输协议为TCP 的Socket，接着调用 bind()函数给这个Socket绑定IP和端口，接着会调用 listen() 函数监听连接接入，通过 accept()函数等待连接连入，如无客户端连接则阻塞，客户端则在创建好 Socket 后调用 connect() 函数发起连接，指定服务端的IP及端口，然后通过TCP的三次握手后连接建立完成 这个连接过程中，监听和连接的Socket 实际上是两个Socket T9V5Uf.png 通过上图可以发现，Socket本质上与文件传输很接近，而Linux一切皆文件的概念，Socket本质上也是文件，而上面这种Socket通信，是最简单的一对一通信，当服务端未处理完一个客户端的网络I/O时则会阻塞，而这个时候其他客户端是无法连接的，只能等待 多进程模型基于上述的Socket阻塞传输I/O，衍生出了多进程模型，即为每个连接进来的客户端都分配一个进程去处理，阻塞也只阻塞当前进程，服务器主进程通过accept()监听客户端连接，当接收到连接后，调用系统fork()函数创建子进程，将父进程的一切内容复制到子进程中，这种复制更像是一种指针，通过子进程来继续与客户端通信，待子进程处理完后再返回给父进程，通过不同的返回值，子进程为 0。 T9eyXd.png 这种做法很容易出现垃圾无法回收的问题，子进程无法销毁，因此父进程可以调用wait()和waitpid()来回收子进程 这种多进程模型的缺点在于，不断地fork子进程会造成大量的进程间上下文切换，而且进程并不足够轻量，每次创建进程则也需要创建对应的 堆栈.寄存器等一系列资源 多线程模型通过上面的多进程模型理念可以看出，不够轻量会导致更多的负载，那么后续又衍生出了多线程模型的概念，既然进程不满足那么就从多线程去下手 通过线程池的概念，连接连接进来时，将已连接的Socket塞到Socket等待队列中，另一边从线程池不断地取出已连接的Socket，然后创建线程交给线程去处理 T9Ju7D.png 结合之前的文章，实际应用中，每个创建的线程创建后都需要加锁，避免资源竞争问题 而这种多线程的做法很大程度上提高了一些效率，也减少了上下文切换的资源消耗问题，但是当数量很大的请求过来时，维护一个超大数量的线程池，或者说给线程池加上限，这并不是一个很好的做法，而维护也更麻烦，调度可能就会宕机，调度宕机也就面临着不可预测的问题。 I/O多路复用多路复用的概念则是从源头出发，这种一对一的方式显然不是最好的，那么就衍生出了 一个进程/线程 对应多个Socket的技术 一个进程同时只能处理一个Socket，但是如果将这个任务时间控制到毫秒微妙级时，将多个Socket都指向同一个进程则是多路复用，他与CPU的并发模型很接近，也被称为时分多路复用 I/O 复用其实复用的不是 I/O 连接，而是复用线程，让一个 thread of control 能够处理多个连接（I/O 事件） T9YOs0.png select将已连接的Socket放到一个文件描述集合(类指针)中，调用select函数将集合拷贝到内核中，内核遍历其中的Socket是否有事件产生，然后将其标记为可读,可写标识，将改过的集合送回用户态，然后用户态则继续遍历找到可读,可写的Socket对其处理 select使用bitsmap标识文件描述集合，所支持的描述符个数有限制，在Linux中的FD_SETSIZE限制，默认最大值是1024，因此只能监听0~1023个文件描述符 pollpoll与select很接近，只是不采用bitsmap存储，改用了链表，解除了限制 但由于结构未变，因此poll与select都有遍历两次循环的问题，且都需要复制两次集合的操作 epollepoll的诞生就是为了解决select/poll留下的问题，且目前epoll的应用场景也很多 关于存储文件描述符，epoll使用红黑树来跟踪进程所有待检测的文件描述符，将需要监控的 Socket 使用 epoll_ctl() 函数将其加入至内核中的红黑树中，这样检查 Socket 是否有事件发生则只需要传入一个待检测的 Socket 即可，不需要整个集合复制，减少了多次数据拷贝的问题 epoll 使用事件驱动，内核中维护一个链表来记录就绪事件，当 Socket 发生了事件时，内核会将其加入这个链表中，用户调用 epoll_wait() 时，只返回链表（事件发生的个数）即可，不需要整个集合返回 T9aLhF.png 水平触发 实则上面的 select/poll/epoll 都支持水平触发，当Socket有可读事件发生时，服务端不断地苏醒，直到read函数执行完才停止 边缘触发 epoll独有的边缘触发，当 Socket 有可读事件发生时，服务端从 epoll_wait 中苏醒，并执行read读取数据，由于他只苏醒一次的概念，因此我们在读取时要一次性将数据读完 边缘触发是循环从文件描述符读写数据，那么如果文件描述符是阻塞的，没有数据可读写时，进程会阻塞在读写函数那里，程序就没办法继续往下执行。所以，边缘触发模式一般和非阻塞 I/O 搭配使用，程序会一直执行 I/O 操作，直到系统调用(如 read 和 write)返回错误，错误类型为 EAGAIN 或 EWOULDBLOCK 结语多路复用 API 返回的事件并不一定可读写的，因此使用多路复用时最好配合 非阻塞 I/O一起使用，应对特殊情况","categories":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/categories/优化/"}],"tags":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/tags/优化/"}]},{"title":"一文搞懂Linux I/O流","slug":"一文搞懂LinuxIO流","date":"2021-12-13T03:29:48.000Z","updated":"2021-12-14T07:40:15.557Z","comments":true,"path":"2021/12/13/One-Linux-IO.html","link":"","permalink":"https://sbcoder.cn/2021/12/13/One-Linux-IO.html","excerpt":"","text":"Linux中的I/O操作缓冲与非缓冲 I/O 缓冲 I/O，利用的是标准库的缓存实现文件的加速访问，而标准库再通过系统调用访问文件。 非缓冲 I/O，直接通过系统调用访问文件，不经过标准库缓存。 程序在读写操作时系统并不会立刻返回数据或者处理数据，系统会监听操作并存储在缓冲区，例如C中的 Scanf 操作，只有在用户敲下了回车时才能真正将输入的字符写入，而输入的过程中可能有删除有追加，他们都是存储在缓冲区的 而非缓冲则是使程序直接访问文件系统，直接读取文件内容 直接与非直接I/O「是否利用操作系统的缓存」，可以把文件 I/O 分为直接 I/O 与非直接 I/O 在操作文件时 可以使用参数O_DIRECT来指定是否需要直接I/O，如果有此参数则说明不需要走操作系统缓存IO 他与缓冲I/O不同在于，一个是操作系统缓存，一个是标准库缓存 例如在Go语言中，利用Go的StringBuffer，可以先将待写入的文件存入系统缓存中，待到调用 write 时才真正的写入到文件中 阻塞I/O与异步I/O用户在发起I/O请求时，内核态会阻塞该线程，直到内核态准备好数据将数据移到程序的缓冲区阻塞才会解除 ojr1Fe.png 而非阻塞I/O是在请求后立即返回，如果没有得到结果则反复请求的过程 ojsFnP.png 如果设置了 O_NONBLOCK 标志，那么就表示使用的是非阻塞 I/O 的 方式访问，而不做任何设置的话，默认是阻塞 I/O。 这种I/O轮询的方式会拖慢整个线程的速度，因此I/O多路复用就出现了 而I/O多路复用也是基于非阻塞I/O的衍生，实际上IO多路复用也是从内核态阻塞线程变更到内核态阻塞，当数据准备好后再通知线程，这样做的好处是可以将CPU的利用率达到更高 而实际上上面所说的阻塞 非阻塞 基于非阻塞的I/O多路复用实际上本质都是同步I/O 而异步I/O则是在内核态阻塞后立即返回，当数据处理好后再通知线程 文件DMA在DMA技术没有应用时，I/O的过程是这样的 ovkTdH.png 当接收到程序发送的 I/O 请求时，CPU会直接阻塞住，处理数据，等待I/O处理完成后才能继续执行任务 DMA则是在这之中起到了一个中间价的作用，当CPU接收到请求时，会把任务扔给DMA就去做别的事去了，DMA将处理请求给磁盘，磁盘将缓冲区数据拷贝到内核缓冲区，当DMA读取到了足够的数据会给CPU发送中断信号，CPU接收到信号后将内核缓冲区数据返回给用户态，返回数据 文件传输socket传输Socket是一种可以远程可以本地传输的套接字，可以理解为一个接口，他的应用场景非常多，可以连接应用程序，可以连接网络层，websocket也正是借鉴了socket的特性开发出的一种协议 实际应用中，我们也是使用socket作为文件传输工具，也可以说，很多I/O操作也都是使用了Socket来操作的，而我们文件传输则需要socket来作为连接网卡的接口来使用 mmap文件拷贝时，相当于 先 read 再 write 应用发起read操作时，应用调用 mmap() 可以将内核缓冲区的数据映射到用户缓冲区里面 当应用调用 mmap()时，DMA会将磁盘的数据拷贝到内核缓冲区，然后将应用进程及内核共享此内容，然后调用write，操作系统将内核缓冲区的内容拷贝到Socket缓冲区，最后把Socket缓冲区的内容拷贝到网卡缓冲区，整个过程都是由DMA操作的 sendfile（零拷贝）在 Linux 内核版本 2.1 中，提供了一个专⻔发送文件的系统调用函数 sendfile() ，函数形式如下 12#include &lt;sys/socket.h&gt;ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count); 它的前两个参数分别是目的端和源端的文件描述符，后面两个参数是源端的偏移量和复制数据的⻓度，返回值是实际复制数据的⻓度，通过sendfile调用来发送数据，则可以替代 read + write 的操作，这样就只调用一次文件拷贝，减少了上下文开销且该方法类似mmap可以直接跳过用户态将内核态数据复制到 socket缓冲区 而网卡如果支持SG-DMA技术的话则可以在此基础上更近一步，跳过socket缓冲区直接将数据发送到网卡缓冲区 通过以下命令查看是否支持 1ethtool -k eth0 | grep scatter-gather 在 Linux 2.4之后的版本，通过调用sendfile()来实现复制，如果网卡支持SG-DMA则复制文件则会产生如下操作 第一步，通过 DMA 将磁盘上的数据拷⻉到内核缓冲区里; 第二步，缓冲区描述符和数据⻓度传到 socket 缓冲区，这样网卡的 SG-DMA 控制器就可以直接将内 核缓存中的数据拷⻉到网卡的缓冲区里，此过程不需要将数据从操作系统内核缓冲区拷⻉到 socket 缓冲区中，这样就减少了一次数据拷⻉; ovu7GQ.png 这就是所谓的零拷⻉(Zero-copy)技术，因为我们没有在内存层面去拷⻉数据，也就是说全程没有通过 CPU 来搬运数据，所有的数据都是通过 DMA 来进行传输的，总体来看，零拷⻉技术可以把文件传输的性能提高至少一倍以上 类似零拷贝技术的应用场景有很多，例如 ： kafka内部使用的transferTo()实际上就是调用 sendfile nginx通过配置可以选择是否开启sendfile 12345http &#123; ... sendfile on ...&#125; 大文件传输大文件传输很少使用同步传输，由于文件的不可确定性，小文件更适合使用同步传输，大文件由于占用时间过长，如果一直等待的情况下，会让CPU一直阻塞，因此大文件通常使用 异步 I/O + 直接 I/O来替代零拷贝技术 nginx中则可以使用 如下配置 123456location /sbcoder.cn/ &#123; sendfile on; aio on; directio 1024m;&#125;","categories":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/categories/优化/"}],"tags":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/tags/优化/"}]},{"title":"多线程中的资源竞争","slug":"多线程中的资源竞争","date":"2021-12-06T05:54:50.000Z","updated":"2021-12-07T02:37:21.882Z","comments":true,"path":"2021/12/06/Process-Thread-Competition.html","link":"","permalink":"https://sbcoder.cn/2021/12/06/Process-Thread-Competition.html","excerpt":"","text":"资源竞争问题当我们有两个线程同时操作同一块儿内存空间时，就容易出现资源竞争问题，这种问题目前有各种各样的出现情况，但在分布式系统中，或者说多线程任务中都是需要处理的 多线程是线程阻塞通过调度器去协调处理的，那么按理说即使是多线程实际上也都是串行操作，为什么也会出现资源竞争呢？ 如下图 osnXcQ.png 当进入线程操作时，会先把变量存的值存入寄存器，待到处理完后在重新放回i的所属内存空间，那么当在放回内存时就有可能覆盖掉上一个线程操作的值，也就出现了资源竞争 解决策略互斥由于多线程执行操作共享变量的这段代码可能会导致竞争状态，因此我们将此段代码称为临界区(critical section)，它是访问共享资源的代码片段，一定不能给多线程同时执行。我们希望这段代码是互斥(mutualexclusion)的，也就说保证一个线程在临界区执行时，其他线程应该 被阻止进入临界区，说白了，就是这段代码执行过程中，最多只能出现一个线程。 osKHSS.png 这种行为也被称为 互斥，通过阻塞完成 同步另外还有一种Go语言中常用的操作是 同步，当任务一和任务二同时执行时，任务二的某处任务需要等到等到任务一执行完得到的数据才能继续执行任务二，相当于Go中的信道阻塞select，只有取到数据才执行否则就一直阻塞 原子操作与锁原子操作，类似于事务，原子操作就是要么全部执行，要么都不执行，不能出现执行到一半的中间状态 锁的概念与进程资源锁一样，进程中通过信号判断是否可以执行，而在线程中，可以通过代码来处理 声明一个变量存储 0 1 为占用状态，为 0 时进入等待队列，使用while循环等待，直到为1时才可执行，这只是一种最简单的锁 信号量信号量则是一个类似线程池的概念，通过信号量控制线程数，当一个方法被多个线程调用时，每个线程进入方法时就增加信号量的值，直到一个负荷后阻塞后来的线程进入等待队列，当信号量发生变更时再决定是否要让新的线程进入 而信号量同样可以适用于更丰富的场景，当程序需要同时执行两块儿代码段时，那就需要占两个锁，而进入第一个锁时，另外的程序占用了第二块儿程序，就无法出现同时占两个锁的情况，也有可能造成同时的阻塞，通过信号量则可以处理此类问题，将程序1加入信号量，程序2也加入信号量，当信号量为2时可以执行两个程序，如果线程1占用了一个锁，那么线程2看到自己没有抢到锁且信号量为1则直接进入等待队列，线程1则继续拿第二个锁，程序执行完时释放加回信号量即可 读写问题「读-读」允许:同一时刻，允许多个读者同时读「读-写」互斥:没有写者时读者才能读，没有读者时写者才能写「写-写」互斥:没有其他写者时，写者才能写 通过信号量来处理读写问题，所有的操作都存储于队列，当写操作开始时，所有其他任务都终止。即当写操作的信号量为0时才可以进行读操作，读操作信号量不为0时写操作不允许执行，所有任务以队列形式进入，因此，此为公平的读写操作 锁的安全性deadlock死锁，一个生产环境上最为可怕的错误之一，他的形成原因大概可以被解释为，程序1和程序2都在等待对方结束才可执行，结果造成了无限期的等待，程序就此卡死，典型的死锁场景 死锁一般长出现于并发线程场景，满足如下条件时会发生 互斥条件，互相等待对方结束后才可继续执行，一次两个或多个线程同时阻塞 持有并等待条件，持有资源一后需要拿到资源二的时候发生，不释放资源一（参照哲学家就餐的问题，可以按照规定顺序拿资源解决，按场景使用信号量解决） 不可剥夺条件，当线程A持有资源时，必须等到线程A结束时线程B才可获取 环路等待条件，两个线程获取的资源形成环形链，死循环造成死锁 在Go语言中可以使用pprof来跟踪堆栈获取死锁行为的信息 死锁解决策略所有的资源全部按顺序获取，例如强制线程来的时候先拿A资源再拿B资源，当A信号量不足时线程阻塞等待，直到 A，B资源同时被上一个线程拿到后再释放信号量 这么做的目的是为了资源的合理分配，而这种情况也会导致资源的缓慢阻塞问题，要最大化的利用则可以根据场景去制定更好的合理化资源分配方案 自旋锁还是互斥锁简单来说，互斥锁是通过内核态由CPU调度处理的锁，当程序没有拿到锁的时候会直接释放CPU，进入睡眠等待，也就是上下文切换，等到拿到锁的时候再唤醒 自旋锁是发生于用户态的锁，由用户程序控制，通俗地讲使用while去轮询获取锁，也算是阻塞等待了，这种操作在Go语言中还挺常见的（所以我总是认为Go的设计理念很大部分都是基于用户态的），CPU提供了PAUSE函数去等待获取锁，相对于while他可以有效减少耗电量，自旋锁可以通过CPU去加锁，CPU提供了CAS函数来加锁，也可以用户自定义锁的方式来做 是否有必要读优先或者写优先字面意思，读优先是，不管什么情况下，读写锁，只要有读操作的线程加入，那么写就要向后排，直到所有的读操作结束写操作才能结束，而写优先则反之 这种情况可以有效地解决一些并发场景，但一昧的单条优先行为，可能会导致 读或者写长期阻塞（饥饿），这并不是开发者愿意看到的，所以使用这种读写优先锁，还是要谨慎 悲观锁和乐观锁首先，为了安全性稳定性，我们上述的所有操作都属于悲观锁 乐观锁是什么呢？它的工作方式是，先修改完共享资源，再验证这段时间内 有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作，释放寄存器。 反之悲观锁是只要占用上就不能继续操作 但某些场景下，为了效率，有的人也推荐使用乐观锁 例如在线文档，如果使用悲观锁，那么有人进入文档操作时，剩下的人都得等待，直到编写完成后才能查看或写入，使用乐观锁则可以通过数据判断修改内容，达成在线多人文档的需求 我们常用的Git和Svn等常见的版本控制工具也都是借鉴了这种想法思路","categories":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/categories/优化/"}],"tags":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/tags/优化/"}]},{"title":"进程与线程,概念及优化空间","slug":"进程与线程与协程-协程GMP调度","date":"2021-12-01T02:36:57.000Z","updated":"2021-12-03T09:18:25.051Z","comments":true,"path":"2021/12/01/Process-Thread-Optimization.html","link":"","permalink":"https://sbcoder.cn/2021/12/01/Process-Thread-Optimization.html","excerpt":"","text":"本文以Go语言为基础 进程基本概念将编译好的的二进制程序，在系统中执行起来的程序会被CPU装载到内存中，CPU会按照程序的指令去顺序执行程序，这个执行中的程序被称之为进程，多个程序同时执行则被称为多进程 单核CPU在执行任务过程中不能同时执行多余的任务，但是我们在实际场景中往往可以看到一台电脑有非常多的进程在运行，这就引出了进程的中断，当程序在读写硬盘这种慢IO操作时，当前进程会发出中断指令，使得CPU去执行下一个进程，防止了阻塞等待的问题，而CPU的执行效率是非常快的，所以更多时候即使他是串行执行程序，但也可以完美接收并发任务 o8RNHH.png 值得注意的是，并发和并行并非一样的东西，并发是代表一个CPU核心同时处理多个任务的情况，而并行是多个CPU核心处理多个任务 o8RSBQ.png 当进程中有大量硬盘IO操作时，将会出现大量的进程阻塞行为，而这种情况可能会占用大量的物理内存，在虚拟内存中，则会将这种阻塞的进程物理内存地址转移至硬盘地址，直至阻塞结束后再替换回物理内存中 而这种进程的执行过程也可以分为 创建、终止、阻塞、唤醒 的过程 线程基本概念一个进程可以有一个或多个线程 个人认为 ~ 线程是进程的抽象化，当一个进程只有一个线程时，那么这个线程就是进程 线程与进程，进程容纳了所有的资源，内存文件及各种单位，线程则只有寄存器和栈，线程与进程相同，同样有 阻塞和唤醒。 线程只有寄存器和栈的特性，以至于创建一个线程比创建进程更方便快捷，占用资源更少，当然前提是这些线程之间的共享资源大部分相同 进程占用资源，线程执行过程，线程都是依托于进程的，线程之间可以共享进程的资源 三种形式 用户线程 （User Thread） 内核线程 （Kennel Thread） 轻量线程 （LightWeight Thread） 首先要明确一个事实，他们并不是同一个维度的，多个用户线程对应多个内核线程，也就是他们是多对多的关系（协程则相当于一个内核线程对应了多个用户线程） oG86l6.png 通常我们常说的线程大部分指的是内核线程 ~ 用户线程是由用户发起的调用，操作系统无法干预，当用户线程执行过程中，操作系统无法查看当前线程的情况也无法由操作系统关闭，即任务管理器也没用（协程则可以通过 pprof 之类的debug工具去测试） 用户线程相当于用户自发开启的线程，不通过系统内核，也可以认为启动用户线程的速度要比内核线程要快的多，也因为如此，即使是不支持线程的系统，也能由用户自发开启的线程来开启用户线程无需兼容内核 内核线程则是通过操作系统调用的，可以通过操作系统去管理该线程，相比于用户线程，内核线程的资源分配更加合理，且用户线程可能会因为阻塞导致多个线程同时阻塞，而内核线程的调度则由操作系统直接完成，无需考虑这一问题，但相比于用户线程，显然内核线程要更重量级一些 轻量线程有多重解释，它相当于内核线程与用户线程的对应和结合，相当于用户线程与内核线程的桥梁或者中间层，与用户线程也是，多对多的关系，兼容三种模式 1:1 N:1 N:N 1:1 一个用户线程 对应一个轻量线程 对应一个内核线程N:1 多个用户线程对应一个轻量线程 对应一个内核线程N:N 混合模式，前面两种方式的结合，多个用户线程对应多个轻量线程，由轻量线程找到内核线程一一对应 调度调度模型进程调度，当出现IO请求的时候，调度会将当前执行的进程切换到另一个进程，并保留上下文，以便于稍后切换回来时能够继续执行之前的进程 进程调度，当出现长时间占用CPU的进程时，造成系统吞吐量降低，调度会权衡任务完成数量 如果一个进程本身计算不复杂，而占用时间长时，需要考虑是否是IO的调用导致的，频繁的IO请求会增加CPU的进程切换，也会加大程序的执行时长 调度对于鼠标键盘等需要实时响应的程序会优先考虑 进程如果处于就绪状态，调度会尽快让进程继续执行 进程之间会通过内核的时间分片去模拟出并发场景，当单核CPU出现三个进程时，如果都没有阻塞，则调度会通过时间分片的方式先完成简单的程序然后再完成复杂程序，ABC三个进程同时存在时，按照进程顺序， A B C，内核会分配一个固定时间分片，例如 5ns，A执行5ns后执行B，B执行5ns后执行C，假设进程B执行完成时，则调度会继续A C之间的循环，B完成后执行C，C执行5ns后执行A，然后循环执行A C 如上操作会出现一个问题就是内核会频繁的切换进程，我们知道上下文也是消耗资源的，那么内核会做一个递增时间分片的操作，例如一开始是5ns，后续可能就递增为 10ns 15ns，以便于尽早完成一个进程减少进程上下文 oaUUtx.png 通信管道在Linux中我们常用的通信管道，|，如下命令中 ps -ef |grep sbcoder ，里面的符号位 | 就是一个管道，他代表将前一个进程中的数据带到下一个进程中 这种没有命名的管道被称之为 匿名管道，匿名管道将在进程结束后释放，有匿名则也有有名字的管道 命名管道 ，Linux中通过关键字 mkfifo 创建命名管道 mkfifo sbcoderChannel，通过命令可以将数据传输至管道中，echo &quot;sbcoder&quot; &gt; sbcoderChannel，接着命令就卡住了，这与Go语言中的信道很类似，有阻塞的作用通过阻塞我们可以做很多事情，有入则有出，可以通过命令取出数据 cat &lt; sbcoderChannel 获取刚才echo进去的数据 管道实际上是内核中的缓存，而读取管道数据则是在一个进程中fork出一个子进程去读取，而如果由一个进程同事负责读写则会非常混乱，所以如果需要双向通信则需要fork两个子进程，而创建子进程也会徒增负荷，也要尽可能避免此类操作 oa1uHf.png 消息队列消息队列是保存在内核中的消息链表，由于消息队列的特性，会出现通信不及时和大小限制问题，更适合小数据的场景 共享内存进程A与进程B都使用虚拟内存（只保存物理地址），则可以实现同一个数据块儿被两个进程同时使用 oa38IO.png 当A和B同时操作一块儿内存时，则也会出现问题，很容易造成数据冲突，就出现了lock的概念，也被称为 信号量，A操作时将信号量数值更改，B同时操作时发现数值已经被更改则说明资源被占用，进程阻塞，A在操作完成后会将信号量数值再改回去，B此时即可继续执行 oa89YD.png 信号Signal 信号，也就是Signal，通过进程中的各种指令做通信，例如：程序接收到快捷键 ctrl + c 则会终止程序 Go语言中的Signal同理~ socket 不同主机之间的socket通信，为了方便不同主机之间的进程通信，衍生出的通信方式，他可以借助 TCP以及UDP以及本地进程等方式通信，其中TCP和UDP更适用于远程主机通信，而本地通信可以借助本地进程通信（字节流，数据报） 思考 高并发场景是否应该频繁读取硬盘信息呢 个人感觉可以通过一个大文本读取至内存，然后并发处理的过程中将会很少产生阻塞行为，但也属于物理内存充足的情况下（空间换时间） 如何更好的利用进程特性处理高并发任务 我们了解并发实际也是自上至下的串行执行程序，那么也要适当地减少并发任务的复杂度和频繁的IO操作，但合理运用内存很重要，如果能计算出什么时间内物理内存的占用情况则更合理一些 单内核多进程调度场景，如何设计更适合的程序结构 个人认为，应该尽可能减少进程数量，在用户态之间搞定，类似Go的GMP调度，如果进程数量实在无法减少可以尝试将某些轻量级程序减负，让重量级的程序保持，多应用消息队列的方式进行通信（过多使用消息队列也是负担），需要综合考量异步的优缺点","categories":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/categories/优化/"}],"tags":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/tags/优化/"}]},{"title":"物理内存与虚拟内存与Swap内存","slug":"物理内存与虚拟内存与Swap内存","date":"2021-11-30T03:48:38.000Z","updated":"2021-11-30T06:15:05.061Z","comments":true,"path":"2021/11/30/Memory-Optimization.html","link":"","permalink":"https://sbcoder.cn/2021/11/30/Memory-Optimization.html","excerpt":"","text":"区别物理内存物理内存是真实的内存空间，通过物理内存地址，标记存储的数据，物理内存的实际大小也与内存条有关，由内核直接调用使用 虚拟内存虚拟内存是物理内存的映射关系，为了防止程序开辟不同的物理内存空间，或者多处占用，则由操作系统去调度，使得进程在调用使用内存时需要通过虚拟内存的映射找到对应的物理内存地址，最终才能使用存储数据 如下图所示 olRoWT.png Swap内存空间Swap内存空间，顾名思义就是交换内存的空间，它的空间是硬盘空间，他是一个很有意思的东西，我们真实的内存空间存储时也是分一段一段去存储的，由于无法连续，那么可能也就无法让性能最大化 例如下图 olWiOH.png 游戏，浏览器及音乐各占不同的内存空间，当浏览器进程退出时，操作系统会回收内存空间，但由于它是一段一段存储的，导致后来的程序想要占用200M的内存空间则无法实现，最多只能使用128M。 而交换空间则应运而生，程序在发生浏览器退出时，会将后面的音乐占用内存放到交换空间中，而后清空游戏后面的内存，再将音乐内存直接放到游戏内存后面，而后面的下一个程序则可以直接占用内存200m 所以交换空间配置适量的大小也很重要，太大没意义，太小则可能无法满足释放内存的需求，而由于交换空间是硬盘空间，速度显然不是很友好，因此相当大的程序释放（放入）时也许会造成程序卡顿。 而这种分段的片段，也可以称之为内存分段 由于内存分段的数量过于庞大，他需要每次程序释放时同时释放内存碎片，为了更好地释放内存，物理内存存储的也是映射关系，也称之为 内存分页，相当于一个索引，一个内存分页存储着不同内存分段的物理地址，而程序只需要通过内存分页即可找到真实的内存数据，由于现实场景中，进程数量的激增，一层分页也无法满足所有，需要每个进程都保存一份分页不太现实，就出现了多级分页，只存储顶级分页及常用的二级分页 olj5DI.png 总结来说 Swap是硬盘空间，速度较差，它存储的进程数据一般是交换空间数据或者不活跃的进程数据 总结为了在多进程环境下，使得进程之间的内存地址不受影响，相互隔离，于是操作系统就为每个进程独立分 配一套虚拟地址空间，每个程序只关心自己的虚拟地址就可以，实际上大家的虚拟地址都是一样的，但分 布到物理地址内存是不一样的。作为程序，也不用关心物理地址的事情。 每个进程都有自己的虚拟(内存)空间，而物理内存只有一个，所以当启用了大量的进程，物理内存必然会很紧 张，于是操作系统会通过内存交换技术，把不常使用的内存暂时存放到硬盘(换出)，在需要的时候再装 载回物理内存(换入)。 划分空间C语言中的空间划分C语言有着各式各样的内存清理问题，这也是各种C语言BUG的大头 o1pdmj.png C语言中，动态分配的内存（malloc，mmap）则是动态分配堆和文件的内存 参考 小林Coding（图解系统） 近期写一写感谢大佬的电子图书笔记，小白受益良多","categories":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/categories/优化/"}],"tags":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/tags/优化/"}]},{"title":"利用CPU的特性开发更高效的代码","slug":"利用CPU-Cache的特性开发更高效的代码","date":"2021-11-29T08:31:34.000Z","updated":"2021-11-30T01:35:29.251Z","comments":true,"path":"2021/11/29/CPU-Cache-Optimization.html","link":"","permalink":"https://sbcoder.cn/2021/11/29/CPU-Cache-Optimization.html","excerpt":"","text":"CPU Cache是什么CPU Cache是在内存的基础上，可以被CPU直接读取的缓存，分为 L1,L2,L3 三层缓存级别，他的读取速度，是内存的100倍以上，我们都知道基于内存的数据库Redis，仅仅是使用了内存存储就很快了，CPU Cache则更快，利用好CPU Cache则可以让你编写的程序更快。 相比较各类IO操作，CPU Cache则是最底层的，分级一般为 L1 Cache &gt; L2 Cache &gt; L3 Cache &gt; MEM &gt; SSD &gt; HDD，按照现在市场上面的定价，相对应的价格也是梯形下降 相对于CPU Cache昂贵的价格，带来的收益自然也要更高，可以通过如下命令查看所在机器的CPU Cache分别是多少，从而更有利于优化代码 1234567891011# 获取L1 数据缓存大小cat /sys/devices/system/cpu/cpu0/cache/index0/size# 获取L1 指令缓存大小cat /sys/devices/system/cpu/cpu0/cache/index1/size# 获取L2 Cache 大小cat /sys/devices/system/cpu/cpu0/cache/index2/size# 获取L3 Cache 大小cat /sys/devices/system/cpu/cpu0/cache/index3/size 一般来说 L3 的容量 &gt; L2 &gt; L1数据 = L1指令 oMLjgI.png 越靠近 CPU 核心的缓存其访问速度越快，CPU 访问 L1 Cache 只需要 2~4 个时钟周期，访问 L2 Cache 大约 10~20 个时钟周期，访问 L3 Cache 大约 20~60 个时钟周期，而访问内存速度大概在 200~300 个 时钟周期之间。 时钟周期是CPU主频的倒数，例如 2GHZ主频的CPU，一个时钟周期是 0.5ns CPU Cache LineCPU Cache Line 是每次CPU载入缓存的大小，CPU在读取缓存信息时并非是一次一字节读取而是每次读一个固定字节长度的数据 1cat /sys/devices/system/cpu/cpu0/cache/index0/coherency_line_size oMOIRs.png 由于他每次是读一块儿数据，那么我们在编写代码时则可以避免多次读取内存，可以将数据内容压缩到64位以内，避免重复读 当我们在使用数组时，例如一个 数据 A 长度 65，则会缓存前64位数组内容，例如从下标0读到63，则不会重复读取内容，那么如果读0 然后 读 64呢？ 答案是会重复读内存，他会自动缓存从0开始的一共长度64的数据，那么下标64已经超出这个长度则会重复读内存 那么如果读 0 然后读 2呢，还会重复读内存吗？ 答案也是肯定的，如果跳着读他会重复缓存，必须是一个连续的数值才可以利用上这个长度 1234567p : = [3][3]int&#123;&#123;1, 2, 3&#125;, &#123;4 ,5, 6&#125;, &#123;7, 8, 9&#125;&#125;for i := 0; i &lt; 3; i++ &#123; for j := 0; j &lt; 3; i++ &#123; fmt.Println(\"echo : \" ,p[i][j]) // fmt.Println(\"echo : \" ,p[j][i]) &#125;&#125; 上述Go代码中 fmt.Println(&quot;echo : &quot; ,p[i][j])是在内存中读取连续的数值，而 fmt.Println(&quot;echo : &quot; ,p[j][i]) 则并非是在读连续数据，他会不断地请求内存，从而会发现前者的效率更高一些 总结 ： 抛开一切因素，读取数据时按照存储顺序来读一定要比任意读效率要高，如果有条件控制数据长度那么可以结合CPU Cache Line 的长度来做一些优化 CPU分支预测CPU本身是有一个分支预测功能，它相当于一个CPU自带的优化器，当我们在代码中使用if判断的时候，CPU会自行预测他的结果并缓存，那么CPU预测的结果就一定是准确的么，当然不是~ 既然CPU的分支预测可以在不知道结果的情况下缓存他认为正确的数据，那么我们在编写代码时则可以适当地让CPU的分支预测更准确，那么也就避免了继续从内存读取数据，避免了多余的操作 代码实现该如何做呢，当一个if语句大多数时间都是 真 的情况下，那么CPU的分支预测将在后续预测中更容易缓存 真 的数据，也可以说，我们的代码尽量让数据保持在一个分支中，可以避免重复读取操作 除了这种CPU自动的分支预测，C语言也提供了一个方法可以告诉CPU大概的结果，从而使CPU更多的缓存某个分支的数据 123456789#define likely(x) __builtin_expect(!!(x),1)#define unlikely(x) __builtin_expect(!!(x),0)if (likely(a == 1))&#123; /* code */&#125;else&#123; /* code */&#125; 数据类型和线程绑定一般情况下，long 类型 要占用更多的空间，所以很多人在使用时更愿意使用 int，但是在CPU Cache line 中确并不如此，如果一些相同的数据经常要一起使用，我们尽量需要把数据长度控制在特定长度之内或者将数据按照指定顺序来存储更好。 数据类型会影响什么，真的是占用内存越小越好吗？ 并非如此，现在的服务器更多的是多核CPU，单核CPU则不需要特别注意，多核CPU在处理数据的时候，L1，L2 Cache是独立存在于各个CPU核心的，只有L3 Cache是共享的，既如此，那么L1 和L2的Cache是如何共享信息保持数据一致性？ 如果一个进程在不同核心 来回切换，各个核心的缓存命中率就会受到影响，当有多个同时执行「计算密集型」的线程，为了防止因为切换到不同的核心，而导致缓存命中率下降的问 题，我们可以把线程绑定在某一个 CPU 核心上 在 Linux 上提供了 sched_setaffinity 方法，来实现将线程绑定到某个 CPU 核心这一功能，从某些程度上来说，亦可以保证数据的一致性问题 多核多线程之间的数据一致性如何保证？现在市面上大多数的CPU核心是通过 MESI 协议来保持数据一致性的，是Modified Exclusive Shared Invalidated的缩写，即是： 已修改 独占 已共享 已失效 oleDCd.png 如上，当两个线程都在操作时，A和B都是从内存取出一块儿数据来操作（CPU Cache Line），很多情况下，如果未能保证数据的连续性，A线程就容易拿到B的数据，B也会拿到A的数据，如果A线程操作变量内容时，那么B也需要同时修改才能保证数据的一致性 那么数据的’锁‘该如何保证呢，则是 MESI协议来保证的。 线程A操作变量发生变化时，线程A不会广播写入到内存，而是将数据标识为 已修改，而其他线程则是将数据标记为 已失效，当线程读取数据发现标识为已失效时才会重复读取数据更新数据，否则频繁的刷新数据则失去了CPU Cache的意义 当线程A将已修改的数据写入到内存后，其他线程也更新完数据，那么，将会把数据标记为 已共享 当线程A创建一个数据，其他线程缓存并不存在该数据时则该数据为 独占 如上，当出现越来越多的数据在不断地变化，多个线程操作同一块儿缓存，即使有MESI协议的调度，也不免多了很多操作，所以有些人就想到了用占位更大的字符类型让一个变量占用更多的字节数，从而达到保证线程永远拿到这一块儿数据的时候不会有其他线程的共享数据，而实际上，在多核系统中，也提供了宏定义 __cacheline_aligned_in_smp 来保证数据的长度与CPU Cache Line 保持一致 olnX9J.png 如上，A和B通过宏定义 __cacheline_aligned_in_smp 定义后，字节数会各自占用一块儿，则避免了数据频繁共享的问题 参考 小林Coding（图解系统） 近期写一写感谢大佬的电子图书笔记，小白受益良多","categories":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/categories/优化/"}],"tags":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/tags/优化/"}]},{"title":"frp+Nginx内网穿透远程桌面","slug":"frp-Nginx内网穿透远程桌面","date":"2020-07-27T08:41:31.000Z","updated":"2020-07-27T08:51:35.693Z","comments":true,"path":"2020/07/27/frp-nginx.html","link":"","permalink":"https://sbcoder.cn/2020/07/27/frp-nginx.html","excerpt":"","text":"说明基于 fatedier/frp 的内网穿透服务参考文档 frp中文文档参考文档 使用frp进行内网穿透 服务端直接下载 Releases · fatedier/frp找到对应版本下载即可，我这里服务端选用的是 frp_0.33.0_linux_386 国内机器速度慢可以使用我的个人镜像地址1wget https://api.0161.org/resources/frp_0.33.0_linux_386.tar.gz 修改配置文件 frps.ini 文件，建议增加Token验证 关于服务端配置可以参照官方给出的完全版配置文件及注释查看 frps_full.ini 文件 配置示例12345678[common]bind_port = 7000token = 123456dashboard_port = 7500dashboard_user = admindashboard_pwd = 123456vhost_http_port = 10088vhost_https_port = 10443 1nohup ./frps -c ./frps.ini &amp; 查看后台进程1jobs 删除进程示例12ps -ef | grep frps | grep -v grepkill &lt;进程id&gt; 根据上述配置好的端口 7500 使用 IP+端口 访问frp面板 输入面板用户名+密码该面板无实际性作用，仅用来做探针以及查看当前服务的状态，如未配置dashboard则无法使用dashboard 1.png 客户端下载 客户端 可以直接在github下载或者使用我的1wget https://api.0161.org/resources/frp_0.33.0_windows_amd64.zip 解压后修改 frpc.ini 12345678910111213[common]server_addr = &lt;你的服务器IP地址&gt;server_port = 7000token = 123456[rdp]type = tcplocal_ip = 127.0.0.1 local_port = 3389remote_port = 7001[web]type = httplocal_port = 80custom_domains = &lt;你的远程解析域名 例如: xxx.0161.org&gt; 上述使用Windows开启3389后可以访问远程桌面，Linux同理，只需要修改为 SSH 即可 2.png 值得注意的是 custom_domains 这个参数需要配合 vhost_http_port 这个参数使用，由于跟Nginx冲突所以上述端口我开启的是 10088可以使用域名解析的方式 架设游戏服务器 或者网络云盘 群晖 你懂得网站等 Nginx反向代理使用上述配置必须要使用 域名+端口 的形式才能访问，如果要用正式环境则不美观，且我们希望它与Nginx共存，因此，可以通过Nginx反向代理的形式去解析配置Nginx配置文件123456789101112server &#123; listen 80; server_name xxx.0161.org; location / &#123; proxy_pass http://127.0.0.1:10088; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header REMOTE-HOST $remote_addr; &#125;&#125; 流程图解 3.png 至此，可以直接访问 xxx.0161.org 无需携带端口号","categories":[{"name":"折腾","slug":"折腾","permalink":"https://sbcoder.cn/categories/折腾/"}],"tags":[{"name":"运维","slug":"运维","permalink":"https://sbcoder.cn/tags/运维/"},{"name":"内网穿透","slug":"内网穿透","permalink":"https://sbcoder.cn/tags/内网穿透/"},{"name":"frp","slug":"frp","permalink":"https://sbcoder.cn/tags/frp/"}]},{"title":"简单制作网易云音乐解析接口","slug":"简单制作网易云音乐解析接口","date":"2020-07-27T02:44:29.000Z","updated":"2020-07-27T06:33:58.069Z","comments":true,"path":"2020/07/27/neteasy-music.html","link":"","permalink":"https://sbcoder.cn/2020/07/27/neteasy-music.html","excerpt":"","text":"官方接口网易云是有一个官方的音乐解析接口的，只是隐藏的比较深（其实也还好），可以选择使用官方的解析接口也可以使用我的，可能官方的有时效性 Step1. 找到一张无版权歌曲点击生成外链播放器 aPDuNR.png Step2. 选择flash播放器开启F12 审查元素 选择flash播放器 aPDnE9.png Step3. 搜索接口直接在F12 搜索 song 找到如下接口 aPDZB4.png Step. 复制接口地址302直接跳转，我们可以直接获取到直链地址 aPDeHJ.png 找到官方接口1https://music.163.com/song/media/outer/url?id=&lt;歌曲ID&gt; 根据官方内容自制接口1234567891011121314151617181920212223242526272829303132&lt;?php$params = $_REQUEST;$returnData = [];$returnData['src'] = 'error 500';$returnData['code'] = 0;$returnData['msg'] = '无状态';if (!isset($params['url']) || empty($params['url'])) &#123; $returnData['msg'] = '5001 URL或者ID参数不存在'; echo json_encode($returnData,JSON_UNESCAPED_SLASHES); exit();&#125;$url = $params['url'];$pattern = '/(\\d&#123;5,20&#125;)/i';preg_match($pattern, $url, $matches);if (!$matches) &#123; $returnData['msg'] = '5002 URL或者ID格式有误'; echo json_encode($returnData,JSON_UNESCAPED_SLASHES); exit();&#125;$getParameterUrl = 'https://music.163.com/song/media/outer/url?id=' . $matches[0];var_dump($getParameterUrl);exit();$headers = get_headers($getParameterUrl, TRUE);//输出跳转到的网址if ($headers['Location']) &#123; $returnData['msg'] = '成功'; $returnData['src'] = $headers['Location']; $returnData['code'] = 1;&#125;echo json_encode($returnData,JSON_UNESCAPED_SLASHES);exit(); 二次封装之后可以使用注意：网易云的这个接口无法使用国外IP访问，如IP不符可能会返回404 可以使用我的API接口获取最新版解析","categories":[{"name":"折腾","slug":"折腾","permalink":"https://sbcoder.cn/categories/折腾/"}],"tags":[{"name":"音乐","slug":"音乐","permalink":"https://sbcoder.cn/tags/音乐/"}]},{"title":"使用Rancher快速部署k8s集群","slug":"使用Rancher快速部署k8s集群","date":"2020-07-24T03:32:57.000Z","updated":"2020-07-24T03:34:48.050Z","comments":true,"path":"2020/07/24/rancher-install.html","link":"","permalink":"https://sbcoder.cn/2020/07/24/rancher-install.html","excerpt":"","text":"安装Rancher注意：最低配置为 2H4G1M 本教程使用 2H8G5M Ubuntu18.04卸载旧版Docker1sudo apt-get remove docker docker-engine docker.io containerd runc 脚本安装Docker1curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun 更换阿里云源登录 https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors 找到 加速地址，或者使用我的12345678sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-&apos;EOF&apos;&#123; &quot;registry-mirrors&quot;: [&quot;https://p4sew3ge.mirror.aliyuncs.com&quot;]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart docker 安装Rancher1sudo docker run -d --restart=unless-stopped -v /home/rancher:/var/lib/rancher/ -p 80:80 -p 443:443 rancher/rancher:stable 打开 https://&lt;你的IP&gt;忽略掉证书提示，继续进入 1.png 添加集群Step1.设置语言 2.png Step2.选择右上角添加集群，选择自定义 3.png Step3.设置好集群名字后直接点击下一步 Step4.配置节点按照需要配置，我这里选择全部 4.png Step5.配置公网IP云主机需要配置 5.png Step6.复制命令执行 6.png 执行后会启动一个容器 7.png Step7.集群部署节点完成准备中… 8.png 完成部署 9.png 增加节点选择主机 - 编辑集群 11.png 拉到最下面，与上面添加节点方式一样，修改为子节点的ip，然后在子节点运行该命令等待添加完成 10.png","categories":[{"name":"架构","slug":"架构","permalink":"https://sbcoder.cn/categories/架构/"}],"tags":[{"name":"运维","slug":"运维","permalink":"https://sbcoder.cn/tags/运维/"},{"name":"Docker","slug":"Docker","permalink":"https://sbcoder.cn/tags/Docker/"}]},{"title":"Ubuntu18.04部署Kubernetes(k8s)集群可视化界面Dashboard","slug":"Ubuntu18-04部署Kubernetes-k8s-集群可视化界面Dashboard","date":"2020-07-23T01:12:57.000Z","updated":"2020-07-23T06:03:37.256Z","comments":true,"path":"2020/07/23/Kubernetes-Ubuntu.html","link":"","permalink":"https://sbcoder.cn/2020/07/23/Kubernetes-Ubuntu.html","excerpt":"","text":"k8s概念架构 Kubernetes是一个完备的分布式系统支撑平台。Kubernetes具有完备的集群管理能力，包括多层次的安全防护和准入机制/多租户应用支撑能力、透明的服务注册和服务发现机制、内建智能负载均衡器、强大的故障发现和自我修复功能、服务滚动升级和在线扩容能力、可扩展的资源自动调度机制，以及多粒度的资源配额管理能力。同时kubernetes提供了完善的管理工具，这些工具覆盖了包括开发、测试部署、运维监控在内的各个环节；因此kubernetes是一个全新的基于容器技术的分布式架构解决方案，并且是一个一站式的完备的分布式系统开发和支撑平台 Kubernetes简易.png Kubernetes Service Service的服务进程目前都基于Socker通信方式对外提供服务，比如redis、memcache、MySQL、Web Server，或者是实现了某个具体业务的一个特定的TCP Server进程。虽然一个Service通常由多个相关的服务进程来提供服务，每个服务进程都有一个独立的Endpoint(IP+Port)访问点，但Kubernetes 能够让我们通过Service虚拟Cluster IP+Service Port连接到指定的Service上。有了Kubernetes内建的透明负载均衡和故障恢复机制，不管后端有多少服务进程，也不管某个服务进程是否会由于发生故障而重新部署到其他机器，都不会影响到我们对服务的正常调用。更重要的是这个Service本身一旦创建就不再变化，这意味着Kubernetes集群中，我们再也不用为了服务的IP地址变来变去的问题而头疼。 service可以通过访问点去访问不同的子节点下面的Pod上，类似一个Proxy的概念，个人理解为他本身类似集群，通过service分发与swarm集群中的service类似，可以保持容器启动数量，由于权限相关问题，用户手动命令要大于service控制的权限级别，因此如果在使用service控制Pod时，有可能导致报错，不推荐使用 Kubernetes Service.png Kubernetes Pod Pod运行在一个我们称之为节点Node的环境中，可以是私有云也可以是公有云的虚拟机或者物理机，通常在一个节点上运行几百个Pod;其次，每个Pod里运行着一个特殊的被称之为Pause的容器，其他容器则为业务容器，这些业务容器共享Pause容器的网络栈和Volume挂载卷，因此他们之间的通讯和数据交换更为高效。在设计时我们可以充分利用这一特征将一组密切相关的服务进程放入同一个Pod中。并不是每个Pod和它里面运行的容器都能映射到一个Service 上，只有那些提供服务(无论是对内还是对外)的一组Pod才会被映射成一个服务。 Kubernetes Pod.png Pod &amp; Container 容器（Container）是一种高度隔离的封装程序 容器1.png 非所有的应用都适合选择容器，开发者可以根据自己应用的特点和需求选择最适合的计算单元。例如，你的应用是高性能、互信的，且处于同一个管理区域，那么用线程或者进程就可以满足；但如果你的应用是多租户的，并且和其他应用运行在同一个空间，那么你就需要考虑如何将这些应用安全地隔离开，使得数据不会被泄露或性能受到影响。那么这时，容器也许就是一个不错的选择了。容器便于管理，因为现在市场上有着完全完善的生态以及Docker的支持度愈发增加，越来越多的公司（个人）选择Docker，我个人也更倾向于Docker，有了Docker就可以非常完美的管理Images以及Container 容器2.png 容器是只占用很少的空间的，真正占用空间大的是Images，也可以说 Container 依赖 Images Pod，一种增强型容器Pod是一种组合的多容器运行单元，也是Kubernetes里的一个基础单元。你可以把它看作是一种容器的扩展或者增强型的容器。Pod里面包括一个主容器和数个辅助容器，它们共同完成一个特定的功能。把多个进程（容器也是一种隔离的进程）打包在一个Name Space里的时候，就构成了一个Pod。Pod里面不同进程的应用包装仍然是独立的（每个容器都会有自己的镜像）。Pod的意义在于，它可以既保持主容器和辅助容器的的密切关系，又保持主容器的独立性。由于主容器和辅助容器的生命周期相同，可以同时被创建和销毁，因此把它们放在一个Pod中，可以使他们的交互更加高效。 参考文档Aholiab - 云原生的基石，一文读懂容器、Docker、Pod到底是什么！ abcdocker编写k8s中文文档Ubuntu18.04使用kubeadm部署v1.18 HA集群 部署k8s机器选择这里我只做学习用途，因此开通的是阿里的按量计费机器以及低配置机器 master01 2H8G 阿里云 Ubuntu18.04 node01 2H8G 阿里云 Ubuntu18.04 部署环境Ubuntu修改仓库镜像12345678910111213141516sudo cat &gt; /etc/apt/sources.list &lt;&lt; EOFdeb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverseEOF 关闭防火墙1sudo ufw disable 时间同步12345678sudo apt-get install chrony -y &amp;&amp; sudo systemctl start chrony &amp;&amp; sudo systemctl enable chrony#查看chrony连接的公网服务器cat /etc/chrony/chrony.conf pool ntp.ubuntu.com iburst maxsources 4pool 0.ubuntu.pool.ntp.org iburst maxsources 1pool 1.ubuntu.pool.ntp.org iburst maxsources 1pool 2.ubuntu.pool.ntp.org iburst maxsources 2 禁用swap1sudo swapoff -a 上述命令可以临时禁用掉swap，如果想要永久禁止，需要编辑 /etc/fstab 文件,将swap那一行注释掉，如果没有则不管 禁用SELinux如果安装了则需要禁止掉，如果没有安装则可以跳过此步骤123sudo setenforce 0 #临时关闭sudo vi /etc/selinux/config #永久关闭SELINUX=permissive 修改内核123456sudo cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt; EOFnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1net.ipv4.ip_forward = 1 #开启ipv4转发，允许内置路由EOFsudo sysctl --system 修改时区12sudo ln -snf /usr/share/zoneinfo/Asia/Shanghai /etc/localtimesudo bash -c &quot;echo &apos;Asia/Shanghai&apos; &gt; /etc/timezone&quot; 安装DockerStep 1: 安装必要的一些系统工具12sudo apt-get updatesudo apt-get -y install apt-transport-https ca-certificates curl software-properties-common Step 2: 安装GPG证书1sudo curl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - Step 3: 写入软件源信息1sudo add-apt-repository &quot;deb [arch=amd64] https://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable&quot; Step 4: 查找Docker-CE的版本1sudo apt-cache madison docker-ce Step 5: 安装指定版本的Docker-CE,docker-ce=VERSION1sudo apt-get -y install docker-ce Setp 6: 安装完成后Docker默认就已经启动和加入开机自启了，这点我们不需要再做了，不过可以检查一下12sudo systemctl status dockersudo systemctl is-enabled docker Setp 7: 配置Docker镜像加速以及指定cgroup驱动为systemd123456789sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-&apos;EOF&apos;&#123; &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;], &quot;registry-mirrors&quot;: [&quot;https://81z69sad.mirror.aliyuncs.com&quot;]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart docker Setp 8: 配置完成后使用 docker info 可以看到修改的配置信息 配置主机名1234cat &gt;&gt; /etc/hosts &lt;&lt; EOF172.26.147.37 master01172.26.147.36 node01EOF 安装Kubeadm Kubelet KubectlStep 1: 安装必要的程序包1apt-get update &amp;&amp; apt-get install -y apt-transport-https Step 2: 导入Kubernetes官方包签名密钥1sudo curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - Step 3: 添加Kubernetes仓库123cat &gt; /etc/apt/sources.list.d/kubernetes.list &lt;&lt; EOFdeb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial mainEOF Step 4: 更新仓库1apt-get update Step 5: 查找kubeadm kubelet kubectl版本123apt-cache madison kubeadm | grep 1.18apt-cache madison kubelet | grep 1.18apt-cache madison kubectl | grep 1.18 目前1.18发布了1.18.0-00 1.18.1-00 1.18.2-00 三个版本 Step 6: 指定版本安装kubelet kubeadm kubectl(如果安装最新版本则无需带版本号)1apt-get install kubeadm kubelet kubectl -y Master节点部署根据需要修改的参数更换以下内容123456789kubeadm init \\--image-repository registry.aliyuncs.com/google_containers \\--kubernetes-version v1.18.0 \\--control-plane-endpoint master01 \\--pod-network-cidr=10.244.0.0/16 \\--service-cidr=10.96.0.0/12 \\--apiserver-advertise-address=0.0.0.0 \\--ignore-preflight-errors=Swap \\--token-ttl 30m 参数说明 image-repository：初始化过程中会去docker仓库拉去镜像，默认指定的为docker hub(国内访问网速不堪)，所以在此使用–image-repository参数指定阿里云镜像。 kubernetes-version：指定正在使用的 Kubernetes 程序组件的版本号，需要与 kubelet kubeadm kubectl 的版本号一致。 control-plane-endpoint: 指定控制平面的固定访问端点，可以是IP地址或DNS名称，会被用于集群管理员及集群组件的kubeconfig配置文件API Server的访问地址；单控制平面部署时可以不使用该选项(如果是单个Master部署则不需要使用该选项，因为等会我们要再加入其它两个Master节点到控制平面，所以这里加上此参数)。 pod-network-cidr：Pod 网络的地址范围，其值为 CIDR 格式的网络地址，使用 flannel 网络插件时，其默认地址为 10.244.0.0/16。 service-cidr：Service 的网络地址范围，其值为 CIDR 格式的网络地址，默认地址为 10.96.0.0/12。 apiserver-advertise-address：API Server 通告给其它组件的IP地址，一般为 Master 节点的IP地址，0.0.0.0 标识节点上所有可用的地址。ignore-preflight-errors：忽略哪些运行时的错误信息，其值为 Swap 时，表示忽略因 swap 未关闭而导致的错误。 token-ttl：token令牌自动删除时间，默认为24小时，指定为 0 表示永不过期，指定单位可以使 秒s 分m 时h，在node加入Kubernetes集群时需要指定token。初始化过程 01.png 02.png 03.png 初始化完成12345678910111213141516171819202122232425#您的Kubernetes控制平面初始化成功!Your Kubernetes control-plane has initialized successfully!#要开始使用您的集群，您需要作为一个普通用户运行以下程序:To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config#你需要部署一个网络插件到集群中才能够使Kubernetes网络运转起来You should now deploy a pod network to the cluster.Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/#如果要添加其它控制平面到集群中使用以下命令You can now join any number of control-plane nodes by copying certificate authoritiesand service account keys on each node and then running the following as root: kubeadm join k8s-devops.io:6443 --token 8r7sjk.9a31rmcjot9650fe \\ --discovery-token-ca-cert-hash sha256: \\ --control-plane#如果要添加数据平面节点到集群中使用以下命令Then you can join any number of worker nodes by running the following on each as root:kubeadm join k8s-devops.io:6443 --token 8r7sjk.9a31rmcjot9650fe \\ --discovery-token-ca-cert-hash sha256: 创建用户12345root@master01:~# useradd -m -s /bin/bash k8s # 创建用户root@master01:~# passwd k8s # 设置密码Enter new UNIX password:Retype new UNIX password:passwd: password updated successfully 为普通用户提权1root@master01:~# echo &apos;k8s ALL=(ALL:ALL) NOPASSWD:ALL&apos; &gt;&gt; /etc/sudoers.d/k8s 创建权限123456root@master01:~# su k8s # 切换用户k8s@master01:/root$ k8s@master01:/root$ cd / # 切换目录k8s@master01:/$ mkdir -p $HOME/.kube #在当前用户家目录下创建.kube目录k8s@master01:/$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config #复制config命令配置文件到当前用户.kube目录下k8s@master01:/$ sudo chown $(id -u):$(id -g) $HOME/.kube/config #修改config文件权限 部署网络插件Step 1: 可以直接在线部署(如果网络下载不了的情况下,也可以先试用浏览器下载后上传到服务器上)1k8s@master01:/$ kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml Step 2: 如果上述方法还是不行，则可以尝试使用我的1kubectl apply -f https://api.0161.org/resources/kube-flannel.yml Step 3: 上传完后修改文件的属性信息(如上述1,2步骤已完成则直接跳过)1k8s@master01:/$ sudo chown -Rf k8s.k8s kube-flannel.yml Step 4: 然后指定文件部署网络插件(如上述1,2步骤已完成则直接跳过)1234567891011k8s@master01:/$ kubectl apply -f kube-flannel.ymlpodsecuritypolicy.policy/psp.flannel.unprivileged createdclusterrole.rbac.authorization.k8s.io/flannel createdclusterrolebinding.rbac.authorization.k8s.io/flannel createdserviceaccount/flannel createdconfigmap/kube-flannel-cfg createddaemonset.apps/kube-flannel-ds-amd64 createddaemonset.apps/kube-flannel-ds-arm64 createddaemonset.apps/kube-flannel-ds-arm createddaemonset.apps/kube-flannel-ds-ppc64le createddaemonset.apps/kube-flannel-ds-s390x created Step 5: 查看网络插件是否部署完成(下面有一个叫kube-flannel-ds-amd64的Pod)如果发现你的 flannel Pod 处于 ImagePullBackOff 状态，那么就是 flannel 镜像未拉取成功，而正常的则为 Running状态12k8s@master01:/$ kubectl get pods -n kube-system | grep flannelkube-flannel-ds-amd64-hx9cr 1/1 Running 0 2m3s Step 6: 查看目前k8s节点信息123k8s@master01:/$ kubectl get nodesNAME STATUS ROLES AGE VERSIONmaster01 Ready master 65m v1.18.6 子节点加入到集群master节点查看join参数1kubeadm token create --print-join-command 子节点运行1kubeadm join master01:6443 --token 8z8ot9.ylyj39j1po0hgyun --discovery-token-ca-cert-hash sha256:e0bb3c41**********************************813c84472f65c 04.png 安装Dashboard官方文档方式启动(不建议)与端口+ip只能选择一种使用！！！1kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.3/aio/deploy/recommended.yaml 如遇到无法访问或者网络连接问题可以使用我的备份文件1kubectl apply -f https://api.0161.org/resources/recommended.yaml 代理方式启动1kubectl proxy 05.png 端口+IP启动(推荐)环境部署下载文件1wget https://k8s-1252147235.cos.ap-chengdu.myqcloud.com/dashboard/dashboard.yaml 拉取镜像1sudo docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kubernetes-dashboard-amd64:v1.10.1 创建服务1sudo kubectl apply -f dashboard.yaml 浏览器输入 https://IP:30001 打开 （可以使用Safari或者火狐，Chrome无法访问） 06.png 绑定用户12sudo kubectl create serviceaccount dashboard-admin -n kube-systemkubectl create clusterrolebinding dashboard-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard 获取Token1kubectl describe secrets -n kube-system $(kubectl -n kube-system get secret | awk &apos;/dashboard-admin/&#123;print $1&#125;&apos;) 按Token启动 07.png 赋予用户权限单命名空间权限文件及绑定创建 role.yaml123456789101112kind: RoleapiVersion: rbac.authorization.k8s.io/v1metadata: namespace: kube-system name: role-dashboard-adminrules:- apiGroups: [&quot;&quot;] resources: [&quot;pods&quot;,&quot;services&quot;] verbs: [&quot;get&quot;, &quot;watch&quot;, &quot;list&quot;]- apiGroups: [&quot;extensions&quot;, &quot;apps&quot;] resources: [&quot;deployments&quot;] verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;update&quot;, &quot;patch&quot;, &quot;delete&quot;] 创建 role-bind.yaml12345678910111213kind: RoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: role-bind-dashboard-admin namespace: kube-systemsubjects:- kind: ServiceAccount name: dashboard-admin namespace: kube-systemroleRef: kind: Role name: role-dashboard-admin apiGroup: rbac.authorization.k8s.io 集群权限配置及绑定创建 cluster-role.yaml12345678kind: ClusterRoleapiVersion: rbac.authorization.k8s.io/v1metadata: name: cluster-role-dashboard-adminrules:- apiGroups: [&quot;&quot;] resources: [&quot;pods&quot;] verbs: [&quot;get&quot;, &quot;watch&quot;, &quot;list&quot;] 创建 cluster-role-bind.yaml123456789101112kind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: cluster-role-bind-dashboard-adminsubjects:- kind: ServiceAccount name: dashboard-admin apiGroup: rbac.authorization.k8s.ioroleRef: kind: ClusterRole name: cluster-role-dashboard-admin apiGroup: rbac.authorization.k8s.io 执行命令1234kubectl create -f role.yamlkubectl create -f role-bind.yamlkubectl create -f cluster-role.yamlkubectl create -f cluster-role-bind.yaml 完成权限配置，可根据自身情况增加配置！ 常用k8s命令 查看pod列表 12kubectl get pods --all-namespaces # 查看所有sudo kubectl get pod -n kube-system # 查看指定命名空间 查看service列表 1kubectl get service --all-namespaces # 查看所有 删除指定命名空间下的service 1kubectl delete service serviceName --namespace=namespaceName 删除指定命名空间下的pod 1kubectl delete pod podName --namespace=namespaceName 查看所有deployment 1kubectl get deployment -A 删除指定deployment 1kubectl delete deployment podName 查看指定命名空间端口 1sudo kubectl get pod,svc -n kube-system","categories":[{"name":"架构","slug":"架构","permalink":"https://sbcoder.cn/categories/架构/"}],"tags":[{"name":"架构","slug":"架构","permalink":"https://sbcoder.cn/tags/架构/"},{"name":"Docker","slug":"Docker","permalink":"https://sbcoder.cn/tags/Docker/"}]},{"title":"Redis持久化及数据备份","slug":"Redis持久化及数据备份","date":"2020-06-10T08:14:42.000Z","updated":"2020-07-23T07:15:15.894Z","comments":true,"path":"2020/06/10/Redis-Backup.html","link":"","permalink":"https://sbcoder.cn/2020/06/10/Redis-Backup.html","excerpt":"","text":"Redis持久化Redis作为内存数据库，数据的安全性一定要得到确切的保障，很多情况下，Redis是作为存储数据库来用的，如果遇到断电，关机等突发情况，则容易丢失关键数据，对此，Redis的持久化就显得尤为关键，甚至某些情况下，需要定时去做备份 RDB可以在每隔一段时间执行一次备份操作，性能比AOF方式更好，RDB是紧凑型文件，但是最多可以执行到5分钟左右，如果再低可能会影响性能RDB相当于 备份数据 恢复数据快 性能更好 可以分时间节点备份文件 容易丢失数据 AOF可以按秒级存储数据，由于长期存储，如果发生崩溃事件，它可能只会丢失几秒的数据，相比较来说，可能更安全AOF相当于 备份执行语句 数据安全性更高 存储时不占用资源 可自定 fsync 策略 恢复速度慢 Docker安装12docker pull redis:latestdocker run -itd --name redis01 -p 6379:6379 redis 1.png 未完！！！","categories":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/categories/优化/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://sbcoder.cn/tags/数据库/"},{"name":"Redis","slug":"Redis","permalink":"https://sbcoder.cn/tags/Redis/"}]},{"title":"MySQL主从同步 读写分离 集群部署","slug":"MySQL-主从同步-读写分离","date":"2020-06-10T06:25:42.000Z","updated":"2020-06-10T06:28:17.018Z","comments":true,"path":"2020/06/10/MySQL-Cluster-MySQLProxy.html","link":"","permalink":"https://sbcoder.cn/2020/06/10/MySQL-Cluster-MySQLProxy.html","excerpt":"","text":"简介可以使用之前写的Canal阿里巴巴增量订阅更新做简单的主从备份，由于Canal只读取 binary log 日志做增量更新 canal工作流程图.png 通过canal可以做简单的按更新备份也可以通过canal做数据更新，根据更新的内容去更新数据库中其他的字段值也可以通过canal客户端发送消息给 ElasticSearch 等服务，适合多样化复杂的MySQL主从操作通过伪造slave的方式请求binary log消息 阿里巴巴也为我们提供了更好的基于Canal的分布式数据库同步系统 otter otter工作原理.jpg 本文所用Docker目的是一台机器搞定集群功能，实际生产环境中不建议使用Docker 参考项目：alibaba/otter - 阿里巴巴分布式数据库同步系统(解决中美异地机房)alibaba/canal - 阿里巴巴 MySQL binlog 增量订阅&amp;消费组件 通过MySQL配置主从备份主从备份，通过配置MySQL做主从备份 主从备份流程图.jpg 注意事项 主从数据库版本保持一致 需要单独的两台服务器（单台机器可使用Docker，没有测试过） 需要网络相连，保证主从服务器通信 表结构不使用外键，使用外键容易造成同步失败 主键使用无意义自增字段 同步数据库所用的账号拥有一定的权限，也可以使用root 安装MySQL参照之前的文章 MySQL Docker启动启动两个不同的 MySQL 映射不同的端口123docker run --restart=always --name mysql5.7-1 -p 3307:3306 -v /Users/XXX/Downloads/Docker/mysql5.7-1:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7 --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_cidocker run --restart=always --name mysql5.7 -p 3306:3306 -v /Users/XXX/Downloads/Docker/mysql5.7:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7 --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci 进入容器内部 安装vim 或者映射 使用参数 -v 映射位置 /etc/mysql/my.cnf 配置文件亦可 安装 vim 方式 编辑 my.cnf12apt-get installapt-get install vim 挂载 本地文件 内容123456789101112131415161718192021222324# Copyright (c) 2016, Oracle and/or its affiliates. All rights reserved.## This program is free software; you can redistribute it and/or modify# it under the terms of the GNU General Public License, version 2.0,# as published by the Free Software Foundation.## This program is also distributed with certain software (including# but not limited to OpenSSL) that is licensed under separate terms,# as designated in a particular file or component or in included license# documentation. The authors of MySQL hereby grant you an additional# permission to link the program and your derivative works with the# separately licensed software that they have included with MySQL.## This program is distributed in the hope that it will be useful,# but WITHOUT ANY WARRANTY; without even the implied warranty of# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the# GNU General Public License, version 2.0, for more details.## You should have received a copy of the GNU General Public License# along with this program; if not, write to the Free Software# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA!includedir /etc/mysql/conf.d/!includedir /etc/mysql/mysql.conf.d/ 配置主从备份主节点 使用root 用户 配置 修改配置文件 /etc/mysql/my.cnf123[mysqld]log-bin=mysql-binserver-id=1 执行命令 input123GRANT REPLICATION SLAVE ON *.* to &apos;root&apos;@&apos;%&apos; identified by &apos;123456&apos;;FLUSH PRIVILEGES;SHOW MASTER STATUS; output12345+------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+------------------+-------------------+| mysql-bin.000001 | 589 | | | |+------------------+----------+--------------+------------------+-------------------+ 从节点 使用root 用户 配置修改配置文件 /etc/mysql/my.cnf123[mysqld]log-bin=mysql-binserver-id=2 执行命令 input123change master to master_host=&apos;172.17.0.2&apos;,master_user=&apos;root&apos;,master_password=&apos;123456&apos;,master_log_file=&apos;mysql-bin.000001&apos;,master_log_pos=589;start slave;show slave status\\G; output1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 172.17.0.2 Master_User: root Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000001 Read_Master_Log_Pos: 589 Relay_Log_File: f919535d2d58-relay-bin.000002 Relay_Log_Pos: 320 Relay_Master_Log_File: mysql-bin.000001 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 589 Relay_Log_Space: 534 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 1 Master_UUID: 380e925e-a645-11ea-a304-0242ac110004 Master_Info_File: /var/lib/mysql/master.info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: Executed_Gtid_Set: Auto_Position: 0 Replicate_Rewrite_DB: Channel_Name: Master_TLS_Version:1 row in set (0.00 sec) 测试 创建一个 test数据库 主从数据库同步.png 监控状态可以使用crontab 配合钉钉通知 使用 curl命令通知 主从同步是否成功 12345678# !/bin/basharray=($(mysql -uroot -p -e \"show slave status\\G\" | grep \"Running\" | awk '&#123;print $2&#125;'))if [ \"$&#123;array[0]&#125;\" == \"Yes\" ] || [ \"$&#123;array[1]&#125;\" == \"Yes\" ] then echo \"Slave is OK\" else echo \"Slave is error\"fi 读写分离master数据库处理写操作，slave数据库处理读操作。利用上面配置的主从数据库，使master数据库的变更实时更新到slave节点上，支持事务，但可能会因为某些原因有阻塞现象发生，不可避免的可能会出现数据同步慢的情况 读写分离.png 使用 MySQLProxy 做读写分离 MySQLProxy实际上是在客户端请求与MySQLServer之间建立了一个连接池。所有客户端请求都是发向MySQLProxy，然后经由MySQLProxy进行相应的分析，判断出是读操作还是写操作，分发至对应的MySQLServer上。对于多节点Slave集群，也可以起做到负载均衡的效果。 MySQLProxy.png 为何要使用MySQLProxy？其实可以不使用，但为了减少代码量，减少开发成本，可以通过运维的手段去做分发处理。常见的开发框架实际上很多是支持读写分离操作不同数据库的，而代理服务器做的则是将这些框架封装好的东西通过代理分发的方式，分别给不同的数据库发送请求，主库只修改，从库只读 缺点 目前MySQLProxy仍然是 alpha（内测） 版 通过lua脚本做的读写分离，MySQL官方并不建议使用 配置MySQLProxy读写分离假定 上述两台服务器 分别为 master slave 那么我们现在需要第三台服务器 proxyproxy需要做中转代理，将接收到的数据库请求分别指向 master 和 slave 下载 MySQLProxy下载地址：MySQL Product Archives 由于我的环境为MAC新版，对 MySQLProxy 的支持度并不好，因此并不在本机使用可以参照下面引用的文章参考配置 参考文章 Mysql 主从备份完整版 MySQL主从备份配置 MySQL读写分离介绍及搭建 MySQL Proxy","categories":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/categories/优化/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://sbcoder.cn/tags/MySQL/"},{"name":"运维","slug":"运维","permalink":"https://sbcoder.cn/tags/运维/"}]},{"title":"ElasticSearch & ELK日志分析 从零开始搭建到使用","slug":"ElasticSearch-Kibana-从零开始搭建到使用","date":"2020-05-27T12:34:16.000Z","updated":"2020-06-04T08:31:49.232Z","comments":true,"path":"2020/05/27/ELK_Stack.html","link":"","permalink":"https://sbcoder.cn/2020/05/27/ELK_Stack.html","excerpt":"","text":"引言介绍基于Lucene的搜索服务器，它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。更适用于集群部署，适合各类 分词，全文搜索，通过建立索引（分片，按节点分片）来实现更快的搜索Elasticsearch是与Logstash的数据收集和日志解析引擎以及Kibana的分析和可视化平台一起开发的。这三个产品被设计成一个集成解决方案，称为“Elastic Stack”（以前称为“ELK stack”）。本文只做单节点运行 ELK.png 官方介绍 Elasticsearch 是一个分布式、RESTful 风格的搜索和数据分析引擎，能够解决不断涌现出的各种用例。 作为 Elastic Stack 的核心，它集中存储您的数据，帮助您发现意料之中以及意料之外的情况。 注意事项 单点服务器维持稳定可能需要常驻内存 4G 以上 单点ELK维持稳定可能需要CPU 4核心 以上 参考文章 Docker安装部署ELK教程 (Elasticsearch+Kibana+Logstash+Filebeat) 零门槛！基于Docker快速部署ES集群 下载集群所需镜像 zookeeper kafka12docker pull zookeeperdocker pull wurstmeister/kafka 单节点无内网IP使用1docker network create elkwork 创建内部网络后在每次 docker run 的时候 增加参数 --net elkwork elastic相关 旧版本 123docker pull docker.elastic.co/elasticsearch/elasticsearch:5.6.8docker pull docker.elastic.co/kibana/kibana:5.6.8docker pull docker.elastic.co/logstash/logstash:5.6.8 新版本 1234docker pull docker.elastic.co/elasticsearch/elasticsearch:7.7.0docker pull docker.elastic.co/kibana/kibana:7.7.0docker pull docker.elastic.co/logstash/logstash:7.7.0docker pull store/elastic/filebeat:7.7.0 启动elasticsearch 自行替换版本&quot;discovery.type=single-node&quot; 单节点1docker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot; docker.elastic.co/elasticsearch/elasticsearch:5.6.8 默认用户名 默认密码elastic changeme 测试是否已经连通-u elastic:changeme 验权1curl -u elastic:changeme localhost:9200 浏览器端口访问测试 elasticsearch.png elasticsearch 各类语法基本浏览器访问http://xxx.xx.xxx.xx:9200/_cat/indices?v 查看当前节点的所有 Indexhttp://xxx.xx.xxx.xx:9200/_mapping?pretty=true 列出每个 Index 所包含的 Type 验权机制增加参数 -u elastic:changeme 验权 命令行访问curl -u elastic:changeme -X PUT &#39;localhost:9200/weather&#39; 可以直接向 Elastic 服务器发出 PUT 请求curl -u elastic:changeme -X DELETE &#39;localhost:9200/weather&#39; 发出 DELETE 请求，删除这个 Index 插入数据123456curl -X POST &apos;localhost:9200/account/person&apos; -d &apos;&#123; &quot;user&quot;: &quot;李四&quot;, &quot;title&quot;: &quot;工程师&quot;, &quot;desc&quot;: &quot;系统管理&quot;&#125;&apos; 读取数据1curl &apos;localhost:9200/account/person/1?pretty=true&apos; 示例 123456789101112&#123; \"_index\" : \"accounts\", \"_type\" : \"person\", \"_id\" : \"1\", \"_version\" : 1, \"found\" : true, \"_source\" : &#123; \"user\" : \"张三\", \"title\" : \"工程师\", \"desc\" : \"数据库管理\" &#125;&#125; 删除记录1curl -X DELETE &apos;localhost:9200/accounts/person/1&apos; 更新记录123456curl -X PUT &apos;localhost:9200/accounts/person/1&apos; -d &apos;&#123; &quot;user&quot; : &quot;张三&quot;, &quot;title&quot; : &quot;工程师&quot;, &quot;desc&quot; : &quot;数据库管理，软件开发&quot;&#125;&apos; 返回所有记录1curl &apos;localhost:9200/accounts/person/_search&apos; 索引 ：/Index/Type/_search total：返回记录数，本例是2条。 max_score：最高的匹配程度，本例是1.0。 hits：返回的记录组成的数组。 查询记录123456curl &apos;localhost:9200/accounts/person/_search&apos; -d &apos;&#123; &quot;query&quot; : &#123; &quot;match&quot; : &#123; &quot;desc&quot; : &quot;软件 系统&quot; &#125;&#125;, &quot;from&quot;: 1 &quot;size&quot;: 1&#125;&apos; size 返回数量 from 开始位置 OR搜索，当前搜索的示例是 软件或系统 AND搜索示例12345678910&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123; &quot;match&quot;: &#123; &quot;desc&quot;: &quot;软件&quot; &#125; &#125;, &#123; &quot;match&quot;: &#123; &quot;desc&quot;: &quot;系统&quot; &#125; &#125; ] &#125; &#125;&#125; 参考文章 全文搜索引擎 Elasticsearch 入门教程 启动kibana 自行替换版本1docker run -d --name kibana -p 8001:5601 docker.elastic.co/kibana/kibana:5.6.8 kibana 容器内部修改配置ip1Vi ./config/kibana.yml 重启容器使配置生效 kibana.png 配置 logstash123mkdir /home/tjy/docker/logstash/mkdir /home/tjy/docker/logstash/conf.d/vi /home/tjy/docker/logstash/logstash.yml 12path.config: /usr/share/logstash/conf.d/*.confpath.logs: /var/log/logstash 1vi /home/tjy/docker/logstash/conf.d/test.conf 123456789101112131415input &#123; beats &#123; port =&gt; 5044 codec =&gt; &quot;json&quot;&#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; [&quot;xxx.xx.xxx.xx:9200&quot;] user =&gt; elastic password =&gt; changeme &#125; stdout &#123; codec =&gt; rubydebug &#125;&#125; 启动logstash并挂载1docker run -it -d -p 8011:5044 -p 9600:9600 --name logstash -v /home/tjy/docker/logstash/logstash.yml:/usr/share/logstash/config/logstash.yml -v /home/tjy/docker/logstash/conf.d/:/usr/share/logstash/conf.d/ docker.elastic.co/logstash/logstash:5.6.8 配置 filebeat下载 通用配置文件 1234mkdir /Users/XXX/Downloads/Docker/filebeat/cd /Users/XXX/Downloads/Docker/filebeatwget https://raw.githubusercontent.com/elastic/beats/7.1/deploy/docker/filebeat.docker.ymlvi filebeat.docker.yml 配置监听 Nginx log 123456789101112131415161718192021filebeat.config: modules: path: $&#123;path.config&#125;/modules.d/*.yml reload.enabled: falsefilebeat.autodiscover: providers: - type: docker hints.enabled: trueprocessors:- add_cloud_metadata: ~filebeat.inputs:- type: log enabled: true paths: - /var/log/nginx/*.logoutput.logstash: hosts: [&apos;logstash:5044&apos;] filebeat 配合 logstash 挂载并启动以下映射的路径为我自己电脑的路径，需要自行修改！1docker run --name filebeat --user=root -d --net elkwork -v /usr/local/var/log/nginx/:/var/log/nginx/ -v /Users/XXX/Downloads/Docker/filebeat/filebeat.docker.yml:/usr/share/filebeat/filebeat.yml -v /var/run/docker.sock:/var/run/docker.sock store/elastic/filebeat:7.7.0 success.png","categories":[{"name":"架构","slug":"架构","permalink":"https://sbcoder.cn/categories/架构/"}],"tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://sbcoder.cn/tags/ElasticSearch/"},{"name":"kibana","slug":"kibana","permalink":"https://sbcoder.cn/tags/kibana/"},{"name":"Logstash","slug":"Logstash","permalink":"https://sbcoder.cn/tags/Logstash/"}]},{"title":"Docker 安装 PHP-fpm","slug":"Docker-安装-PHP-fpm","date":"2020-05-17T04:54:47.000Z","updated":"2020-06-05T09:10:42.132Z","comments":true,"path":"2020/05/17/Docker_PHP_fpm.html","link":"","permalink":"https://sbcoder.cn/2020/05/17/Docker_PHP_fpm.html","excerpt":"","text":"创建 uploads.ini12345file_uploads = Onmemory_limit = 64 Mupload_max_filesize = 20Mpost_max_size = 20Mmax_execution_time = 600 创建 Dockerfile1234567891011121314151617FROM php:7.3-fpmRUN apt-get updateRUN apt-get install -y libwebp-dev libjpeg-dev libpng-dev libfreetype6-devEXPOSE 9000#上传配置成20MCOPY uploads.ini /usr/local/etc/php/conf.dRUN docker-php-ext-install mysqliRUN docker-php-ext-install pdoRUN docker-php-ext-install pdo_mysqlRUN pecl install redis-4.2.0 &amp;&amp; docker-php-ext-enable redisRUN docker-php-ext-install bcmathRUN docker-php-ext-configure gd --with-webp-dir=/usr/include/webp --with-png-dir=/usr/include --with-jpeg-dir=/usr/include --with-freetype-dir=/usr/include/freetype2RUN docker-php-ext-install gd Docker build1docker build -t ai0by/php-fpm73:v1 . 运行容器挂载物理机内容到 容器内部 可以修改下方的 /var/www/html/workspace 为你的项目地址 1docker run -v /var/www/html/workspace:/var/www/html/workspace -p 9002:9000 -d php73:0.1 Nginx配置修改 fastcgi_pass 后面的 值为 127.0.0.1:9002 LNMP用户 修改 /usr/local/nginx/conf/enable-php-pathinfo.conf 将 fastcgi_pass unix:/tmp/php-cgi.sock; 修改为 fastcgi_pass 127.0.0.1:9002; 其他环境与此类似，直接改即可 MySQL Docker启动自行修改 挂载路径 以及 密码1docker run --restart=always --name mysql5.7 -p 3306:3306 -v /Users/XXX/Downloads/Docker/mysql5.7:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7 --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci Nginx 个人不习惯扔Docker中，因此暂时不管","categories":[{"name":"PHP","slug":"PHP","permalink":"https://sbcoder.cn/categories/PHP/"}],"tags":[{"name":"fpm","slug":"fpm","permalink":"https://sbcoder.cn/tags/fpm/"},{"name":"nginx","slug":"nginx","permalink":"https://sbcoder.cn/tags/nginx/"}]},{"title":"Workerman 适合PHPer使用的Socket通讯框架","slug":"Workerman-适合PHPer使用的Socket通讯框架","date":"2020-05-14T13:48:33.000Z","updated":"2020-05-14T13:51:53.699Z","comments":true,"path":"2020/05/14/workerman.html","link":"","permalink":"https://sbcoder.cn/2020/05/14/workerman.html","excerpt":"","text":"简介适用于 客户端-服务端 客户端-客户端 一对多 多对多的关系，多个客户端之间的长连接通信，聊天室，在线客服，服务端反向推送播报消息 特性：多进程，长连接，高并发，常驻内存… 客户端与worker进程 客户端与worker进程.png 主进程与worker子进程 主进程与worker子进程.png 使用Workerman可以做很多有趣的事。（工业自动化，互联网工业，PLC机械报警…），通过长连接取数据，操作数据等，但PHP并不适用于工业领域。做一个仿im聊天工具，除了前端展示界面，后端也要考虑全面，更多的依赖于长连接。 本文参考 workerman官方文档本文参考 thinksocketio - 基于socketio的聊天室Demo 安装Workerman框架服务端创建一个文件夹 我这里使用 testWebSocket12mkdir testWebSocketcd testWebSocket git形式安装(推荐)1git clone https://github.com/walkor/Workerman 根据官方文档创建一个示例 在 testWebSocket 下创建一个 PHP文件 test.php12345678910111213141516171819&lt;?phpuse Workerman\\Worker;require_once __DIR__ . '/Workerman/Autoloader.php';// 注意：这里与上个例子不同，使用的是websocket协议$ws_worker = new Worker(\"websocket://0.0.0.0:2000\");// 启动4个进程对外提供服务$ws_worker-&gt;count = 4;// 当收到客户端发来的数据后返回hello $data给客户端$ws_worker-&gt;onMessage = function($connection, $data)&#123; // 向客户端发送hello $data $connection-&gt;send('hello ' . $data);&#125;;// 运行workerWorker::runAll() 前端测试前端测试例子代码 直接在Google浏览器执行123456789ws = new WebSocket(\"ws://127.0.0.1:2000\");ws.onopen = function() &#123; alert(\"连接成功\"); ws.send('tom'); alert(\"给服务端发送一个字符串：tom\");&#125;;ws.onmessage = function(e) &#123; alert(\"收到服务端的消息：\" + e.data);&#125;; 效果展示 执行界面.png 服务端界面.png Workermen框架支持的协议1234567891011$websocket_worker = new Worker('websocket://0.0.0.0:2345');// text协议$text_worker = new Worker('text://0.0.0.0:2346');// frame协议$frame_worker = new Worker('frame://0.0.0.0:2347');// tcp Worker，直接基于socket传输，不使用任何应用层协议$tcp_worker = new Worker('tcp://0.0.0.0:2348');// udp Worker，不使用任何应用层协议$udp_worker = new Worker('udp://0.0.0.0:2349');// unix domain Worker，不使用任何应用层协议$unix_worker = new Worker('unix:///tmp/wm.sock'); 整合ThinkPHP说明Workermen是一个成熟的单独框架，在ThinkPHP中也可以使用Composer安装对应的扩展来使用，这里使用了针对PHP开发的扩展 PHPSocket.IO。PHPSocket.IO设计的目标是利用PHP构建能够在不同浏览器和移动设备上良好运行的实时应用，如实时分析系统、在线聊天室、在线客服系统、评论系统、WebIM等。 PHPSocket.IO与workerman的区别是，PHPSocket.IO基于workerman开发，workerman有的特性PHPSocket.IO都支持。 PHPSocket.IO最大的优势是对各种浏览器的兼容性更好。 安装及引用使用Composer 安装对应的扩展1composer require workerman/phpsocket.io 在编辑代码时引用对应的扩展即可12use Workerman\\Worker;use PHPSocketIO\\SocketIO; 服务端创建一个服务端 application\\socketio\\controller\\server.php12345678910111213141516171819202122232425262728293031&lt;?phpnamespace app\\socketio\\controller;use Workerman\\Worker;use PHPSocketIO\\SocketIO;use think\\Db;class Server&#123; public function index()&#123; // 在2021端口创建服务 $io = new SocketIO(2021); $io-&gt;on('connection', function($socket)use($io)&#123; $socket-&gt;on('chat message', function($msg)use($io)&#123; $io-&gt;emit('chat message', $msg); &#125;); // 监听到新的客户端连接即在服务端输出'new connection' echo 'new connection'.\"\\n\"; // 并向服务端发送'连接成功' $socket-&gt;emit('success', '连接成功'); // 服务端发送消息过来 $socket-&gt;on('sendMsg', function($msg)use($io)&#123; // 在服务端输出消息 echo $msg.\"\\n\"; // 在收到的消息前面拼接'收到'后向客户端发送回去 $io-&gt;emit('sendMsg', '收到\"'.$msg.'\"'); &#125;); &#125;); // 启动服务 Worker::runAll(); &#125;&#125; 由于 Workermen 是一个独立于PHP程序使用的单一文件，需要单独用一个命令行来启动的，他完全可以独立使用，因此并不推荐使用TP框架来整合，但如果有这个需求，也可以在 /public目录下生成一个文件来绑定控制器，例如绑定 到 socketio/Server创建文件 public/server.php , 输入以下内容123456789&lt;?php// [ 应用入口文件 ]namespace think;// 加载基础文件require __DIR__ . '/../thinkphp/base.php';// 执行应用并响应（绑定）Container::get('app')-&gt;bind('socketio/Server')-&gt;run()-&gt;send(); 执行时 直接在Shell中运行该PHP文件即可，剩下的交给TP的机制12cd /publicphp server.php 执行结果.png 结语根据通信行为可以衍生出各类应用，目前websocket已经是各大公司都需要的技术，会websocket就多了一份机会！","categories":[{"name":"PHP","slug":"PHP","permalink":"https://sbcoder.cn/categories/PHP/"}],"tags":[{"name":"socket","slug":"socket","permalink":"https://sbcoder.cn/tags/socket/"},{"name":"通讯","slug":"通讯","permalink":"https://sbcoder.cn/tags/通讯/"},{"name":"workerman","slug":"workerman","permalink":"https://sbcoder.cn/tags/workerman/"}]},{"title":"UnblockNeteaseMusic 解锁网易云音乐灰色歌曲","slug":"UnblockNeteaseMusic-解锁网易云音乐灰色歌曲","date":"2020-05-09T13:52:19.000Z","updated":"2020-05-09T13:53:34.444Z","comments":true,"path":"2020/05/09/UnblockNeteaseMusic.html","link":"","permalink":"https://sbcoder.cn/2020/05/09/UnblockNeteaseMusic.html","excerpt":"","text":"Docker 安装运行服务端基于nondanee/UnblockNeteaseMusic的音乐解锁代理服务 1docker run --name=unblockneteasemusic -d -p 8888:8080 nondanee/unblockneteasemusic 日志界面 配置客户端 平台 基础设置 Windows 设置 &gt; 工具 &gt; 自定义代理 (客户端内) UWP Windows 设置 &gt; 网络和 Internet &gt; 代理 Linux 系统设置 &gt; 网络 &gt; 网络代理 macOS 系统偏好设置 &gt; 网络 &gt; 高级 &gt; 代理 Android WLAN &gt; 修改网络 &gt; 高级选项 &gt; 代理 iOS 无线局域网 &gt; HTTP 代理 &gt; 配置代理 Windows配置截图 将ip设置为服务器ip即可，映射内部的8080到外部8888端口 效果 当播放或者下载时，日志会记录，解析过程","categories":[{"name":"折腾","slug":"折腾","permalink":"https://sbcoder.cn/categories/折腾/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://sbcoder.cn/tags/Docker/"},{"name":"音乐","slug":"音乐","permalink":"https://sbcoder.cn/tags/音乐/"}]},{"title":"Aria2 + Rclone + Goindex 实现离线下载在线观看","slug":"Aria2-Rclone-Goindex-实现离线下载在线观看","date":"2020-01-21T23:32:33.000Z","updated":"2020-01-23T00:48:01.000Z","comments":true,"path":"2020/01/22/aria_goindex.html","link":"","permalink":"https://sbcoder.cn/2020/01/22/aria_goindex.html","excerpt":"","text":"准备工作 云阀 5R NAT小鸡 Google Drive 账号一枚 CloudFlare 账号 关于云阀的小鸡，性价比高，只提供ipv6和ipv4端口，因此下面的教程可能某些地方做了多余的动作，例如修改端口号等 安装Aria2一键脚本执行下面的命令1wget -N git.io/aria2.sh &amp;&amp; chmod +x aria2.sh &amp;&amp; ./aria2.sh 进入下载脚本的目录运行脚本123456789101112131415161718192021222324252627./aria2.shAria2 一键安装管理脚本 [vX.X.X]-- P3TERX.COM --1. 升级脚本————————————1. 安装 Aria22. 更新 Aria23. 卸载 Aria2————————————4. 启动 Aria25. 停止 Aria26. 重启 Aria2————————————7. 修改 配置8. 查看 配置9. 查看 日志10. 清空 日志————————————11. 手动更新 BT-Tracker12. 自动更新 BT-Tracker————————————当前状态: 已安装 并 已启动请输入数字 [0-12]: 输入 1 回车 1.png 等待安装完成 再执行1./aria2.sh 输入 7 回车 2.png 如需要可修改 RPC 密码，也建议修改 安装 LNMP 一键安装包 / Nginx我这里安装LNMP，其实只需要 Nginx就行了安装教程参考 安装 - LNMP一键安装包 或者 直接执行1wget http://soft.vpser.net/lnmp/lnmp1.6.tar.gz -cO lnmp1.6.tar.gz &amp;&amp; tar zxf lnmp1.6.tar.gz &amp;&amp; cd lnmp1.6 &amp;&amp; ./install.sh lnmp 我这里安装的是 1.6 ，可自行修改版本号 安装 Aria2NG 界面管理打开地址 Releases · mayswind/AriaNg选择最新版本下载到 网站 目录下，如果不知道网站目录配置，建议存放在 LNMP的默认目录 /home/wwwroot/ 按照如下操作12345mkdir /home/wwwroot/Xcd /home/wwwroot/Xwget https://github.com/mayswind/AriaNg/releases/download/1.1.4/AriaNg-1.1.4.zipunzip AriaNg-1.1.4.ziprm AriaNg-1.1.4.zip 配置 Nginx12cd /usr/local/nginx/conf/vhost/vi X.conf 输入以下配置123456789101112131415161718192021222324252627282930313233343536373839404142server &#123; listen 10002 default_server reuseport; #listen [::]:80 default_server ipv6only=on; server_name _; index index.html index.htm index.php; root /home/wwwroot/x; #error_page 404 /404.html; # Deny access to PHP files in specific directory #location ~ /(wp-content|uploads|wp-includes|images)/.*\\.php$ &#123; deny all; &#125; include enable-php.conf; location /nginx_status &#123; stub_status on; access_log off; &#125; location ~ .*\\.(gif|jpg|jpeg|png|bmp|swf)$ &#123; expires 30d; &#125; location ~ .*\\.(js|css)?$ &#123; expires 12h; &#125; location ~ /.well-known &#123; allow all; &#125; location ~ /\\. &#123; deny all; &#125; access_log /home/wwwlogs/access.log; &#125; 主要就是把端口改为 10002，其他的就是lnmp默认配置不动 配置完毕后，打开 网址 http://virt-nat-eu-1.cloudraft.cn:1XXX5将XX替换成你的 内网IP最后一位 例如 2 则访问 http://virt-nat-eu-1.cloudraft.cn:10025 3.png 点击 Aria2NG配置 - RPC(XXXX) 4.png 修改 RPC 别名 RPC 地址 RPC 秘钥其他不动，按图填写即可 免费申请一个Google无限团队盘打开地址 创建Google TeamDriveGmail必须填写正确！ 等待创建即可！ 安装Rclone执行12curl https://rclone.org/install.sh | sudo bashrclone config 配置说明如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148e) Edit existing remoten) New remoted) Delete remoter) Rename remotec) Copy remotes) Set configuration passwordq) Quit confige/n/d/r/c/s/q&gt; n # 选择n，新建name&gt; Google # 输入名称，类似于标签，用于区分不同的网盘。Type of storage to configure.Enter a string value. Press Enter for the default (&quot;&quot;).Choose a number from below, or type in your own value 1 / A stackable unification remote, which can appear to merge the contents of several remotes \\ &quot;union&quot; 2 / Alias for a existing remote \\ &quot;alias&quot; 3 / Amazon Drive \\ &quot;amazon cloud drive&quot; 4 / Amazon S3 Compliant Storage Providers (AWS, Ceph, Dreamhost, IBM COS, Minio) \\ &quot;s3&quot; 5 / Backblaze B2 \\ &quot;b2&quot; 6 / Box \\ &quot;box&quot; 7 / Cache a remote \\ &quot;cache&quot; 8 / Dropbox \\ &quot;dropbox&quot; 9 / Encrypt/Decrypt a remote \\ &quot;crypt&quot;10 / FTP Connection \\ &quot;ftp&quot;11 / Google Cloud Storage (this is not Google Drive) \\ &quot;google cloud storage&quot;12 / Google Drive \\ &quot;drive&quot;13 / Hubic \\ &quot;hubic&quot;14 / JottaCloud \\ &quot;jottacloud&quot;15 / Local Disk \\ &quot;local&quot;16 / Mega \\ &quot;mega&quot;17 / Microsoft Azure Blob Storage \\ &quot;azureblob&quot;18 / Microsoft OneDrive \\ &quot;onedrive&quot;19 / OpenDrive \\ &quot;opendrive&quot;20 / Openstack Swift (Rackspace Cloud Files, Memset Memstore, OVH) \\ &quot;swift&quot;21 / Pcloud \\ &quot;pcloud&quot;22 / QingCloud Object Storage \\ &quot;qingstor&quot;23 / SSH/SFTP Connection \\ &quot;sftp&quot;24 / Webdav \\ &quot;webdav&quot;25 / Yandex Disk \\ &quot;yandex&quot;26 / http Connection \\ &quot;http&quot;Storage&gt; 12 # 选择12，Google Drive** See help for drive backend at: https://rclone.org/drive/ **Google Application Client IdLeave blank normally.Enter a string value. Press Enter for the default (&quot;&quot;).client_id&gt; # 留空，回车Google Application Client SecretLeave blank normally.Enter a string value. Press Enter for the default (&quot;&quot;).client_secret&gt; # 留空，回车Scope that rclone should use when requesting access from drive.Enter a string value. Press Enter for the default (&quot;&quot;).Choose a number from below, or type in your own value 1 / Full access all files, excluding Application Data Folder. \\ &quot;drive&quot; 2 / Read-only access to file metadata and file contents. \\ &quot;drive.readonly&quot; / Access to files created by rclone only. 3 | These are visible in the drive website. | File authorization is revoked when the user deauthorizes the app. \\ &quot;drive.file&quot; / Allows read and write access to the Application Data folder. 4 | This is not visible in the drive website. \\ &quot;drive.appfolder&quot; / Allows read-only access to file metadata but 5 | does not allow any access to read or download file content. \\ &quot;drive.metadata.readonly&quot;scope&gt; 1ID of the root folderLeave blank normally.Fill in to access &quot;Computers&quot; folders. (see docs).Enter a string value. Press Enter for the default (&quot;&quot;).root_folder_id&gt; # 留空，回车Service Account Credentials JSON file pathLeave blank normally.Needed only if you want use SA instead of interactive login.Enter a string value. Press Enter for the default (&quot;&quot;).service_account_file&gt;Edit advanced config? (y/n)y) Yesn) Noy/n&gt; nRemote configUse auto config? * Say Y if not sure * Say N if you are working on a remote or headless machine or Y didn&apos;t worky) Yesn) Noy/n&gt; nIf your browser doesn&apos;t open automatically go to the following link: https://accounts.google.com/o/oauth2/auth?access_type=offline&amp;client_id=XXXXXXXXXXX.apps.googleusercontent.com&amp;redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&amp;response_type=code&amp;scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&amp;state=XXXXXXXXXXXXXXXXXXXXLog in and authorize rclone for access # 会弹出浏览器，要求你登录账号进行授权。如果没有弹出，复制上面的链接到浏览器中打开进行授权。Enter verification code&gt; # 在这里输入网页上显示的验证码Configure this as a team drive?y) Yesn) Noy/n&gt; yFetching team drive list...No team drives found in your account--------------------[Google]type = drivescope = drivetoken = &#123;&quot;access_token&quot;:&quot;XXXXXXXXXXXXXXXXXXXXX&quot;&#125;--------------------y) Yes this is OKe) Edit this remoted) Delete this remotey/e/d&gt; yCurrent remotes:Name Type==== ====Google driveOne onedrivee) Edit existing remoten) New remoted) Delete remoter) Rename remotec) Copy remotes) Set configuration passwordq) Quit confige/n/d/r/c/s/q&gt; q 参考:P3TERX - Rclone 安装配置教程 - 连接 OneDrive 和 Google Drive 配置 Aira2 自动上传执行 按图修改1vi /root/.aria2/autoupload.sh 5.png 执行 按图修改1vi /root/.aria2/aria2.conf 6.png 重启 Aria21service aria2 restart 使用Goindex + CloudFlare搞一个在线观看官方说明 donwa/Github 复制 index.js 里面的代码 打开 CloudFlare ，创建Workers 7.png 将上面复制的内容黏贴到Script中 执行 并 查看 rclone.conf 路径。1rclone config file 8.png 复制 root_folder_id 和 refresh_token 的值填入 CloudFlare Workers Script对应的代码位置里面 9.png 配置好后点击保存，然后打开CloudFlare Workers提供的域名即可看到对应的网盘内容 作者博客 风向标博客","categories":[{"name":"折腾","slug":"折腾","permalink":"https://sbcoder.cn/categories/折腾/"}],"tags":[{"name":"离线下载","slug":"离线下载","permalink":"https://sbcoder.cn/tags/离线下载/"},{"name":"Google","slug":"Google","permalink":"https://sbcoder.cn/tags/Google/"}]},{"title":"Canal 根据 binlog日志数据同步","slug":"Canal-根据-binlog日志数据同步","date":"2020-01-21T23:32:09.000Z","updated":"2020-01-21T23:33:46.000Z","comments":true,"path":"2020/01/22/canal_go.html","link":"","permalink":"https://sbcoder.cn/2020/01/22/canal_go.html","excerpt":"","text":"创建mysql账户如果使用的是root用户，则不需要操作这个步骤 grant all privileges on . to ‘jcc’@’%’ identified by ‘jcc’;flush privileges; 配置mysql (参见canal Quickstart)启用binlog日志打开 mysql.cnf 文件1234[mysqld] log-bin=mysql-bin binlog-format=ROW #选择row模式 server_id=9527 #配置mysql replaction需要定义，不能和canal的slaveId重复 添加slave权限如果使用的是root用户，则不需要操作这个步骤12CREATE USER canal IDENTIFIED BY 'canal'; GRANT SELECT, SHOW VIEW, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'canal'@'%';FLUSH PRIVILEGES; 创建canal server 服务端需要提前安装好Docker，如果不会安装，可以参考我之前写的文章 CentOS7 安装 Docker 1docker run -p 11111:11111 -e canal.auto.scan=false -e canal.instance.master.address=127.0.0.1:3306 -e canal.instance.dbUsername=test -e canal.instance.dbPassword=test -e canal.instance.connectionCharset=UTF-8 -e canal.instance.tsdb.enable=true -e canal.instance.gtidon=false -e canal.instance.filter.regex=.*\\\\..* -e canal.destinations=test -d canal/canal-server 需要替换以下参数 canal.instance.master.address=127.0.0.1:3306 地址ip更换（尽量用内网） canal.instance.dbUsername=test 数据库账户 canal.instance.dbPassword=test 数据库密码 canal.destinations=test test为名称 可以修改 11111:11111 服务器端口：docker端口 需要注意的是，所填写的数据库账户必须拥有数据库的操作权限，如果不知道权限如何配置，则建议直接使用root用户 canal 客户端我们这里使用Go客户端，因为Go语言的特性，可以很好的运行在Docker上 canal-go 文档: withlin/canal-go 开发过程可以参照文档 Docker启动canal客户端推荐使用Jenkins配置 canal-go构建成功后执行shell 12docker build -t canal_prod:v1 $&#123;WORKSPACE&#125;docker service update --image canal_prod:v1 --force --no-resolve-image canal_prod 如果看过我之前的 代码架构文章，可以在Portainer中看到打印在控制台的文字，也可以看到运行状态 FAQ问题解决Q:如果服务停止了，如何解决A:链接到canal-server的Docker内部，查看 canal-server - logs 中的日志 Q:如果数据同步失败了如何解决A:很大可能是由于改变了数据库结构导致的，需要重启客户端和服务端尝试 Q:一开始数据就不同步A:查看你的数据库账户是否有权限，如无权限则修改服务端启动时附带的数据库账户参数","categories":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/categories/优化/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://sbcoder.cn/tags/数据库/"},{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/tags/优化/"}]},{"title":"ThinkPHP使用RabbitMQ进行数据解耦 从安装到监听完全版","slug":"ThinkPHP使用RabbitMQ进行数据解耦-从安装到监听完全版","date":"2020-01-07T15:32:40.000Z","updated":"2020-01-07T15:33:42.000Z","comments":true,"path":"2020/01/07/rabbitmq_thinkphp.html","link":"","permalink":"https://sbcoder.cn/2020/01/07/rabbitmq_thinkphp.html","excerpt":"","text":"介绍分布式部署，RabbitMQ(简称MQ)作为消息中间件是一个非常不错的选择，可以实现异步互不干扰的解耦操作。 解决需求当有两套系统分别部署时，需要同步一部分数据，或者需要互不干扰解决异步独立运行时，可以使用RebbitMQ来给两套系统解耦，使用RebbitMQ作为中间件，只做消息传输使用，当系统A宕机或者因故障无法使用时，不会影响到系统B的正常运行！ 部署MQ使用Docker部署，安装Docker可以参照之前写的 CentOS7 安装 Docker，或者Ubuntu16.04/Ubuntu18.04 安装 Docker。 下载镜像镜像地址 rabbitmq1docker pull rabbitmq:management 1.png 1234# 创建容器并运行docker run -d -p 5672:5672 -p 15672:15672 --name rabbitmq rabbitmq:management# 查看 当前运行的容器docker ps 2.png 配置MQ安装MQ打开 http://IP:15672 3.png 使用默认用户名密码登录username:guest password:guest 4.png 红框内为你的rabbitmq版本号，我这里是3.8.2 创建一个管理员用户 5.png 修改guest的密码，请将123456修改为你需要修改的密码123docker exec -it rabbitmq /bin/bashrabbitmqctl list_usersrabbitmqctl change_password guest &apos;123456&apos; 修改guest默认密码以防止被人恶意利用 6.png 创建队列及交换机创建队列可以在mq页端创建也可以在代码中自动创建，我这里直接在页端创建 创建Queen 创建交换机，也在页端创建好 创建Exchange ThinkPHP实现过程Composer安装php-amqplib略 生产者实现 创建一个生产者类放置于 common 目录下，方便调用 123456789101112131415161718192021222324252627282930313233343536class RabbitMq&#123; protected $connection; protected $channel; //protected $exchange = 'router'; // //protected $queue = 'msgs'; public function __construct()&#123; $this-&gt;connection = new AMQPStreamConnection(config('rabbit_mq.host'), config('rabbit_mq.port'), config('rabbit_mq.user'), config('rabbit_mq.password')); $this-&gt;channel = $this-&gt;connection-&gt;channel(); &#125; /* * 向队列发送信息（生产者） * $data 向队列发送参数 * $code 路由名 * $queue 主题 * */ public function send($data,$exchange,$routing_key='order')&#123;// $this-&gt;channel-&gt;queue_declare($this-&gt;queue, false, true, false, false);// $this-&gt;channel-&gt;exchange_declare($this-&gt;exchange, AMQPExchangeType::DIRECT, false, true, false);// $this-&gt;channel-&gt;queue_bind($this-&gt;queue, $this-&gt;exchange); $messageBody = json_encode($data);//将要发送数据变为json字符串 $message = new AMQPMessage($messageBody, array('content_type' =&gt; 'text/plain', 'delivery_mode' =&gt; AMQPMessage::DELIVERY_MODE_PERSISTENT)); $this-&gt;channel-&gt;basic_publish($message,$exchange,$routing_key); $this-&gt;stop(); &#125; //关闭进程 public function stop()&#123; $this-&gt;channel-&gt;close(); $this-&gt;connection-&gt;close(); &#125;&#125; 实现过程如下 123456789101112131415161718192021222324252627class RabbitMq extends controller&#123; private $rabbitMq; /** * Unit constructor. * @param Request $request * @throws \\think\\db\\exception\\DataNotFoundException * @throws \\think\\db\\exception\\ModelNotFoundException * @throws \\think\\exception\\DbException */ public function __construct(Request $request)&#123; parent::__construct(); $this-&gt;rabbitMq = new \\app\\common\\RabbitMq(); &#125; /** * 添加 * @throws \\think\\db\\exception\\DataNotFoundException * @throws \\think\\db\\exception\\ModelNotFoundException * @throws \\think\\exception\\DbException */ public function add()&#123; $params = $this-&gt;request-&gt;param(); $this-&gt;rabbitMq-&gt;send($params,'testMq'); &#125;&#125; 消费者实现 创建一个RabbitMq类,方便之后调用 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768class RabbitMq extends controller&#123; protected $connection; protected $channel; protected $exchange; // protected $queue; protected $vhost; protected $consumerTag; protected $routeKey; // 此处使用配置文件配置，具体可自行配置 public function __construct() &#123; //连接RabbitMQ $this-&gt;queue = Config::get('database.RabbitMQ')['queue']; $this-&gt;exchange = Config::get('database.RabbitMQ')['exchange']; $this-&gt;vhost = Config::get('database.RabbitMQ')['vhost']; $this-&gt;consumerTag = 'AgentOrder'; $this-&gt;routeKey = 'addOrderAndSub'; $host = Config::get('database.RabbitMQ')['host']; $port = Config::get('database.RabbitMQ')['port']; $username = Config::get('database.RabbitMQ')['username']; $password = Config::get('database.RabbitMQ')['password']; $this-&gt;connection = new AMQPStreamConnection($host, $port, $username, $password); $this-&gt;channel = $this-&gt;connection-&gt;channel(); $this-&gt;logMqWright('MQ已连接'); &#125; // 消费信息 public function getMessage($callback) &#123; // 队列声明，创建队列，如果不存在则自动创建，如已创建则不需要使用 // $this-&gt;channel-&gt;queue_declare($this-&gt;queue, false, true, false, false); // 绑定交换机 $this-&gt;channel-&gt;exchange_declare($this-&gt;exchange, 'direct', false, true, false); $this-&gt;logMqWright('---MQ交换机绑定完成---'); // 绑定队列 $this-&gt;channel-&gt;queue_bind($this-&gt;queue, $this-&gt;exchange, $this-&gt;routeKey); $this-&gt;logMqWright('---MQ队列绑定完成---'); // 信息消费，no_ack 为true时为自动应答 $this-&gt;channel-&gt;basic_consume($this-&gt;queue, $this-&gt;consumerTag, false, true, false, false, $callback); $i = 0; while (count($this-&gt;channel-&gt;callbacks)) &#123; $this-&gt;logMqWright('---MQ执行次数统计[' . $i . ']---'); $i++; $this-&gt;channel-&gt;wait(); &#125; &#125; // 日志写入函数 目录/runtime/agent_log/当前年月/当前日期MQ.txt protected function logMqWright($msg) &#123; $val = \"\"; $currentDateTime = date('Y-m-d H:i:s', time()); $currentDate = date('Ymd', time()); $fileDir = __DIR__ . '/../../runtime/' . 'agentlog/' . date('Ym', time()); if (!file_exists($fileDir)) &#123; mkdir($fileDir, 0777, true); &#125; $fileName = $fileDir . '/' . $currentDate . \"MQ.txt\";//文件名称 $data = fopen($fileName, 'a+');//添加不覆盖，首先会判断这个文件是否存在，如果不存在，则会创建该文件，即每天都会创建一个新的文件记录的信息 $val = '[' . $currentDateTime . ']:' . $msg; $val .= \"\\n\"; fwrite($data, $val);//写入文本中 &#125; //关闭进程 public function stop() &#123; $this-&gt;channel-&gt;close(); $this-&gt;connection-&gt;close(); &#125;&#125; 消费者消费过程 1234567891011// CLI接口,需要开启守护进程 public function catch() &#123; //连接RabbitMQ $RabbitMq = new \\app\\common\\RabbitMq();//队列 $this-&gt;logAgentWrite('------------------MQ链接成功 开始整理MQ消息------------------'); $callback = function ($msg) &#123; echo $msg; // msg为队列内的信息流，在此处填写消费过程即可 &#125;; $RabbitMq-&gt;getMessage($callback); &#125; 消费者创建监听接口，用于守护进程调用 12345678class MqService&#123; public function __construct() &#123; &#125; public function mqAction() &#123; $this-&gt;catch(); // 调用上面的catch函数，自行修改 &#125;&#125; 至此所需要的代码就完成了 消费者脚本守护进程tips:只适用于Linux 我们在使用PHP作为消费者时，一般是使用PHP直接执行文件，使用nohup守护进程调用，但是当系统不稳定时，可能会出现各种问题导致mq队列失效，这时候就需要使用脚本监听，如果守护进程不存在，则自动重启守护进程 首先测试时可以先执行守护进程命令，例如1nohup /usr/bin/php7.2 /alidata/workspace/test/public/index.php /api_comm/mq_service/mqAction &amp; 路径请自行修改 监听信息编写Shell如下 1234567891011121314151617181920#!/bin/shfile_name=\"/root/restartMqService.log\" #重启脚本的日志，保证可写入，保险一点执行 chmod 777 restartMqService.logpid=0proc_num() &#123; num=`ps -ef | grep '/usr/bin/php7.2 /alidata/workspace/test/public/index.php /api_comm/mq_service/mqAction' | grep -v grep | wc -l` #此处'nohup /usr/bin/php7.2 /alidata/workspace/test/public/index.php /api_comm/mq_service/mqAction &amp;'替代为实际的，尽量准确，避免误kill return $num &#125;proc_id()&#123; pid=`ps -ef | grep '/usr/bin/php7.2 /alidata/workspace/test/public/index.php /api_comm/mq_service/mqAction' | grep -v grep | awk '&#123;print $2&#125;'` #此处'nohup /usr/bin/php7.2 /alidata/workspace/test/public/index.php /api_comm/mq_service/mqAction &amp;'也替代为实际的&#125; proc_num #执行proc_num()，获取进程数number=$? #获取上一函数返回值if [ $number -eq 0 ] #如果没有该进程，则重启then nohup /usr/bin/php7.2 /alidata/workspace/test/public/index.php /api_comm/mq_service/mqAction &amp; #启动程序的命令 proc_id echo $&#123;pid&#125;, `date` &gt;&gt; $file_name #把重启的进程号、时间 写入日志fi 将该脚本重命名为 mqMonitor.sh 配置Crontab在crontab配置文件下加上一行1*/2 * * * * sh /root/mqMonitor.sh 保存后重启生效，大致是2分钟监测一次，可自行修改","categories":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/categories/优化/"}],"tags":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/tags/优化/"},{"name":"消息队列","slug":"消息队列","permalink":"https://sbcoder.cn/tags/消息队列/"},{"name":"解耦","slug":"解耦","permalink":"https://sbcoder.cn/tags/解耦/"}]},{"title":"公司代码架构 - Docker + Jenkins + Gogs + Portainer(四)","slug":"公司代码架构-Docker-Jenkins-Gogs-Portainer-四","date":"2019-12-13T23:35:13.000Z","updated":"2019-12-18T12:51:18.000Z","comments":true,"path":"2019/12/14/docker_swarm.html","link":"","permalink":"https://sbcoder.cn/2019/12/14/docker_swarm.html","excerpt":"","text":"Portainer + Swarm 管理Docker集群介绍Portainer是一个Docker管理工具，它支持多种方式，我们这里只写，远程链接形式和本地形式 搭建环境 服务器1 ：Virmach 水牛城 RAM1.8G 2C 10GSSD（黑五机器） 操作系统 ：Ubuntu16.04 部署环境 ：LNMP1.6 （我是军哥铁粉） 服务器1：搭建Jenkins中转服务器，做代码自动构建使用服务器2：生产环境服务器，实则测试服务器，部署代码使用服务器3：Gogs服务器，Git版本库服务器，做代码版本控制使用 配置Portainer开放DockerAPI端口将需要加入Portainer管理的服务器（需要安装过Docker），打开2375端口，方便管理 创建一个备份，并编辑配置文件12cp /lib/systemd/system/docker.service /lib/systemd/system/docker.service.bak vi /lib/systemd/system/docker.service 方法一：在ExecStart整行后面添加 -H tcp://0.0.0.0:2375，有的时候他可能不止一行，则在最后面增加这一段即可，如下 2.png :wq 保存退出 方法二（推荐）：本方法并不适用于所有的Docker版本1vi /etc/docker/daemon.json 复制以下内容123456&#123; \"hosts\": [ \"tcp://0.0.0.0:2375\", \"unix:///var/run/docker.sock\" ]&#125; 配置完后重启Docker12systemctl daemon-reload systemctl restart docker 这里推荐大家使用iptables防火墙限制一下2375端口的访问，如果将2375暴露在公网则可能出现一系列安全问题，如果是国内的腾讯或者阿里，则可以直接在后台配置安全组，安全组里限制 指定IP访问指定端口即可，如果将2375暴露在外，则可能受到黑客恶意攻击！ 如果不是国内机器，也可以通过iptables限制访问1234iptables -I INPUT -s 107.173.XXX.XXX -p tcp --dport 2375 -j ACCEPTsystemctl iptables.service savesystemctl restart iptables.service# systemctl stop iptables.service 如果配置有误可以停止iptables尝试 非常不推荐直接将2375暴露在公网，秒被黑~ 配置后的效果如下图 3.png 安装Portainer创建数据1docker volume create portainer_data 创建Portainer并运行1docker run -d -p 8000:8000 -p 9000:9000 -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer 执行后访问 http://ip:9000即可看到 1.png 刚创建完会提示创建一个管理员用户，按照提示创建即可 选择创建Docker时使用Remote，远程连接，按下图填写 4.png 添加完成后如下图，点击访问创建好的节点则可以操作里面的内容 5.png 创建Swarm集群在管理节点上增加Swarm集群manager节点12docker swarm init --advertise-addr [IP ADDRESS]# 例如 docker swarm init --advertise-addr 107.173.XXX.XXX 返回结果如下，为了安全，关键位置已打码1234567Swarm initialized: current node (mjjrpuemaukx5a185iqd54mka) is now a manager.To add a worker to this swarm, run the following command: docker swarm join --token SWMTKN-1-1zd********2oci43nbf1jjhlng8k********fhfzqw2-1ywv79qnvmlb*******h3gs35r 107.173.XXX.XXX:2377To add a manager to this swarm, run &apos;docker swarm join-token manager&apos; and follow the instructions. 当Manager节点增加完成后，可以在子节点中输入上面提示的命令以worker形式加入集群1docker swarm join --token SWMTKN-1-1zd********2oci43nbf1jjhlng8k********fhfzqw2-1ywv79qnvmlb*******h3gs35r 107.173.XXX.XXX:2377 子节点加入成功后可以在父节点中查看子节点信息1docker node ls 6.png 如果在Portainer增加manager节点，则会自动出现 Swarm 和 Service选项，如图 7.png 结语本次搭建过程就基本完成了，我们可以通过Portainer管理之前搭建的一系列环境，至此，一套简单的公司架构就完成了，生产环境也可以做到实时构建，只需要在Gogs上面发布版本就可以了，选择手动构建，构建时选择版本号即可，这样做的好处是如果正式环境有bug时可以随时回滚到稳定版本，当然，发布版本也是建立在测试完后的场景！","categories":[{"name":"架构","slug":"架构","permalink":"https://sbcoder.cn/categories/架构/"}],"tags":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/tags/优化/"},{"name":"架构","slug":"架构","permalink":"https://sbcoder.cn/tags/架构/"},{"name":"版本控制","slug":"版本控制","permalink":"https://sbcoder.cn/tags/版本控制/"}]},{"title":"公司代码架构 - Docker + Jenkins + Gogs + Portainer(三)","slug":"公司代码架构-Docker-Jenkins-Gogs-Portainer-三","date":"2019-12-11T11:09:38.000Z","updated":"2019-12-11T11:10:26.000Z","comments":true,"path":"2019/12/11/jenkins_docker.html","link":"","permalink":"https://sbcoder.cn/2019/12/11/jenkins_docker.html","excerpt":"","text":"配置Jenkins实现自动构建介绍前面已经搭建好了基本环境，剩下的就是自动构建了，这里就需要使用我们的构建工具Jenkins，Jenkins是一个非常牛逼的东西，它可以实现代码同步构建，当你修改你的代码并传到git时，Jenkins可以自动将你的代码同步到服务器上面，当然这只是Jenkins的基本功能之一，他还有非常多的东西值得我们学习~ 搭建环境 服务器2 ：Pacificrack 洛杉矶 RAM2G 2C 35GSSD（圣诞机器）18刀 操作系统 ：CentOS7.5 部署环境 ：LNMP1.6 （我是军哥铁粉） + Java8 服务器1：搭建Jenkins中转服务器，做代码自动构建使用服务器2：生产环境服务器，实则测试服务器，部署代码使用服务器3：Gogs服务器，Git版本库服务器，做代码版本控制使用 生产环境搭建服务器2的生产环境搭建。 生产环境，主要就是LNMP和Java8，LNMP是可选的，看需要部署的程序环境，例如需要部署node.js则只需要node.js环境即可，其他同理，我这边是准备自动部署PHP程序，因此就还是使用LNMP； Java8是必须的，Jenkins使用SSH连接到服务器时是需要源服务器有Java环境的 安装LNMPLNMP环境安装教程 : LNMP一键安装包 - 安装教程 安装Java8Jenkins连接节点的服务器必须安装！其他服务器无需安装！ 首先更新 yum 源1yum update 安装 jdk1.81yum install java-1.8.0-openjdk java-1.8.0-openjdk-devel 这里注意，是可以选择Java版本的，我这里使用了8所以按照8的方式安装的 可以搜索yum选择需要安装的版本1yum search java | grep jdk 一般 使用上面方法安装的Java配置文件都在 /etc/profile 编辑配置1vi /etc/profile 在末尾添加 环境变量，注意修改自己的版本号12345JAVA_HOME=/user/lib/jvm/java-1.8.0-openjdk-1.8.0.191.b12-1.el7_6.x86_64JRE_HOME=$JAVA_HOME/jreCLASS_PATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libPATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binexport JAVA_HOME JRE_HOME CLASS_PATH PATH 重置 profile1source /etc/profile 查看Java版本1java -version Jenkins配置安装必要的插件打开Jenkins登录后 打开 系统管理 - 插件管理 - 可选插件 搜索 安装 以下插件 汉化语言包(可选) Locale plugin Localization: Chinese (Simplified) Docker容器(可选) Docker Pipeline 远程连接(必须) SSH plugin SSH Slaves plugin Oracle Java SE Development Kit Installer Plugin Git服务(推荐) GitHub plugin Gogs plugin 推荐安装(可选) bouncycastle API Plugin Branch API Plugin Command Agent Launcher Plugin 插件属于按需配置，不适合自己的插件无需安装 增加节点增加节点必须要先在节点服务器配置Java环境，参照上面的配置Java8环境配置！如果没有配置Java环境则会报错！ 增加节点必须要有SSH插件，因此如果界面与我不一样请检查自己是否安装了上面的插件 打开Jenkins 系统管理 - 节点管理 - 新建节点 1.png 新建节点页面如下 2.png 如果没有设置过凭证则选择添加，界面如下 3.png 全部设置完点保存，他会自动启动代理节点 首页左下角会显示状态 4.png 或者在节点管理里面也可以看到 配置Gogs WebHook根据上一节我们配置好的Gogs，新建一个仓库，这里不多说，直接点加号就行，用过Github的都懂 可以选择公有仓库或者私有仓库，我这里都是私有仓库，也可以使用Gogs的迁移外部仓库功能直接迁移，迁移时可能会出现504错误，这是因为Nginx的反向代理时有超时设置，超过指定时间则直接504，我们在迁移仓库时经常会超时，因此建议修改一下默认超时时间，具体配置可以自行搜索，不多赘述。 找到需要自动构建的仓库，选择 仓库设置 - 管理 Web 钩子 - 添加Web钩子 6.png 注意：图中红框处的test需要跟后面配置的Jenkins对应，例如我创建的Jenkins任务名为 test 则此处填写test，修改域名为你的Jenkins域名，其他格式一致 注意：图中秘钥可随便填写，记录下来，配置Jenkins任务时会用到 配置Jenkins任务打开 Jenkins 新建任务，如果以前没有任务则首页会显示 创建一个新任务 5.png 配置Jenkins任务 7.png 描述部分可随便填写，这里主要配置一下 Gogs Webhook 勾选 Use Gogs secret，Secret填写上面创建Gogs WebHook时的秘钥 勾选 限制项目的运行节点 ，标签表达式填写你的节点名字，例如我这里的节点名字就是我的服务器ip地址，直接填写ip地址即可 8.png 源码管理选择Git，Repository URL选择需要自动构建的Git项目地址，http形式的，Credentials处为验证，如果是公共仓库则无需配置，如果是私有库则需要填写登录到 Gogs 的账户和密码，配置与之前的节点配置凭据一样，不多赘述 指定分支填写需要自动构建的分支，我这里填写的是dev分支，用来做开发版测试使用，根据自己情况来即可 配置上线Nginx配置由于我创建的节点 目录地址是 /home/wwwroot 在项目自动构建时，则会自动创建目录 /home/wwwroot/workspace/[JOB NAME]JOB NAME 为 任务名，例如我的 test 则自动创建目录 /home/wwwroot/workspace/test Nginx则只需要配置 域名解析即可 1lnmp vhost add 9.png 按图上配置即可，建议增加SSL证书，增加证书前记得先把域名解析到指定服务器IP上，否则会生成证书失败 记得给文件夹加上权限，755 构建返回Jenkins，点击立即构建，第一次构建时间可能会长一些，等待即可! 构建完成后则会在 配置的目录下创建workspace目录，并将代码放入 /home/wwwroot/workspace/test 目录中，根据自己的配置自行修改目录 由于我的程序涉及到跨目录访问，因此需要更改 fastcgi.conf 文件，与本文无关这里不多说~ 附一张成功截图，由于我这是前后端分离项目，因此没有界面~ 10.png 自动构建上面已经配置好了自动构建，我们每次合并代码或者提交代码变更到dev分支时，Gogs则会以Webhook的形式将内容推送到Jenkins上面去，实现每次更新代码自动构建服务器代码。 结语目前搭建好的架构，适合还在开发测试程序的开发小组，配合测试人员使用，也能让产品们在汇报工作进度的时候更得心应手，了解开发进度，当然也不是特别准确的开发进度，摸鱼还是要摸的。后面应该会写一下 Portainer + Swarm 管理Docker集群，慢慢写~","categories":[{"name":"架构","slug":"架构","permalink":"https://sbcoder.cn/categories/架构/"}],"tags":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/tags/优化/"},{"name":"架构","slug":"架构","permalink":"https://sbcoder.cn/tags/架构/"},{"name":"版本控制","slug":"版本控制","permalink":"https://sbcoder.cn/tags/版本控制/"}]},{"title":"公司代码架构 - Docker + Jenkins + Gogs + Portainer(二)","slug":"公司代码架构-Docker-Jenkins-Gogs-Portainer-二","date":"2019-12-10T11:05:36.000Z","updated":"2019-12-10T11:07:02.000Z","comments":true,"path":"2019/12/10/gogs_docker.html","link":"","permalink":"https://sbcoder.cn/2019/12/10/gogs_docker.html","excerpt":"","text":"安装 Gogs + Docker常用命令介绍本节主要写一下Jenkins的配置与自动构建过程，包括使用Gogs作为git服务器，配置自动构建等。本节需要配合上一节的内容使用，即 安装 Docker + Jenkins 的服务器一台 搭建环境 服务器3 ：TencentCloud 北京 RAM4G 2C 40GSSD（新用户机器）998RMB/3Year 操作系统 ：CentOS7.5 部署环境 ：LNMP1.6 （我是军哥铁粉） 服务器1：搭建Jenkins中转服务器，做代码自动构建使用服务器2：生产环境服务器，实则测试服务器，部署代码使用服务器3：Gogs服务器，Git版本库服务器，做代码版本控制使用 配置无需对标，都是低配置小鸡，唯一一个腾讯云 2C4G 的机器是我之前放其他业务的机器，由于git经常需要使用因此搭建在国内套CloudFlare使用，实则Gogs只需要 2C1G 机器即可，官方推荐配置是2C512M，是一个不吃内存的程序，目前腾讯云的 1C2G 只需要99/年，属于大众所承受的起的价格，由于我不是专职AFFMAN，因此不贴链接 CentOS7 安装 Docker1yum -y install docker 1.png 12start dockerenable docker 2.png 查看版本号，查看是否安装成功！1docker -v 3.png Docker 常用命令记录一下安装时可能会出现的问题，以及常用的Docker命令 查看当前运行的容器1docker ps 查看所有容器1docker ps -a 停止容器12docker stop [DOCKER NAME] # 例如：docker stop gogs 删除容器(必须在Stop之后才可以删除)12docker rm [DOCKER NAME] # 例如：docker rm gogs 进入容器1234docker attach [DOCKER NAME] # 例如： docker attach gogsdocker exec -it [DOCKER IMAGE ID] /bin/bash# 例如： docker exec -it ef5cb0692b57 /bin/bash 退出容器1exit 查看容器变动日志12docker diff [DOCKER NAME]# 例如：docker diff gogs 查看容器或者镜像详细信息12sudo docker inspect [IMAGE NAME]:0.1 # 例如： sudo docker inspect gogs 向容器内部发送指令12docker exec [DOCKER NAME] [COMMAND]# 例如 docker exec gogs ls 安装 Gogs安装下载镜像 Gogs1docker pull gogs/gogs 4.png 创建目录12mkdir -p /home/Gogscd /home/Gogs 5.png 开启Docker1234# 直接启动docker run --name=gogs -p 10022:22 -p 10080:3000 -v /home/Gogs:/data gogs/gogs# 后台启动docker run --name=gogs -d -p 10022:22 -p 10080:3000 -v /home/Gogs:/data gogs/gogs 配置正常启动后直接打开 http://ip:10080即可 如图： 6.png 接下来按照提示配置即可，我们这里使用SQLite3 应用配置需要注意一下 域名填写你的服务器公网IP SSH端口号填写 映射的端口号 10022 HTTP端口号填写 3000 应用URL填写 ip + 映射的端口号 10080 访问 7.png 配置完成后如果设置好管理员账户的会自动登录进去，如果没有设置的可以自行注册。 注意：数据库中第一个用户就是管理员账户 8.png Tips：Gogs的配置文件存放在 Docker中的 /data/gogs/conf/app.ini 如果想要更改可以 反向代理绑定域名同 公司代码架构 - Docker + Jenkins + Gogs + Portainer(一)一样，在应用配置阶段修改或者修改配置文件都可以 结语Gogs 是一个轻量级的 Git服务器，适用于一些小公司小团队使用，大公司使用Gitlab的情况可能更多一些，但是东西实际都是差不多的，为了占用资源更小一些，我这里还是选用了比较轻量级的Gogs","categories":[{"name":"架构","slug":"架构","permalink":"https://sbcoder.cn/categories/架构/"}],"tags":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/tags/优化/"},{"name":"架构","slug":"架构","permalink":"https://sbcoder.cn/tags/架构/"},{"name":"版本控制","slug":"版本控制","permalink":"https://sbcoder.cn/tags/版本控制/"}]},{"title":"公司代码架构 - Docker + Jenkins + Gogs + Portainer(一)","slug":"公司代码架构 - Docker + Jenkins + Gogs + Portainer(一)","date":"2019-12-09T11:47:26.000Z","updated":"2019-12-10T11:07:37.000Z","comments":true,"path":"2019/12/09/code_build.html","link":"","permalink":"https://sbcoder.cn/2019/12/09/code_build.html","excerpt":"","text":"公司代码架构 - Docker + Jenkins + Gogs + Portainer(一)介绍公司研发项目时，遇到git作为版本控制时，很常见的问题是部署比较麻烦（相比较麻烦），需要先克隆在拉到服务器部署，代码提交频率过高时，就会出现一天很多次提交代码，部署代码，浪费了大量的人力物力，于是乎大量的架构师技术总监们开始研究各类解决方案，各种上线前review代码，这是一件非常痛苦的事情，这里简单记录一下公司代码架构的部署，来解决公司代码架构上的诸多问题，也是自己做一个笔记，文章内如有错误，还请各位指出。 Tips：该环境并不适用于个人用户以及小微企业，适用于项目众多且开发人员大于30人的公司 搭建环境 服务器1 ：Virmach 水牛城 RAM1.8G 2C 10GSSD（黑五机器） 操作系统 ：Ubuntu16.04 部署环境 ：LNMP1.6 （我是军哥铁粉） 这里说明一下，多台服务器是为了解耦，说是解耦，实则认为承受不住，且大部分公司已经有一套完整的git服务器了，本节要做的就是加个自动构建而已，git服务器可自选环境，后面会讲如何搭建Gogs，如果有高配置服务器的公司或个人，可以尝试使用单服务器多部署，本文所需共三台服务器。 服务器1：搭建Jenkins中转服务器，做代码自动构建使用服务器2：生产环境服务器，实则测试服务器，部署代码使用服务器3：Gogs服务器，Git版本库服务器，做代码版本控制使用 服务器1的配置属于中下配置，该机型一年 13刀，属于大部分人都承受的起的价格，请注意，本文标注的配置仅用于配置自动构建服务器，并不用于部署代码以及Git服务，个人用户小鸡多的可以尝试 Ubuntu16.04/Ubuntu18.04 安装 DockerDocker可以说是非常的牛X了，关于他的概念不多说，牛就牛在管理太方便了，就好像是 WHMCS 用母鸡开小鸡一样，母鸡永远不考虑小鸡的运作，只需要配合就好，Docker也一样，我们只需要创建容器，管理容器就够了，剩下的交给Docker来处理，且Docker可以做负载均衡，后续做架构的时候可以开多个Docker做集群，按需来做 安装删除旧版本，更新apt-get，安装docker123sudo apt-get remove docker docker-engine docker-ce docker.iosudo apt-get updatesudo apt install docker.io 启动Docker并查看版本启动docker123systemctl start dockersystemctl enable dockerdocker --version 我这里安装的是 18.09版本 Docker1.png 安装Jenkins安装安装Jenkins可以选择多种方式安装，我这里采用的是Docker的方式安装的，由于我们上面已经安装过Docker，按照Jenkins官方给的安装方案就可以了，首先pull一个稳定版本的 Jenkins 镜像镜像地址 : jenkinsci/blueocean12docker pull jenkinsci/blueoceandocker images Docker2.png 查看当前Jenkins版本1docker inspect [IMAGE ID] 这里的 IMAGE ID 则是上面 查看镜像的 IMAGE ID Jenkins1.png 红框内则是 对应版本号 123456# 创建一个存放Jenkins Docker的目录mkdir /home/root/Jenkins# 启动一个Dockerdocker run -d --name jenkins -p 8081:8080 -v /home/jenkins:/home/jenkins jenkins/jenkins:lts# 查看jenkins服务docker ps | grep jenkins Jenkins2.png 打开 http://IP:8081 Jenkins3.png 输入命令进入 Docker内部123docker exec -it jenkins bash# 获取密码cat /var/jenkins_home/secrets/initialAdminPassword 重启Docker1docker restart [CONTAINER ID] [CONTAINER ID] 为当前Jenkins的版本号 例如 2.164.3 则输入 docker restart 2.164.3 Nginx反代Jenkins，绑定域名由于众所周知的水牛城服务器卡，国内环境必须搭配CloudFlare才可以使用，否则太卡了，因此安装LNMP环境，后续自动构建时也可以构建到这里 安装方法一： LNMP环境安装教程 : LNMP一键安装包 - 安装教程 懒得打开的话，可以直接输入1wget http://soft.vpser.net/lnmp/lnmp1.6.tar.gz -cO lnmp1.6.tar.gz &amp;&amp; tar zxf lnmp1.6.tar.gz &amp;&amp; cd lnmp1.6 &amp;&amp; ./install.sh lnmp 我这里安装的是 1.6稳定版，需要其他版本的可以自行修改版本号安装 安装方法二： apt-get安装，建议先更新apt-get1apt-get install nginx 打开NGINX配置文件目录，创建一个新的配置文件(这里是lnmp环境的配置文件地址，apt-get安装的nginx配置文件存放于 /etc/nginx/conf.d 中) 1vi /usr/local/nginx/conf/vhost/jenkins.conf 输入以下内容，请注意替换掉下面的 jenkins.0161.org1234567891011121314server &#123; listen 80; server_name jenkins.0161.org; client_max_body_size 60M; client_body_buffer_size 512k; location / &#123; proxy_pass http://localhost:8081; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;&#125; 重启lnmp使配置生效1lnmp reload 打开CloudFlare绑定域名，增加CDN支持，此处比较简单，不多赘述 结语一个完整的架构，需要很多的付出，并非一朝一夕，本文所属架构并不适用于所有公司或者个人，大型公司还需要K8s集群，承受多少并发取决于很多因素，任何架构都不能通杀所有类型的公司","categories":[{"name":"架构","slug":"架构","permalink":"https://sbcoder.cn/categories/架构/"}],"tags":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/tags/优化/"},{"name":"架构","slug":"架构","permalink":"https://sbcoder.cn/tags/架构/"},{"name":"版本控制","slug":"版本控制","permalink":"https://sbcoder.cn/tags/版本控制/"}]},{"title":"开发中常见的MySQL数据库优化细节","slug":"开发中常见的MySQL数据库优化细节","date":"2019-06-20T10:17:03.000Z","updated":"2019-12-09T11:51:26.000Z","comments":true,"path":"2019/06/20/mysql_optimize.html","link":"","permalink":"https://sbcoder.cn/2019/06/20/mysql_optimize.html","excerpt":"","text":"前言以我的习惯来讲，每开始一个新的项目都需要先把思路完善，紧接着就需要建立数据库，在码代码的时候，就一般不会在修改数据库的构造了，因此，数据库的结构通常关乎着查询的速度以及程序的完善程度，一个好的结构可以让你少写很多代码，也能让程序的运行速度更加快，通常在大公司都是由DBA来做这件事，但是事无绝对，作为一名合格的后端，掌握一些少量的数据库优化也是很需要的。 MySQL优化 - 数据类型及CURDPROCEDURE ANALYSE()PROCEDURE ANALYSE() [prəˈsējər ˈænəlaɪz]是一个MySQL自带的给我们提供数据库优化建议的函数，他可以直接运行在MySQL中，直接在执行语句中加上这个函数即可1SELECT * FROM `list` WHERE 1 PROCEDURE ANALYSE ( ) 这段SQL执行过后，将会把list表中的数据分析一遍，并把他的分析结果展示出来 Field_nameMin_valueMax_valueMin_lengthMax_lengthEmpties_or_zerosNullsAvg_value_oravg_lengthstdOptimal_fieldtype 他将会把分析出来的 字段名 最短值 最大值 以及最后一列就是MySQL给出的分析结果，我们可以在有一定数据的时候使用这个函数来分析，这样给出的结果会更精确一些，只需要查看最后一列Optimal_fieldtype的值即可，这个函数并不适用于数据库设计阶段，它适用于后期使用 EXPLAINEXPLAIN是一个非常好用的MySQL语法，在我们功能测试阶段，如果发现某页面非常慢，排除静态资源问题后就可以试试使用EXPLAIN，我们可以在执行语句前面加上 EXPLAIN 来获得执行过程，通过该结果我们可以看到SQL如何改变会减少查询时间和次数。1EXPLAIN SELECT * FROM `list` WHERE 1 这段SQL执行后，将会返回如下格式的分析结果 idselect_typetabletypepossible_keyskeykey_lenrefrowsExtra 我们主要看rows就行，为了得到想要的结果，rows的值越小越好，使用EXPLAIN来调试简直是再好不过了！ ENUM(枚举)类型很多程序员往往喜欢统一一个数据类型，比如说 ‘varchar’ ，这可能是我见过最多的数据类型了，早些时期，的确是有很多的公司或者程序都是大面积使用，随着MySQL的革新换代，很多的类型都可以避免使用它。我在很多得程序上测试过（有数据）PROCEDURE ANALYSE()方法，他给出了很多 ‘varchar’ 替换为 ‘enum’ 的建议，这说明，enum类型的确是一个应该被重视的数据类型，但由于他是一个枚举类型，我们在定义数据类型的时候并不适合直接上手定义，所以很多时候都是在有一定的数据量的时候才想要换数据类型的。可以理解为枚举即时索引，枚举就相当于给这个字段的可能值都加上了一个索引，与我们为了优化查询加索引是一样的概念。enum更适用于选项卡类字段，例如性别，订单状态等，如果您字段中只有几个重复的值也是非常推荐使用的。 JOIN链接查询，这是我们在开发中非常常用的查询方式，首先要知道，我们在学校里学习的大多数是 AND 链接多表查询，虽然能够将结果无误的查询出来，但是速度就影响的非常多了，这里还是推荐大家使用JOIN来连接查询有些同学可能不太理解JOIN，简单说一下JOIN的内连接和外链接，左外链接和右外链接吧 内连接即是A B两表链接，只取两表共有的数据，假设 B 中 有的数据 A 表内没有对应的数据则无法查询到 1SELECT * FROM list1 INNER JOIN list2 on list1.id = list2.id 外连接（FULL JOIN 也称作全连接）即是A B两表链接，取两表所有的数据，即使 B 表中的某些数据无法匹配链接条件时，也正常链接 1SELECT * FROM list1 FULL JOIN list2 on list1.id = list2.id 左外连接，即是 A B两表链接，取两表所有数据，若A表中有B表不匹配的数据，同样展示出来，B表如果有A不匹配的数据，则不展示 1SELECT * FROM list1 LEFT OUTER JOIN list2 on list1.id = list2.id 右外连接，即是 A B两表链接，取两表所有数据，若B表中有A表不匹配的数据，同样展示出来，A表如果有B不匹配的数据，则不展示，与左外连接相反 VvmQFU.png MySQL优化 - 结构FULLTEXT INDEXFULLTEXT INDEX(全文索引)，更适用于文章内容搜索的索引，我们在作搜索功能的时候，很多人喜欢将文章内容(content)建立普通索引，但是实际上，这种做法并不会增加查询速度，通常我们做搜索的时候，执行下列语句。 1SELECT content FROM `list` WHERE content LIKE '%风向标%' 如果搜索功能权重比较高的网站，就需要将content这个字段建立索引。 1ALTER TABLE `list` ADD FULLTEXT (`content`) 如果是phpmyadmin用户，在phpmyadmin中直接点击’全文搜索’即可。 MyISAM OR InnoDB？就我现阶段写出来的东西来看（数据量小，查询次数少，用户量较少），MyISAM肯定是最适合我的，它更适用于小型网站，以及事务处理较少的网站InnoDB则与之相反，如果你的业务比较复杂，针对数据库的操作较多的时候，InnoDB就会更适合一些。使用INSERT插入数据时 MyISAM 就比 InnoDB 更快一些，而 UPDATE 时 InnoDB 就会比 MyISAM 快一些 如果您是轻度SQL用户，重功能不重视业务的项目，那么我个人以为 MyISAM 更适合一些如果您感觉业务逻辑复杂，经常使用SQL，那么可以尝试使用 InnoDB 最后也是见仁见智，没有好坏，如果您希望测试，也是可以通过直接修改数据库引擎来测试速度的 MySQL优化 - 小知识点 不要使用 SELECT * 查询 不要使用 NULL 频繁查询的字段建立索引 索引过多时会影响 UPDATE 和 INSERT 的执行速度 避免在 WHERE 时使用 != &lt;&gt; 等操作符，MySQL会自动放弃索引，直接全表扫描 避免使用 IN 和 NOT IN，尽量使用BETWEEN，MySQL会自动放弃索引，直接全表扫描 可以使用 EXISTS 来代替 IN 使用 某些情况下可以使用强制使用索引查询 SELECT * FROM list with(index(索引名)) WHERE …. 避免使用 OR 作为调件，可以使用 UNION 并集查询将两次查询结果合并 尽可能将表内容长度固定 查询时如果只查询一条信息，就使用 LIMIT 1 避免使用比较表达式 如 10000+1 = id 可以使用 id = 10000+1 记得将查询链接即时关闭掉 使用变量来给MySQL开启查询缓存，避免使用MySQL内置变量函数 设置的主键尽量使用长度短且最好是int类型 垂直分割，将大量的字段的表优化成多个少字段的表 INSERT 和 DELETE 是一个可以锁定数据表的SQL语句，必须等待执行完毕后才会解除锁定，如果这条语句执行起来过于缓慢，请谨慎使用 Object Relational Mapper Prepared Statements 参考: Top 20+ MySQL Best Practices参考: 廖雪峰的个人网站 - 链接查询","categories":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/categories/优化/"}],"tags":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/tags/优化/"},{"name":"MySQL","slug":"MySQL","permalink":"https://sbcoder.cn/tags/MySQL/"}]},{"title":"mm131全栈多线程爬虫","slug":"mm131全栈多线程爬虫","date":"2019-06-19T14:34:31.000Z","updated":"2019-06-19T14:56:33.000Z","comments":true,"path":"2019/06/19/mm131_spider.html","link":"","permalink":"https://sbcoder.cn/2019/06/19/mm131_spider.html","excerpt":"","text":"起因LOC的大佬们最近开始疯狂的爬取mm131，作为一个Python初心者，作为技术上的学习，也要与时俱进，简单写了一个图片下载爬虫，看到大佬们似乎是做了一个typechoo的对接接口，我这边回头有空也搞一个wordpress的接口（只在博客内发布），之前写过一个新浪远程上传的接口，由于种种原因，新浪已经不支持外链了，因此这个wordpress接口可能就有时间再做了，不然做出来也是个摆设，没地方放。 代码解析网址不发了，直接讲，或者大家直接百度谷歌都可以搜得到。打开网站,总共有如下六个分类 mm131.jpg 每个分类下面都有一堆的图集，有N个分页的图集，但是第一页跟第二页的地址还不太一样，这点跟192tt做的很相似，感觉这几个站长是不是都是用的同一套程序，如果是的话可以通杀了。。。首先遍历图集的地址，到目前更新文章截止，一共大概5000多套按分类给他搞一个分类循环 1234list = &#123;'xinggan':6,'qingchun':1,'xiaohua':2,'chemo':3,'qipao':4,'mingxing':5&#125; # list = &#123;'mingxing':5&#125; for key in list: getPageUrl(key,list[key]) 解析图片url，用正则获取就行，用bs4取到末页的地址，然后遍历循环取图集地址 1234567try: i.find('img').get('src')except Exception as e: for s in i.find_all('a'): endPage = s.get('href') endPage = rex('list_%s_(\\d+).html'%num,endPage) continue 获取图集地址12345678910nextUrl = \"%s/list_%s_%s.html\"%(url,num,i+2)response = requests.get(nextUrl, headers=headers)response.encoding = 'gb2312'soup = BeautifulSoup(response.text, 'html.parser')for i in soup.find('dl', &#123;'class': 'public-box'&#125;).find_all('dd'): try: i.find('img').get('src') except Exception as e: continue print(i.find('a').get('href')) 需要注意的是，mm131的图片是有防盗链的，根据referer判断，随便找一个图集的地址设置上即可1234headers = &#123; \"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36\", 'referer': \"http://www.mm131.com/xinggan/4995.html\",&#125; 线程池应用之前的爬虫除了Scrapy搞出来的之外都是单线程的爬虫，优点是比较稳定，但是缺点也很明显，太慢了，mm131这个站的图大都比较小，如果是一张一张下载确实是不太划算，于是搞了个线程池。Python的线程池很简单，只需要引入 threadpool 即可，如果报错，请 pip install threadpool,12345678910# 引入threadpoolimport threadpool# 创建线程池，设置为12线程，可以根据自身情况修改pool = threadpool.ThreadPool(12)# 创建callback函数，参数1 getSingleData 是需要调用的函数名，list是函数getSingleData的参数，该方法适用于单个参数的函数，list是一个一维数组或对象pageTask = threadpool.makeRequests(getSingleData, list)# 执行线程池[pool.putRequest(req) for req in pageTask]# 等待完成后退出pool.wait() 演示和下载演示图 多线程演示.jpg 下载结果.jpg 下载演示代码不全，直接上地址https://github.com/ai0by/ai0by-spider/tree/master/mm131","categories":[{"name":"Python","slug":"Python","permalink":"https://sbcoder.cn/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://sbcoder.cn/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://sbcoder.cn/tags/爬虫/"},{"name":"福利","slug":"福利","permalink":"https://sbcoder.cn/tags/福利/"}]},{"title":"Redis/Redis集群以及在Laravel中的使用方法","slug":"Redis-Redis集群以及在Laravel中的使用方法","date":"2019-06-17T13:19:37.000Z","updated":"2019-06-17T13:21:08.000Z","comments":true,"path":"2019/06/17/Redis_laravel_PHP.html","link":"","permalink":"https://sbcoder.cn/2019/06/17/Redis_laravel_PHP.html","excerpt":"","text":"Redis的数据类型Redis也算是一种数据的容器，承载在内存上，因此它的各方面性能都比较快，且作为非关系型数据库，面对各种索引也比普通的数据库查询快，不同的场景下使用不同的数据类型，适用于很多地方 字符串类型 String一一对应，使用场景比较多 key:value 形式 命令 描述 set key value 设置指定key值 get key 获取指定key的value值 mget key1 key2 获取多个key 的 value，按顺序返回value值 mset key1 ‘value1’ key2 ‘value2’ 批量设置多个key的value strlen key 返回对应value长度 getrange key start end 截取字符串 append key value 追加key关联的value值，返回长度 getset key value 设置key的value并返回原value值 setex key time value 设置value值，并加上一个过期时间，使用ttl key查看过期时间，秒为单位 setnx key value 当key不存在时，设置value msetnx key1 ‘value1’ key2 ‘value2’ 当所有的key都不存在时，批量设置多个key的value incr key 将key关联value的值加一，仅对数字有效 incrby key num 将key关联value的值加num，例如 10，仅对数字有效 incrbyflout key num 将key关联value的值加num，浮点类型 decr key 将key关联value的值减一，仅对数字有效 decrby key num 将key关联value的值减num，例如 10，仅对数字有效 哈希类型 Hash一对一对多，类似字符串，但又区别于字符串，它比字符串复杂一些，同样是key:value，但是他的value可以是一个map，同时，它也无法给单个属性赋予过期时间，但可以给单个属性设置值，某些情况下比String占用资源少，当需要缓存整张表时推荐使用 命令 描述 hset key field value 设置key关联的value hkeys key 获取所有的key hgetall key 获取key的所有对应field hvals key 获取hash表中所有的value hlen key 获取keyd的长度 hmget key field1 field2 获取多个field的值 hmset key field1 value1 field2 value2 设置多个field的值 hdel key field 删除单个field的单个属性 hsetnx key field value 当field不存在时存储数值 hincrby key field num 给指定字段增加数值，整数 hincrbyfloat key field num 给指定字段增加浮点数 列表类型 List类似栈，拥有栈的特性，也有链表的特性，亦可用作消息队列等场景，使用场景很广 命令 描述 lpush key value1 value2 将多个value插入到关联的key里面 头部 lpushx key value 将value插入到key中，需要key已经存在 头部 lpop key 删除并获取当前key里面的第一个元素 llen key 获取当前key关联的list长度 rpush key value1 value2 将多个value插入到关联的key里面 尾部 rpop key 删除并获取列表内的最后一个元素 rpushx key value 将value插入到key中，需要key已经存在 尾部 blpop key1 key2 timeout 删除并获取列表的第一个元素，key1存在时不执行key2，如果没有会一直阻塞到弹出为止，建议添加延时 brpop key1 key2 timeout 删除并获取列表的最后一个元素，key1存在时不执行key2，如果没有会一直阻塞到弹出为止，建议添加延时 lindex key 通过索引来获取list中的元素 lset key index value 通过索引来设置相应元素的值 lrange key start end 截取指定列表内元素 ltrim key start end 只保留开始和结束内的元素 集合 set数据池，无序，可计算差集交集等，之前写爬虫时用集合做过去重，Python使用redis也是非常方便的 命令 描述 sadd key member1 member2 向集合内添加元素 scard key 获取集合内元素数量 smembers key 获取集合内所有的元素 sismember key member 判断member是否是key集合的子元素 sdiff key1 key2 获取给定集合的差集 sinter key1 key2 获取给定集合的交集 sunion key1 key2 获取给定集合的并集 spop key 随机删除一个集合内元素并返回 srandmember key num 返回集合内的一个或者多个随机元素 srem key member1 member2 删除集合中一个或者多个指定元素 其他剩下的数据类型确实是没用过，这里不便多说 Laravel使用redis流程简单来说如下图所示 Laravel使用redis 程序将数据存储请求发送给Laravel内置的redis模块（PHPRedis，Predis等），并在config/database.php中配置好redis的端口密码等信息，通过内置模块调用已经安装好的redis即可使用redis存储使用数据了，然后redis内部处理数据我们如果不做底层的话，正常存储使用，只需要处理好程序与Laravel之间的过程就可以了，也就是说，了解PHPRedis和Predis就可以了，目前似乎大多数人使用的都是这两种，也不仅限于Laravel，原生PHP以及像Swoole这种的也是可以使用的。 关于Laravel中的Redis配置使用 可以参考 Laravel中文文档5.8 - redis 1234567// laravel 简单调用示例use Illuminate\\Support\\Facades\\Redis;class testRedis()&#123; Redis::set('username','风向标'); $username = Redis::get('username'); return $username;&#125; Laravel使用Redis集群仍然是在 config/database 中配置 clusters123456789101112131415161718192021222324252627282930313233'redis' =&gt; [ 'client' =&gt; env('REDIS_CLIENT', 'predis'), 'options' =&gt; [ 'cluster' =&gt; env('REDIS_CLUSTER', 'predis'), // 'cluster' =&gt; env('redis'), ], 'clusters' =&gt; [ 'vaneCache' =&gt; [ [ 'host' =&gt; env('REDIS_HOST', '127.0.0.1'), 'password' =&gt; env('REDIS_PASSWORD', null), 'port' =&gt; env('REDIS_PORT', 6379), 'database' =&gt; 1, ], [ 'host' =&gt; env('REDIS_HOST', '127.0.0.1'), 'password' =&gt; env('REDIS_PASSWORD', null), 'port' =&gt; env('REDIS_PORT', 6379), 'database' =&gt; 2, ], [ 'host' =&gt; env('REDIS_HOST', '127.0.0.1'), 'password' =&gt; env('REDIS_PASSWORD', null), 'port' =&gt; env('REDIS_PORT', 6379), 'database' =&gt; 3, ], ], ], ], 在使用时仅需要 使用 connection 即可 1234$redis1 = Redis::connection('vaneCache');$redis1-&gt;set('username','风向标');$username = $redis1-&gt;get('username');echo $username;","categories":[{"name":"PHP","slug":"PHP","permalink":"https://sbcoder.cn/categories/PHP/"}],"tags":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/tags/优化/"},{"name":"PHP","slug":"PHP","permalink":"https://sbcoder.cn/tags/PHP/"},{"name":"Laravel","slug":"Laravel","permalink":"https://sbcoder.cn/tags/Laravel/"},{"name":"Redis","slug":"Redis","permalink":"https://sbcoder.cn/tags/Redis/"}]},{"title":"tuwan（兔玩）全站妹子图爬虫可多窗口","slug":"tuwan全站妹子图爬虫可多窗口","date":"2019-05-13T15:01:00.000Z","updated":"2019-05-13T15:29:23.000Z","comments":true,"path":"2019/05/13/tuwan_spider.html","link":"","permalink":"https://sbcoder.cn/2019/05/13/tuwan_spider.html","excerpt":"","text":"前言兔玩是一个非常不错的妹子图网站，跟曾经的PR社有异曲同工之处，花少量的钱可以看Coser的图片，但是tuwan的妹子还是很正经的哟~兔玩官网 tuwanjun.com以下是网站截图 tuwan 兔玩的更新速度还是不错的呢~ 破解看到官网的套图打开后，一般是有几张可以看得图，也有一堆尺寸小的预览图，地址很相似，例如这张1http://img4.tuwandata.com/v3/thumb/jpg/YjAzYiwxNTgsMTU4LDksMywxLC0xLE5PTkUsLCw5MA==/u/GLDM9lMIBglnFv7YKftLBuvzpwYbEIoBh8ap84BsgXdniTdx80UqsXLdP5yaJZklUj09PvGO8IYpAC3nOanE0EHpB9bCnRKUnvdbAJH6CcXC.jpg YjAzYiwxNTgsMTU4LDksMywxLC0xLE5PTkUsLCw5MA==这一串很容易看的出是base64加密过的串，经过解密获得12base64.b64decode(imgurl)# b03b,158,158,9,3,1,-1,NONE,,,90 这里的158,158就是缩略图的尺寸了，我们尝试修改缩略图尺寸然后在base64加密后就可以取得地址，经过尝试，修改为 0，0即可还原原图尺寸~12base64.b64encode(base64.b64decode(imgurl.encode('utf-8')).replace('158','0'))# YjAzYiwwLDAsOSwzLDEsLTEsTk9ORSwsLDkw 组合成原图地址：1http://img4.tuwandata.com/v3/thumb/jpg/YjAzYiwwLDAsOSwzLDEsLTEsTk9ORSwsLDkw/u/GLDM9lMIBglnFv7YKftLBuvzpwYbEIoBh8ap84BsgXdniTdx80UqsXLdP5yaJZklUj09PvGO8IYpAC3nOanE0EHpB9bCnRKUnvdbAJH6CcXC.jpg 下载源代码已经开源到Github上了上一张测试图 测试图 下载地址：tuwan_spider","categories":[{"name":"Python","slug":"Python","permalink":"https://sbcoder.cn/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://sbcoder.cn/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://sbcoder.cn/tags/爬虫/"},{"name":"福利","slug":"福利","permalink":"https://sbcoder.cn/tags/福利/"}]},{"title":"Discuz会员数据与Wordpress互通","slug":"Discuz会员数据与Wordpress互通","date":"2019-04-11T12:06:06.000Z","updated":"2019-05-13T14:57:58.000Z","comments":true,"path":"2019/04/11/Discuz-Userinfo-To-Wordpress.html","link":"","permalink":"https://sbcoder.cn/2019/04/11/Discuz-Userinfo-To-Wordpress.html","excerpt":"","text":"情景这个情景可能遇到的也不在少数，不想舍弃用户数据，还想让用户无需注册在新站保留账号。实际当我们在迁移的时候，稍微了解数据库的同学应该明白想要迁移用户数据只需要迁移用户数据表即可。实际上我也是这么做的，但是中途遇到了几个小问题，这里我总结一下！ Discuz用户密码加密算法Discuz的用户信息都存放在 ‘pre_common_member‘ 表里，包含了我们需要转移的 邮箱,用户名,密码,积分,ip 等各类信息那么很简单了，便利这个表再插入到Wordpress表内即可但在导入表之前需要先测试一下用户数据是否匹配以示严谨~当我测试密码匹配的时候发现，这里的密码似乎并不匹配，首先我想到的就是应该是加盐了，但是纵观整个 ‘pre_common_member‘ 表，似乎并没有该有的字段网上找了一圈发现Discuz的用户真实密码是存在 ‘pre_ucenter_members‘ 表内的，’pre_common_member‘ 表内的密码我现在还不知道有什么用处，但至少跟我们需要迁移的数据没什么关联。从 ‘pre_ucenter_members‘ 表中找到了我们需要的 ‘salt‘ 字段，经过测试得出Discuz的密码加密算法为1md5(md5('password').'salt'); tips: Discuz里面的salt是一个6位的 数字+字母 随机数 Wordpress用户密码加密算法搞定了DZ的加密算法后，那么如何将DZ的用户信息插入到WP里面就很重要了，打开 Wordpress 的数据库找到 ‘wp-user‘表，找到 ‘user_pass‘ 字段，发现里面加密的内容似乎无迹可寻。实际上，Wordpress的加密是使用了 phpass 类来加密的，由 phpass 加密的密码具有不可逆性，所以想要破解是不可能了，这里简单说一下 phpass 的加密算法目前我们的PHP版本应该都在5以上，所以前缀是一样的 $P$B 大致写出来如下：12345$count = rand(1,8);$hash = md5($salt . $password, TRUE);while($count--)&#123; $hash = md5($hash . $password, TRUE);&#125; 看起来是不是很强，我们无法破解这样的密码，实际使用中，我们也可以使用 phpass 来做密码加密，让我们的数据库更加的安全~然而我们数据迁移时其实完全可以避免这种问题，Wordpress是保留了md5加密的形式的，如果 ‘user_pass‘ 字段里面存储的是md5加密的32值，wordpress也可以登录成功，并且再登陆后会将 ‘user_pass‘ 字段修改为 phpass 加密的格式，是不是很人性化呢。综上所述，我们无需解出来wordpress的加密算法，我们也解不出来~ 开始迁移用户数据关于迁移有很多细节，本来是打算写出来的，后来发现没什么技术含量，都是流水账，直接开源到github好了需要的朋友请直接点击 D2W - Github","categories":[{"name":"PHP","slug":"PHP","permalink":"https://sbcoder.cn/categories/PHP/"}],"tags":[{"name":"Discuz","slug":"Discuz","permalink":"https://sbcoder.cn/tags/Discuz/"},{"name":"Wordpress","slug":"Wordpress","permalink":"https://sbcoder.cn/tags/Wordpress/"}]},{"title":"192TT(192tb)套图吧整站爬虫","slug":"192TT-192tb-套图吧整站爬虫","date":"2019-03-28T08:15:16.000Z","updated":"2020-05-17T05:22:15.811Z","comments":true,"path":"2019/03/28/192tt_Spider.html","link":"","permalink":"https://sbcoder.cn/2019/03/28/192tt_Spider.html","excerpt":"","text":"观察目录结构目标网站：192tb.com网站结构复杂，但也不是太复杂，总体来说都写在导航栏上面了，本以为是new分类下就是所有的文章了，后来发现不是，需要遍历整个导航分类，由于每个分类都有很庞大的资源，因此我决定写成配置文件的形式，建立config.py 1234567891011121314# -*- coding: utf-8 -*-mt = 'https://www.192tb.com/listinfo-1-1.html' # 美图mt1 = 'https://www.192tb.com/meitu/xingganmeinv/' # 性感美女mt2 = 'https://www.192tb.com/meitu/siwameitui/' # 丝袜美腿mt3 = 'https://www.192tb.com/meitu/weimeixiezhen/' # 唯美写真mt4 = 'https://www.192tb.com/meitu/wangluomeinv/' # 网络美女mt5 = 'https://www.192tb.com/meitu/gaoqingmeinv/' # 高清美女mt6 = 'https://www.192tb.com/meitu/motemeinv/' # 模特美女mt7 = 'https://www.192tb.com/meitu/tiyumeinv/' # 体育美女mt8 = 'https://www.192tb.com/meitu/dongmanmeinv/' # 动漫美女mt9 = 'https://www.192tb.com/new/ugirlapp/' # 爱尤物APP/尤果网gc = 'https://www.192tb.com/gc/' # 国产gc1 = 'https://www.192tb.com/gc/bl/' # beautyleg1 顶级分类和二级分类不便多说，这里只是测试并没有收录所有的分类，有兴趣可以自己添加 进入分类页后既是套图封面，从这里可以爬取套图的链接，分类页的底部也是有下一页的选项，可以根据下一页来获取下一个分类页的链接，以此递归，并获取链接 获取到套图链接后发现每个单页面都是需要点击下一张图片来做的，单页面中的图片，使用BeautifulSoup即可轻松获取，由于不知道一套图里面有多少张，我这边使用递归的方式，走到最后一张，即退出递归。 核心代码获取单个套图并下载1234567891011121314151617def getSingleData(url,singleTitle,i = 1): response = requests.get(url) soup = BeautifulSoup(response.text,\"html.parser\") imgUrl = soup.find(id = 'p').find('center').find('img').get('lazysrc') print imgUrl try: j = i + 1 result = '_%s.html'%i in url if result: nextImg = response.url.replace('_%s.html'%i, '_%s.html'%j) else: nextImg = response.url.replace('.html', '_%s.html'%j) # print nextImg downImg(imgUrl,singleTitle,i) getSingleData(nextImg,j) except Exception,e: return 0 获取下一页页面信息123456789101112131415161718192021222324def getPage(url,new = 1,i = 1): print '开始采集第%s页'%i print url response = requests.get(url) soup = BeautifulSoup(response.text,\"html.parser\") for dataUrl in soup.find('div',&#123;'class':'piclist'&#125;).find('ul').find_all('li'): singleDataUrl = 'https://www.192tb.com/'+dataUrl.find('a').get('href') print singleDataUrl try: singleTitle = dataUrl.find('a').find('img').get('alt') except Exception,e: continue print singleTitle getSingleData(singleDataUrl,singleTitle) result = '_%s.html' % i in url j = i + 1 if new != 1: nextPageUrl = url.replace('listinfo-1-%s.html' % i, 'listinfo-1-%s.html' % j) else: if result: nextPageUrl = url.replace('index_%s.html' % i, 'index_%s.html' % j) else: nextPageUrl = url.replace(url, url+'/index_%s.html' % j) getPage(nextPageUrl,new,j) 演示及下载下载地址：Github 192tt演示图","categories":[{"name":"Python","slug":"Python","permalink":"https://sbcoder.cn/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://sbcoder.cn/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://sbcoder.cn/tags/爬虫/"},{"name":"福利","slug":"福利","permalink":"https://sbcoder.cn/tags/福利/"}]},{"title":"正则表达式应用，常用取值表（记录）","slug":"正则表达式应用，常用取值表（记录）","date":"2019-03-26T08:11:06.000Z","updated":"2019-03-27T03:50:12.000Z","comments":true,"path":"2019/03/26/Regex_match_note.html","link":"","permalink":"https://sbcoder.cn/2019/03/26/Regex_match_note.html","excerpt":"","text":"正则表达式 查询表 字符 描述 场景 \\ 转义 转义场景 \\ ^ 匹配输入字符串的开始位置。如果设置了 RegExp 对象的 Multiline 属性，^ 也匹配 ‘\\n’ 或 ‘\\r’ 之后的位置。 取a开头的字符串 ^a.* $ 匹配输入字符串的结束位置。如果设置了RegExp 对象的 Multiline 属性，$ 也匹配 ‘\\n’ 或 ‘\\r’ 之前的位置。 取a开头b结尾 ^a.*b$ * 匹配前面的子表达式零次或多次。 zo 能匹配 “z” 以及 “zoo”。 等价于{0,} + 匹配前面的子表达式一次或多次。 ‘zo+’ 能匹配 “zo” 以及 “zoo”，但不能匹配 “z”。+ 等价于 {1,} ? 匹配前面的子表达式零次或一次. “do(es)?” 可以匹配 “do” 或 “does” 中的”do” 。? 等价于 {0,1}。 {n} n 是一个非负整数。匹配确定的 n 次。 ‘o{2}’ 不能匹配 “Bob” 中的 ‘o’，但是能匹配 “food” 中的两个 o。 {n,} n 是一个非负整数。至少匹配n 次。 ‘o{2,}’ 不能匹配 “Bob” 中的 ‘o’，但能匹配 “foooood” 中的所有 o。’o{1,}’ 等价于 ‘o+’。’o{0,}’ 则等价于 ‘o*’ {n,m} m 和 n 均为非负整数，其中n &lt;= m。最少匹配 n 次且最多匹配 m 次。 “o{1,3}” 将匹配 “fooooood” 中的前三个 o。’o{0,1}’ 等价于 ‘o?’。请注意在逗号和两个数之间不能有空格。 ? 当 该字符紧跟在任何一个其他限制符 (*, +, ?, {n}, {n,}, {n,m}) 后面时，匹配模式是非贪婪的。 非贪婪模式尽可能少的匹配所搜索的字符串，而默认的贪婪模式则尽可能多的匹配所搜索的字符串。对于字符串 “oooo”，’o+?’ 将匹配单个 “o”，而 ‘o+’ 将匹配所有 ‘o’。 . 匹配除 “\\n” 之外的任何单个字符。 要匹配包括 ‘\\n’ 在内的任何字符，请使用象 ‘[.\\n]’ 的模式。 x&#124;y 匹配 x 或 y。 ‘z&#124;food’ 能匹配 “z” 或 “food”。’(z&#124;f)ood’ 则匹配 “zood” 或 “food”。 [xyz] 字符集合。匹配所包含的任意一个字符。 ‘[abc]’可以匹配 “plain” 中的 ‘a’。 [^xyz] 取反，匹配未包含的任意字符。 ‘?[^abc]’ 可以匹配 “plain” 中的’p’。 [a-z] 字符范围。匹配指定范围内的任意字符。 ‘[a-z]’ 可以匹配 ‘a’ 到 ‘z’ 范围内的任意小写字母字符。 \\b 匹配一个单词边界，也就是指单词和空格间的位置。 ‘er\\b’ 可以匹配”never” 中的 ‘er’，但不能匹配 “verb” 中的 ‘er’。 \\B 匹配非单词边界 ‘er\\B’ 能匹配 “verb” 中的 ‘er’，但不能匹配 “never” 中的 ‘er’。 \\cx 匹配由 x 指明的控制字符。 \\cM 匹配一个 Control-M 或回车符。x 的值必须为 A-Z 或 a-z 之一。否则，将 c 视为一个原义的 ‘c’ 字符。 \\d 匹配一个数字字符 等价于 [0-9]。 \\D 匹配一个非数字字符。 等价于 [^0-9]。 \\f 匹配一个换页符。 等价于 \\x0c 和 \\cL。 \\n 匹配一个换行符。 等价于 \\x0a 和 \\cJ。 \\r 匹配一个回车符。 等价于 \\x0d 和 \\cM。 \\s 匹配任何空白字符，包括空格、制表符、换页符等等。 等价于 [ \\f\\n\\r\\t\\v]。 \\S 匹配任何非空白字符。 等价于 [^ \\f\\n\\r\\t\\v]。 \\t 匹配一个制表符。 等价于 \\x09 和 \\cI。 \\v 匹配一个垂直制表符。 等价于 \\x0b 和 \\cK。 \\w 匹配包括下划线的任何单词字符。 等价于’[A-Za-z0-9_]’。 \\W 匹配任何非单词字符。 等价于 ‘[^A-Za-z0-9_]’。 \\xn 匹配十六进制数 ‘\\x41’ 匹配 “A”。’\\x041’ 则等价于 ‘\\x04’ &amp; “1”。正则表达式中可以使用 ASCII 编码。. \\num 匹配 一个正整数。对所获取的匹配的引用。 ‘(.)\\1’ 匹配两个连续的相同字符。 \\n 标识一个八进制转义值或一个向后引用。 如果 \\n 之前至少 n 个获取的子表达式，则 n 为向后引用。否则，如果 n 为八进制数字 (0-7)，则 n 为一个八进制转义值。 \\nm 标 识一个八进制转义值或一个向后引用。 如果 \\nm 之前至少有 nm 个获得子表达式，则 nm 为向后引用。如果 \\nm 之前至少有 n 个获取，则 n 为一个后跟文字 m 的向后引用。如果前面的条件都不满足，若 n 和 m 均为八进制数字 (0-7)，则 \\nm 将匹配八进制转义值 nm。 \\nml 匹配八进制数 如果 n 为八进制数字 (0-3)，且 m 和 l 均为八进制数字 (0-7)，则匹配八进制转义值 nml。 \\un 匹配 n，其中 n 是一个用四个十六进制数字表示的 Unicode 字符。 \\u00A9 匹配版权符号 。 常用案例演示123# -*- coding:utf-8 -*-import restr1 = 'ai0by123' 提取a开头的字符串1regexStr = \"^a.*\" 提取a开头b结尾字符串1regexStr = \"^a.*3$\" 提取最右边符合条件的值,贪婪1regexStr = \".*(a.*b).*\" # 贪婪，取a到b之间，右边开始取，取最右边符合条件的 提取最左边符合条件的值，非贪婪1regexStr = \".*?(a.*?b).*\" # 非贪婪，取a到b之间的值含a和b，从左往右只取一次 提取符合集合内的值，或运算1regexStr = \"((ai00000by|ai0by)123)\" # 或运算，符合其中一种即可 提取出生日期123456str1 = 'XXX 出生于2008年12月6日'str1 = 'XXX 出生于2008/12/6'str1 = 'XXX 出生于2008-12-6'str1 = 'XXX 出生于2008-12-06'str1 = 'XXX 出生于2008-12'regexStr = \".*出生于(\\d&#123;4&#125;[年/-]\\d&#123;1,2&#125;([月/-]\\d&#123;1,2&#125;|[月/-]$|$))\" 提取图片url,其他网站同理1234567str1 = '地址：https://www.ttbcdn.com/d/file/p/2018-02-17/g4edlvxmmyi9627.jpg'# 取整串地址regexStr = \".*https.*jpg$\"# 取XXX.jpg png gif 等regexStr = \".*/(.*.(jpg|gif|png))$\"# 取2018-02-17/g4edlvxmmyi9627.jpg png gif等regexStr = \".*/(\\d&#123;4&#125;-\\d&#123;2&#125;-\\d&#123;2&#125;/(.*.(jpg|gif|png)))$\" 收尾提取字符串12345reMatch = re.match(regexStr,str1)if reMatch: print (reMatch.group(1))else: print('No')","categories":[{"name":"note","slug":"note","permalink":"https://sbcoder.cn/categories/note/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"https://sbcoder.cn/tags/笔记/"},{"name":"正则表达式","slug":"正则表达式","permalink":"https://sbcoder.cn/tags/正则表达式/"}]},{"title":"博客迁移说明","slug":"博客迁移说明","date":"2019-03-25T05:12:58.000Z","updated":"2021-11-30T02:47:36.881Z","comments":true,"path":"2019/03/25/Hello_world.html","link":"","permalink":"https://sbcoder.cn/2019/03/25/Hello_world.html","excerpt":"","text":"关于迁移博客总是在起起伏伏，关了又开，开了又关中反复，这一次，我将风向标博客放在了Github Page上。程序采用了当下比较流行的静态博客程序 Hexo ，Hexo其实是一个非常好的程序，但由于我经常换电脑，以前用hexo搭建的博客数据丢失了很多次，后经过更换为Wordpress，Typecho之类的开源博客程序后，我又回到了 Hexo 的怀抱，可能是真的懒得折腾了，上了年纪？这次我将源代码都备份好了，应该会长期更新，有什么好的东西我应该会分享出来，主打原创~可能之前认识我的人也很少，但我这个域名还是很好记的，sb coder 也是一种自嘲吧，有想跟我交流技术或者有外包工作介绍给我的，我的微信与域名同号~多的不说了，我将尽我所能，一周至少写一篇文章，可能有时候晚上回家写一点，一天写一点，一周下来也能写不少，希望各位监督~ 关于我我是谁，职业是Go,PHP，目前全职Go开发，爱好Python，云服务器爱好者有想法的朋友可以联系我 Telegram : ai0by 承接业务运维及开发，个人有团队可承接业务","categories":[],"tags":[{"name":"ai0by","slug":"ai0by","permalink":"https://sbcoder.cn/tags/ai0by/"}]},{"title":"岛国推特妹子图爬虫","slug":"岛国推特妹子图爬虫","date":"2019-03-22T03:54:58.000Z","updated":"2020-05-17T05:22:04.930Z","comments":true,"path":"2019/03/22/Japan_Twitter_Spider.html","link":"","permalink":"https://sbcoder.cn/2019/03/22/Japan_Twitter_Spider.html","excerpt":"","text":"LOC的大佬们分享了一个网站，收集了很多岛国的妹子图和她们的推特地址：岛国妹子推特推特不是很感兴趣，就爬一下图片好了~ 爬虫介绍爬虫环境： Python2.7.9 可更替为3，自行更替 BeautifulSoup4 requests 代码：12345678910111213141516171819202122232425262728293031323334# -*- coding: utf-8 -*-from bs4 import BeautifulSoupimport requestsimport urllib2import randomdef spy(url): req = urllib2.Request(url) req = urllib2.urlopen(req) page = req.read() soup = BeautifulSoup(page, \"html.parser\") for imgSoup in soup.find_all('div', &#123;\"class\": \"row\"&#125;): for i in imgSoup.find_all('div', &#123;'class': 'photo'&#125;): for j in i.find('div', &#123;'class': 'photo-link-outer'&#125;).find('a').find_all('img'): img = j.get(\"src\") print img str = random.sample('zyxwvutsrqponmlkjihgfedcba', 6) downImg(img, str) nexturl = soup.find('p',&#123;'class':'go-to-next-page'&#125;) nexturl = nexturl.find('a').get('href') pageurl = \"http://jigadori.fkoji.com\"+nexturl spy(pageurl)def downImg(img,m): try: r = requests.get(img) except Exception , e: print \"图片获取失败\" return with open('./img/good%s.jpg' % m, 'wb') as f: f.write(r.content)if __name__ == '__main__': url = \"http://jigadori.fkoji.com\" spy(url) 整体思路看一下，网页构造，发现首页底部有下一页标签，BeautifulSoup取Class取值递归获取下一页地址图片同上整体难度不高，有兴趣的可以拿这个网站练练手~ 演示截图 演示数据1 演示数据2","categories":[{"name":"Python","slug":"Python","permalink":"https://sbcoder.cn/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://sbcoder.cn/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://sbcoder.cn/tags/爬虫/"},{"name":"福利","slug":"福利","permalink":"https://sbcoder.cn/tags/福利/"}]}]}