{"meta":{"title":"风向标 | 分享与创造","subtitle":null,"description":null,"author":"ai0by","url":"https://sbcoder.cn","root":"/"},"pages":[{"title":"api","date":"2019-04-03T02:17:31.000Z","updated":"2019-04-04T07:33:08.000Z","comments":true,"path":"api/index.html","permalink":"https://sbcoder.cn/api/index.html","excerpt":"","text":"风向标API合集 名称 作用 接口 微博图床api 远程图片上传到微博图床 https://sbcoder.cn/api/sinaImg.html 生成二维码 将地址转换为二维码图片 https://sbcoder.cn/api/qrcode.html 更多api请持续关注…"},{"title":"api","date":"2019-04-04T07:27:21.000Z","updated":"2020-05-17T05:16:44.490Z","comments":true,"path":"api/qrcode.html","permalink":"https://sbcoder.cn/api/qrcode.html","excerpt":"","text":"二维码生成（已失效）介绍使用场景很多，简单来讲，给我地址，我给你图，直接将地址放在img标签内即可~ 参数说明以GET的方式提交到：https://api.0161.org/qrcode/qrcode.php 参数 数值类型 示例 是否必传 url String https://sbcoder.cn 是 err String L (L,M,Q,H四种对应容错级别，不传默认L) 否 size String 7 (可以选择1~9999之间的值，对应不同大小，默认7) 否 logo String https://sbcoder.cn/img/avatar.jpg 否 返回值类型 : 直接返回图片 演示直接访问以下地址 12https://api.0161.org/qrcode/qrcode.php?url=https://sbcoder.cnhttps://api.0161.org/qrcode/qrcode.php?url=https://sbcoder.cn&amp;err=L&amp;size=7&amp;logo=https://sbcoder.cn/img/avatar.jpg 示例图片"},{"title":"api","date":"2019-04-04T07:27:21.000Z","updated":"2020-05-17T05:16:35.983Z","comments":true,"path":"api/sinaImg.html","permalink":"https://sbcoder.cn/api/sinaImg.html","excerpt":"","text":"微博图床-远程图片上传api（已失效）介绍我们在使用爬虫相关内容的时候，存放图片时往往会遇到图片尺寸过大，存储不方便等问题，这时候，存放在一个永久存储的云上面就很有必要，微博是一个不限流量，全球CDN的图床~微博也是有缺点的，他并不是一个易于管理的图床，仅限于存放图片但不能管理图片，如果希望使用可以管理的图床，可以参考使用自建图床，参考我的:FuliCOSIMG 参数说明以GET的方式提交到：https://api.0161.org/sinaimg/sinaImg.php 传递参数类型：GET POST 参数 数值类型 示例 是否必传 url String https://sbcoder.cn/img/avatar.jpg 是 返回参数类型 ： JSON 演示示例:1&#123;\"large\":\"http://ww2.sinaimg.cn/bmiddle/0062WdSely1g1p8mlciyrg30390120jl.gif\"&#125; PHP DEMO12345678910111213141516171819$data = array( 'url' =&gt; \"https://sbcoder.cn/img/avatar.jpg\", );echo curlPost(\"https://api.0161.org/sinaimg/sinaImg.php\",$data);function curlPost($url,$res)&#123; $curl = curl_init(); curl_setopt($curl, CURLOPT_URL, $url); curl_setopt($curl, CURLOPT_SSL_VERIFYPEER, 0); curl_setopt($curl, CURLOPT_FOLLOWLOCATION, 1); curl_setopt($curl, CURLOPT_AUTOREFERER, 1); curl_setopt($curl, CURLOPT_POST, 1); curl_setopt($curl, CURLOPT_POSTFIELDS, http_build_query($res)); curl_setopt($curl, CURLOPT_TIMEOUT, 30); curl_setopt($curl, CURLOPT_HEADER, 0); curl_setopt($curl, CURLOPT_RETURNTRANSFER, 1); $result = curl_exec($curl); curl_close($curl); return $result;&#125;"},{"title":"categories","date":"2019-03-21T07:11:04.000Z","updated":"2019-03-21T07:11:32.000Z","comments":false,"path":"categories/index.html","permalink":"https://sbcoder.cn/categories/index.html","excerpt":"","text":""},{"title":"Links","date":"2019-04-22T12:14:24.000Z","updated":"2020-05-27T14:34:11.737Z","comments":true,"path":"custom/index.html","permalink":"https://sbcoder.cn/custom/index.html","excerpt":"","text":"我的朋友 - 排名不分先后 - songsong’s Blog - 猫爪导航🐱 - Huas Leung’s Blog 申请友情链接 直接在下面留言即可！ 要求： - 正规站点 - 博客类优先 - 技术类站点优先 本站链接格式 - 风向标博客 - https://sbcoder.cn"},{"title":"tags","date":"2019-03-21T05:14:24.000Z","updated":"2019-03-21T05:14:52.000Z","comments":false,"path":"tags/index.html","permalink":"https://sbcoder.cn/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"ElasticSearch & Kibana 从零开始搭建到使用","slug":"ElasticSearch-Kibana-从零开始搭建到使用","date":"2020-05-27T12:34:16.000Z","updated":"2020-06-03T03:49:28.361Z","comments":true,"path":"2020/05/27/ELK_Stack.html","link":"","permalink":"https://sbcoder.cn/2020/05/27/ELK_Stack.html","excerpt":"","text":"引言介绍基于Lucene的搜索服务器，它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。更适用于集群部署，适合各类 分词，全文搜索，通过建立索引（分片，按节点分片）来实现更快的搜索Elasticsearch是与Logstash的数据收集和日志解析引擎以及Kibana的分析和可视化平台一起开发的。这三个产品被设计成一个集成解决方案，称为“Elastic Stack”（以前称为“ELK stack”）。本文只做单节点运行 ELK.png 官方介绍 Elasticsearch 是一个分布式、RESTful 风格的搜索和数据分析引擎，能够解决不断涌现出的各种用例。 作为 Elastic Stack 的核心，它集中存储您的数据，帮助您发现意料之中以及意料之外的情况。 注意事项 单点服务器维持稳定可能需要常驻内存 4G 以上 单点ELK维持稳定可能需要CPU 4核心 以上 参考文章 Docker安装部署ELK教程 (Elasticsearch+Kibana+Logstash+Filebeat) 零门槛！基于Docker快速部署ES集群 下载集群所需镜像 zookeeper kafka12docker pull zookeeperdocker pull wurstmeister/kafka 单节点无内网IP使用1docker network create elkwork 创建内部网络后在每次 docker run 的时候 增加参数 --net elkwork elastic相关 旧版本 123docker pull docker.elastic.co/elasticsearch/elasticsearch:5.6.8docker pull docker.elastic.co/kibana/kibana:5.6.8docker pull docker.elastic.co/logstash/logstash:5.6.8 新版本 1234docker pull docker.elastic.co/elasticsearch/elasticsearch:7.7.0docker pull docker.elastic.co/kibana/kibana:7.7.0docker pull docker.elastic.co/logstash/logstash:7.7.0docker pull store/elastic/filebeat:7.7.0 启动elasticsearch 自行替换版本&quot;discovery.type=single-node&quot; 单节点1docker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot; docker.elastic.co/elasticsearch/elasticsearch:5.6.8 默认用户名 默认密码elastic changeme 测试是否已经连通-u elastic:changeme 验权1curl -u elastic:changeme localhost:9200 浏览器端口访问测试 elasticsearch.png elasticsearch 各类语法基本浏览器访问http://xxx.xx.xxx.xx:9200/_cat/indices?v 查看当前节点的所有 Indexhttp://xxx.xx.xxx.xx:9200/_mapping?pretty=true 列出每个 Index 所包含的 Type 验权机制增加参数 -u elastic:changeme 验权 命令行访问curl -u elastic:changeme -X PUT &#39;localhost:9200/weather&#39; 可以直接向 Elastic 服务器发出 PUT 请求curl -u elastic:changeme -X DELETE &#39;localhost:9200/weather&#39; 发出 DELETE 请求，删除这个 Index 插入数据123456curl -X POST &apos;localhost:9200/account/person&apos; -d &apos;&#123; &quot;user&quot;: &quot;李四&quot;, &quot;title&quot;: &quot;工程师&quot;, &quot;desc&quot;: &quot;系统管理&quot;&#125;&apos; 读取数据1curl &apos;localhost:9200/account/person/1?pretty=true&apos; 示例 123456789101112&#123; \"_index\" : \"accounts\", \"_type\" : \"person\", \"_id\" : \"1\", \"_version\" : 1, \"found\" : true, \"_source\" : &#123; \"user\" : \"张三\", \"title\" : \"工程师\", \"desc\" : \"数据库管理\" &#125;&#125; 删除记录1curl -X DELETE &apos;localhost:9200/accounts/person/1&apos; 更新记录123456curl -X PUT &apos;localhost:9200/accounts/person/1&apos; -d &apos;&#123; &quot;user&quot; : &quot;张三&quot;, &quot;title&quot; : &quot;工程师&quot;, &quot;desc&quot; : &quot;数据库管理，软件开发&quot;&#125;&apos; 返回所有记录1curl &apos;localhost:9200/accounts/person/_search&apos; 索引 ：/Index/Type/_search total：返回记录数，本例是2条。 max_score：最高的匹配程度，本例是1.0。 hits：返回的记录组成的数组。 查询记录123456curl &apos;localhost:9200/accounts/person/_search&apos; -d &apos;&#123; &quot;query&quot; : &#123; &quot;match&quot; : &#123; &quot;desc&quot; : &quot;软件 系统&quot; &#125;&#125;, &quot;from&quot;: 1 &quot;size&quot;: 1&#125;&apos; size 返回数量 from 开始位置 OR搜索，当前搜索的示例是 软件或系统 AND搜索示例12345678910&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123; &quot;match&quot;: &#123; &quot;desc&quot;: &quot;软件&quot; &#125; &#125;, &#123; &quot;match&quot;: &#123; &quot;desc&quot;: &quot;系统&quot; &#125; &#125; ] &#125; &#125;&#125; 参考文章 全文搜索引擎 Elasticsearch 入门教程 启动kibana 自行替换版本1docker run -d --name kibana -p 8001:5601 docker.elastic.co/kibana/kibana:5.6.8 kibana 容器内部修改配置ip1Vi ./config/kibana.yml 重启容器使配置生效 kibana.png 配置 logstash123mkdir /home/tjy/docker/logstash/mkdir /home/tjy/docker/logstash/conf.d/vi /home/tjy/docker/logstash/logstash.yml 12path.config: /usr/share/logstash/conf.d/*.confpath.logs: /var/log/logstash 1vi /home/tjy/docker/logstash/conf.d/test.conf 123456789101112131415input &#123; beats &#123; port =&gt; 5044 codec =&gt; &quot;json&quot;&#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; [&quot;xxx.xx.xxx.xx:9200&quot;] user =&gt; elastic password =&gt; changeme &#125; stdout &#123; codec =&gt; rubydebug &#125;&#125; 启动logstash并挂载1docker run -it -d -p 8011:5044 -p 9600:9600 --name logstash -v /home/tjy/docker/logstash/logstash.yml:/usr/share/logstash/config/logstash.yml -v /home/tjy/docker/logstash/conf.d/:/usr/share/logstash/conf.d/ docker.elastic.co/logstash/logstash:5.6.8 配置 filebeat下载 通用配置文件 1234mkdir /Users/XXX/Downloads/Docker/filebeat/cd /Users/XXX/Downloads/Docker/filebeatwget https://raw.githubusercontent.com/elastic/beats/7.1/deploy/docker/filebeat.docker.ymlvi filebeat.docker.yml 配置监听 Nginx log 123456789101112131415161718192021filebeat.config: modules: path: $&#123;path.config&#125;/modules.d/*.yml reload.enabled: falsefilebeat.autodiscover: providers: - type: docker hints.enabled: trueprocessors:- add_cloud_metadata: ~filebeat.inputs:- type: log enabled: true paths: - /var/log/nginx/*.logoutput.logstash: hosts: [&apos;logstash:5044&apos;] filebeat 配合 logstash 挂载并启动以下映射的路径为我自己电脑的路径，需要自行修改！1docker run --name filebeat --user=root -d --net elkwork -v /usr/local/var/log/nginx/:/var/log/nginx/ -v /Users/XXX/Downloads/Docker/filebeat/filebeat.docker.yml:/usr/share/filebeat/filebeat.yml -v /var/run/docker.sock:/var/run/docker.sock store/elastic/filebeat:7.7.0 success.png","categories":[{"name":"架构","slug":"架构","permalink":"https://sbcoder.cn/categories/架构/"}],"tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://sbcoder.cn/tags/ElasticSearch/"},{"name":"kibana","slug":"kibana","permalink":"https://sbcoder.cn/tags/kibana/"},{"name":"Logstash","slug":"Logstash","permalink":"https://sbcoder.cn/tags/Logstash/"}]},{"title":"Docker 安装 PHP-fpm","slug":"Docker-安装-PHP-fpm","date":"2020-05-17T04:54:47.000Z","updated":"2020-05-17T04:55:53.037Z","comments":true,"path":"2020/05/17/Docker_PHP_fpm.html","link":"","permalink":"https://sbcoder.cn/2020/05/17/Docker_PHP_fpm.html","excerpt":"","text":"创建 uploads.ini12345file_uploads = Onmemory_limit = 64 Mupload_max_filesize = 20Mpost_max_size = 20Mmax_execution_time = 600 创建 Dockerfile1234567891011121314151617FROM php:7.3-fpmRUN apt-get updateRUN apt-get install -y libwebp-dev libjpeg-dev libpng-dev libfreetype6-devEXPOSE 9000#上传配置成20MCOPY uploads.ini /usr/local/etc/php/conf.dRUN docker-php-ext-install mysqliRUN docker-php-ext-install pdoRUN docker-php-ext-install pdo_mysqlRUN pecl install redis-4.2.0 &amp;&amp; docker-php-ext-enable redisRUN docker-php-ext-install bcmathRUN docker-php-ext-configure gd --with-webp-dir=/usr/include/webp --with-png-dir=/usr/include --with-jpeg-dir=/usr/include --with-freetype-dir=/usr/include/freetype2RUN docker-php-ext-install gd 运行容器挂载物理机内容到 容器内部 可以修改下方的 /var/www/html/workspace 为你的项目地址 1docker run -v /var/www/html/workspace:/var/www/html/workspace -p 9002:9000 -d php73:0.1 Nginx配置修改 fastcgi_pass 后面的 值为 127.0.0.1:9002 LNMP用户 修改 /usr/local/nginx/conf/enable-php-pathinfo.conf 将 fastcgi_pass unix:/tmp/php-cgi.sock; 修改为 fastcgi_pass 127.0.0.1:9002; 其他环境与此类似，直接改即可","categories":[{"name":"PHP","slug":"PHP","permalink":"https://sbcoder.cn/categories/PHP/"}],"tags":[{"name":"fpm","slug":"fpm","permalink":"https://sbcoder.cn/tags/fpm/"},{"name":"nginx","slug":"nginx","permalink":"https://sbcoder.cn/tags/nginx/"}]},{"title":"Workerman 适合PHPer使用的Socket通讯框架","slug":"Workerman-适合PHPer使用的Socket通讯框架","date":"2020-05-14T13:48:33.000Z","updated":"2020-05-14T13:51:53.699Z","comments":true,"path":"2020/05/14/workerman.html","link":"","permalink":"https://sbcoder.cn/2020/05/14/workerman.html","excerpt":"","text":"简介适用于 客户端-服务端 客户端-客户端 一对多 多对多的关系，多个客户端之间的长连接通信，聊天室，在线客服，服务端反向推送播报消息 特性：多进程，长连接，高并发，常驻内存… 客户端与worker进程 客户端与worker进程.png 主进程与worker子进程 主进程与worker子进程.png 使用Workerman可以做很多有趣的事。（工业自动化，互联网工业，PLC机械报警…），通过长连接取数据，操作数据等，但PHP并不适用于工业领域。做一个仿im聊天工具，除了前端展示界面，后端也要考虑全面，更多的依赖于长连接。 本文参考 workerman官方文档本文参考 thinksocketio - 基于socketio的聊天室Demo 安装Workerman框架服务端创建一个文件夹 我这里使用 testWebSocket12mkdir testWebSocketcd testWebSocket git形式安装(推荐)1git clone https://github.com/walkor/Workerman 根据官方文档创建一个示例 在 testWebSocket 下创建一个 PHP文件 test.php12345678910111213141516171819&lt;?phpuse Workerman\\Worker;require_once __DIR__ . '/Workerman/Autoloader.php';// 注意：这里与上个例子不同，使用的是websocket协议$ws_worker = new Worker(\"websocket://0.0.0.0:2000\");// 启动4个进程对外提供服务$ws_worker-&gt;count = 4;// 当收到客户端发来的数据后返回hello $data给客户端$ws_worker-&gt;onMessage = function($connection, $data)&#123; // 向客户端发送hello $data $connection-&gt;send('hello ' . $data);&#125;;// 运行workerWorker::runAll() 前端测试前端测试例子代码 直接在Google浏览器执行123456789ws = new WebSocket(\"ws://127.0.0.1:2000\");ws.onopen = function() &#123; alert(\"连接成功\"); ws.send('tom'); alert(\"给服务端发送一个字符串：tom\");&#125;;ws.onmessage = function(e) &#123; alert(\"收到服务端的消息：\" + e.data);&#125;; 效果展示 执行界面.png 服务端界面.png Workermen框架支持的协议1234567891011$websocket_worker = new Worker('websocket://0.0.0.0:2345');// text协议$text_worker = new Worker('text://0.0.0.0:2346');// frame协议$frame_worker = new Worker('frame://0.0.0.0:2347');// tcp Worker，直接基于socket传输，不使用任何应用层协议$tcp_worker = new Worker('tcp://0.0.0.0:2348');// udp Worker，不使用任何应用层协议$udp_worker = new Worker('udp://0.0.0.0:2349');// unix domain Worker，不使用任何应用层协议$unix_worker = new Worker('unix:///tmp/wm.sock'); 整合ThinkPHP说明Workermen是一个成熟的单独框架，在ThinkPHP中也可以使用Composer安装对应的扩展来使用，这里使用了针对PHP开发的扩展 PHPSocket.IO。PHPSocket.IO设计的目标是利用PHP构建能够在不同浏览器和移动设备上良好运行的实时应用，如实时分析系统、在线聊天室、在线客服系统、评论系统、WebIM等。 PHPSocket.IO与workerman的区别是，PHPSocket.IO基于workerman开发，workerman有的特性PHPSocket.IO都支持。 PHPSocket.IO最大的优势是对各种浏览器的兼容性更好。 安装及引用使用Composer 安装对应的扩展1composer require workerman/phpsocket.io 在编辑代码时引用对应的扩展即可12use Workerman\\Worker;use PHPSocketIO\\SocketIO; 服务端创建一个服务端 application\\socketio\\controller\\server.php12345678910111213141516171819202122232425262728293031&lt;?phpnamespace app\\socketio\\controller;use Workerman\\Worker;use PHPSocketIO\\SocketIO;use think\\Db;class Server&#123; public function index()&#123; // 在2021端口创建服务 $io = new SocketIO(2021); $io-&gt;on('connection', function($socket)use($io)&#123; $socket-&gt;on('chat message', function($msg)use($io)&#123; $io-&gt;emit('chat message', $msg); &#125;); // 监听到新的客户端连接即在服务端输出'new connection' echo 'new connection'.\"\\n\"; // 并向服务端发送'连接成功' $socket-&gt;emit('success', '连接成功'); // 服务端发送消息过来 $socket-&gt;on('sendMsg', function($msg)use($io)&#123; // 在服务端输出消息 echo $msg.\"\\n\"; // 在收到的消息前面拼接'收到'后向客户端发送回去 $io-&gt;emit('sendMsg', '收到\"'.$msg.'\"'); &#125;); &#125;); // 启动服务 Worker::runAll(); &#125;&#125; 由于 Workermen 是一个独立于PHP程序使用的单一文件，需要单独用一个命令行来启动的，他完全可以独立使用，因此并不推荐使用TP框架来整合，但如果有这个需求，也可以在 /public目录下生成一个文件来绑定控制器，例如绑定 到 socketio/Server创建文件 public/server.php , 输入以下内容123456789&lt;?php// [ 应用入口文件 ]namespace think;// 加载基础文件require __DIR__ . '/../thinkphp/base.php';// 执行应用并响应（绑定）Container::get('app')-&gt;bind('socketio/Server')-&gt;run()-&gt;send(); 执行时 直接在Shell中运行该PHP文件即可，剩下的交给TP的机制12cd /publicphp server.php 执行结果.png 结语根据通信行为可以衍生出各类应用，目前websocket已经是各大公司都需要的技术，会websocket就多了一份机会！","categories":[{"name":"PHP","slug":"PHP","permalink":"https://sbcoder.cn/categories/PHP/"}],"tags":[{"name":"socket","slug":"socket","permalink":"https://sbcoder.cn/tags/socket/"},{"name":"通讯","slug":"通讯","permalink":"https://sbcoder.cn/tags/通讯/"},{"name":"workerman","slug":"workerman","permalink":"https://sbcoder.cn/tags/workerman/"}]},{"title":"UnblockNeteaseMusic 解锁网易云音乐灰色歌曲","slug":"UnblockNeteaseMusic-解锁网易云音乐灰色歌曲","date":"2020-05-09T13:52:19.000Z","updated":"2020-05-09T13:53:34.444Z","comments":true,"path":"2020/05/09/UnblockNeteaseMusic.html","link":"","permalink":"https://sbcoder.cn/2020/05/09/UnblockNeteaseMusic.html","excerpt":"","text":"Docker 安装运行服务端基于nondanee/UnblockNeteaseMusic的音乐解锁代理服务 1docker run --name=unblockneteasemusic -d -p 8888:8080 nondanee/unblockneteasemusic 日志界面 配置客户端 平台 基础设置 Windows 设置 &gt; 工具 &gt; 自定义代理 (客户端内) UWP Windows 设置 &gt; 网络和 Internet &gt; 代理 Linux 系统设置 &gt; 网络 &gt; 网络代理 macOS 系统偏好设置 &gt; 网络 &gt; 高级 &gt; 代理 Android WLAN &gt; 修改网络 &gt; 高级选项 &gt; 代理 iOS 无线局域网 &gt; HTTP 代理 &gt; 配置代理 Windows配置截图 将ip设置为服务器ip即可，映射内部的8080到外部8888端口 效果 当播放或者下载时，日志会记录，解析过程","categories":[{"name":"折腾","slug":"折腾","permalink":"https://sbcoder.cn/categories/折腾/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://sbcoder.cn/tags/Docker/"},{"name":"音乐","slug":"音乐","permalink":"https://sbcoder.cn/tags/音乐/"}]},{"title":"2020年计划","slug":"2020年计划","date":"2020-02-19T01:50:52.000Z","updated":"2020-05-01T01:43:27.538Z","comments":true,"path":"2020/02/19/2020.html","link":"","permalink":"https://sbcoder.cn/2020/02/19/2020.html","excerpt":"","text":"开源项目计划vFeedBack整合，重构vFeedBack项目，完善系统 vFeedBack准备列入我的第一个商业系统 vFeedBack将更适合企业应用 vFeedBack将区分商业和个人版 企业可以单独运营vFeedBack项目 我自己也将独立运营Pollos网址导航暂停 Pollos是一个坑爹的项目 数据库丢失，继续下去需要很多的人力物力，需要重理思路逻辑 后台模板可能涉及侵权问题，需要重写写一个通用的后台管理系统 支持前后端分离项目 预备将Pollos的管理系统修改为这个新的管理系统 预备要做的很多 暂定名字为 easyAdmin，基于Laravel5.8以上 前端知识补充 学习VUE，刻不容缓 （进行中） Element UI学习，前后端分离，VUE 知识补充 学习Socket相关知识 laravel深入了解 Golang加深 Docker加深，k8s，Rancher(想去面试) 某事结束后 争取今年自己还房贷 把xnbox做一做，没准能赚点外快 玩个网游，下班无聊时还能看一看 （不执行） 找个女朋友老生常谈，不知道能不能行，我得抓紧了（暂缓执行） 减肥20斤肚子大了，今年目标20斤，干掉肚腩","categories":[{"name":"note","slug":"note","permalink":"https://sbcoder.cn/categories/note/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"https://sbcoder.cn/tags/笔记/"},{"name":"计划","slug":"计划","permalink":"https://sbcoder.cn/tags/计划/"}]},{"title":"Aria2 + Rclone + Goindex 实现离线下载在线观看","slug":"Aria2-Rclone-Goindex-实现离线下载在线观看","date":"2020-01-21T23:32:33.000Z","updated":"2020-01-23T00:48:01.000Z","comments":true,"path":"2020/01/22/aria_goindex.html","link":"","permalink":"https://sbcoder.cn/2020/01/22/aria_goindex.html","excerpt":"","text":"准备工作 云阀 5R NAT小鸡 Google Drive 账号一枚 CloudFlare 账号 关于云阀的小鸡，性价比高，只提供ipv6和ipv4端口，因此下面的教程可能某些地方做了多余的动作，例如修改端口号等 安装Aria2一键脚本执行下面的命令1wget -N git.io/aria2.sh &amp;&amp; chmod +x aria2.sh &amp;&amp; ./aria2.sh 进入下载脚本的目录运行脚本123456789101112131415161718192021222324252627./aria2.shAria2 一键安装管理脚本 [vX.X.X]-- P3TERX.COM --1. 升级脚本————————————1. 安装 Aria22. 更新 Aria23. 卸载 Aria2————————————4. 启动 Aria25. 停止 Aria26. 重启 Aria2————————————7. 修改 配置8. 查看 配置9. 查看 日志10. 清空 日志————————————11. 手动更新 BT-Tracker12. 自动更新 BT-Tracker————————————当前状态: 已安装 并 已启动请输入数字 [0-12]: 输入 1 回车 1.png 等待安装完成 再执行1./aria2.sh 输入 7 回车 2.png 如需要可修改 RPC 密码，也建议修改 安装 LNMP 一键安装包 / Nginx我这里安装LNMP，其实只需要 Nginx就行了安装教程参考 安装 - LNMP一键安装包 或者 直接执行1wget http://soft.vpser.net/lnmp/lnmp1.6.tar.gz -cO lnmp1.6.tar.gz &amp;&amp; tar zxf lnmp1.6.tar.gz &amp;&amp; cd lnmp1.6 &amp;&amp; ./install.sh lnmp 我这里安装的是 1.6 ，可自行修改版本号 安装 Aria2NG 界面管理打开地址 Releases · mayswind/AriaNg选择最新版本下载到 网站 目录下，如果不知道网站目录配置，建议存放在 LNMP的默认目录 /home/wwwroot/ 按照如下操作12345mkdir /home/wwwroot/Xcd /home/wwwroot/Xwget https://github.com/mayswind/AriaNg/releases/download/1.1.4/AriaNg-1.1.4.zipunzip AriaNg-1.1.4.ziprm AriaNg-1.1.4.zip 配置 Nginx12cd /usr/local/nginx/conf/vhost/vi X.conf 输入以下配置123456789101112131415161718192021222324252627282930313233343536373839404142server &#123; listen 10002 default_server reuseport; #listen [::]:80 default_server ipv6only=on; server_name _; index index.html index.htm index.php; root /home/wwwroot/x; #error_page 404 /404.html; # Deny access to PHP files in specific directory #location ~ /(wp-content|uploads|wp-includes|images)/.*\\.php$ &#123; deny all; &#125; include enable-php.conf; location /nginx_status &#123; stub_status on; access_log off; &#125; location ~ .*\\.(gif|jpg|jpeg|png|bmp|swf)$ &#123; expires 30d; &#125; location ~ .*\\.(js|css)?$ &#123; expires 12h; &#125; location ~ /.well-known &#123; allow all; &#125; location ~ /\\. &#123; deny all; &#125; access_log /home/wwwlogs/access.log; &#125; 主要就是把端口改为 10002，其他的就是lnmp默认配置不动 配置完毕后，打开 网址 http://virt-nat-eu-1.cloudraft.cn:1XXX5将XX替换成你的 内网IP最后一位 例如 2 则访问 http://virt-nat-eu-1.cloudraft.cn:10025 3.png 点击 Aria2NG配置 - RPC(XXXX) 4.png 修改 RPC 别名 RPC 地址 RPC 秘钥其他不动，按图填写即可 免费申请一个Google无限团队盘打开地址 创建Google TeamDriveGmail必须填写正确！ 等待创建即可！ 安装Rclone执行12curl https://rclone.org/install.sh | sudo bashrclone config 配置说明如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148e) Edit existing remoten) New remoted) Delete remoter) Rename remotec) Copy remotes) Set configuration passwordq) Quit confige/n/d/r/c/s/q&gt; n # 选择n，新建name&gt; Google # 输入名称，类似于标签，用于区分不同的网盘。Type of storage to configure.Enter a string value. Press Enter for the default (&quot;&quot;).Choose a number from below, or type in your own value 1 / A stackable unification remote, which can appear to merge the contents of several remotes \\ &quot;union&quot; 2 / Alias for a existing remote \\ &quot;alias&quot; 3 / Amazon Drive \\ &quot;amazon cloud drive&quot; 4 / Amazon S3 Compliant Storage Providers (AWS, Ceph, Dreamhost, IBM COS, Minio) \\ &quot;s3&quot; 5 / Backblaze B2 \\ &quot;b2&quot; 6 / Box \\ &quot;box&quot; 7 / Cache a remote \\ &quot;cache&quot; 8 / Dropbox \\ &quot;dropbox&quot; 9 / Encrypt/Decrypt a remote \\ &quot;crypt&quot;10 / FTP Connection \\ &quot;ftp&quot;11 / Google Cloud Storage (this is not Google Drive) \\ &quot;google cloud storage&quot;12 / Google Drive \\ &quot;drive&quot;13 / Hubic \\ &quot;hubic&quot;14 / JottaCloud \\ &quot;jottacloud&quot;15 / Local Disk \\ &quot;local&quot;16 / Mega \\ &quot;mega&quot;17 / Microsoft Azure Blob Storage \\ &quot;azureblob&quot;18 / Microsoft OneDrive \\ &quot;onedrive&quot;19 / OpenDrive \\ &quot;opendrive&quot;20 / Openstack Swift (Rackspace Cloud Files, Memset Memstore, OVH) \\ &quot;swift&quot;21 / Pcloud \\ &quot;pcloud&quot;22 / QingCloud Object Storage \\ &quot;qingstor&quot;23 / SSH/SFTP Connection \\ &quot;sftp&quot;24 / Webdav \\ &quot;webdav&quot;25 / Yandex Disk \\ &quot;yandex&quot;26 / http Connection \\ &quot;http&quot;Storage&gt; 12 # 选择12，Google Drive** See help for drive backend at: https://rclone.org/drive/ **Google Application Client IdLeave blank normally.Enter a string value. Press Enter for the default (&quot;&quot;).client_id&gt; # 留空，回车Google Application Client SecretLeave blank normally.Enter a string value. Press Enter for the default (&quot;&quot;).client_secret&gt; # 留空，回车Scope that rclone should use when requesting access from drive.Enter a string value. Press Enter for the default (&quot;&quot;).Choose a number from below, or type in your own value 1 / Full access all files, excluding Application Data Folder. \\ &quot;drive&quot; 2 / Read-only access to file metadata and file contents. \\ &quot;drive.readonly&quot; / Access to files created by rclone only. 3 | These are visible in the drive website. | File authorization is revoked when the user deauthorizes the app. \\ &quot;drive.file&quot; / Allows read and write access to the Application Data folder. 4 | This is not visible in the drive website. \\ &quot;drive.appfolder&quot; / Allows read-only access to file metadata but 5 | does not allow any access to read or download file content. \\ &quot;drive.metadata.readonly&quot;scope&gt; 1ID of the root folderLeave blank normally.Fill in to access &quot;Computers&quot; folders. (see docs).Enter a string value. Press Enter for the default (&quot;&quot;).root_folder_id&gt; # 留空，回车Service Account Credentials JSON file pathLeave blank normally.Needed only if you want use SA instead of interactive login.Enter a string value. Press Enter for the default (&quot;&quot;).service_account_file&gt;Edit advanced config? (y/n)y) Yesn) Noy/n&gt; nRemote configUse auto config? * Say Y if not sure * Say N if you are working on a remote or headless machine or Y didn&apos;t worky) Yesn) Noy/n&gt; nIf your browser doesn&apos;t open automatically go to the following link: https://accounts.google.com/o/oauth2/auth?access_type=offline&amp;client_id=XXXXXXXXXXX.apps.googleusercontent.com&amp;redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&amp;response_type=code&amp;scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&amp;state=XXXXXXXXXXXXXXXXXXXXLog in and authorize rclone for access # 会弹出浏览器，要求你登录账号进行授权。如果没有弹出，复制上面的链接到浏览器中打开进行授权。Enter verification code&gt; # 在这里输入网页上显示的验证码Configure this as a team drive?y) Yesn) Noy/n&gt; yFetching team drive list...No team drives found in your account--------------------[Google]type = drivescope = drivetoken = &#123;&quot;access_token&quot;:&quot;XXXXXXXXXXXXXXXXXXXXX&quot;&#125;--------------------y) Yes this is OKe) Edit this remoted) Delete this remotey/e/d&gt; yCurrent remotes:Name Type==== ====Google driveOne onedrivee) Edit existing remoten) New remoted) Delete remoter) Rename remotec) Copy remotes) Set configuration passwordq) Quit confige/n/d/r/c/s/q&gt; q 参考:P3TERX - Rclone 安装配置教程 - 连接 OneDrive 和 Google Drive 配置 Aira2 自动上传执行 按图修改1vi /root/.aria2/autoupload.sh 5.png 执行 按图修改1vi /root/.aria2/aria2.conf 6.png 重启 Aria21service aria2 restart 使用Goindex + CloudFlare搞一个在线观看官方说明 donwa/Github 复制 index.js 里面的代码 打开 CloudFlare ，创建Workers 7.png 将上面复制的内容黏贴到Script中 执行 并 查看 rclone.conf 路径。1rclone config file 8.png 复制 root_folder_id 和 refresh_token 的值填入 CloudFlare Workers Script对应的代码位置里面 9.png 配置好后点击保存，然后打开CloudFlare Workers提供的域名即可看到对应的网盘内容 作者博客 风向标博客","categories":[{"name":"折腾","slug":"折腾","permalink":"https://sbcoder.cn/categories/折腾/"}],"tags":[{"name":"离线下载","slug":"离线下载","permalink":"https://sbcoder.cn/tags/离线下载/"},{"name":"Google","slug":"Google","permalink":"https://sbcoder.cn/tags/Google/"}]},{"title":"Canal 根据 binlog日志数据同步","slug":"Canal-根据-binlog日志数据同步","date":"2020-01-21T23:32:09.000Z","updated":"2020-01-21T23:33:46.000Z","comments":true,"path":"2020/01/22/canal_go.html","link":"","permalink":"https://sbcoder.cn/2020/01/22/canal_go.html","excerpt":"","text":"创建mysql账户如果使用的是root用户，则不需要操作这个步骤 grant all privileges on . to ‘jcc’@’%’ identified by ‘jcc’;flush privileges; 配置mysql (参见canal Quickstart)启用binlog日志打开 mysql.cnf 文件1234[mysqld] log-bin=mysql-bin binlog-format=ROW #选择row模式 server_id=9527 #配置mysql replaction需要定义，不能和canal的slaveId重复 添加slave权限如果使用的是root用户，则不需要操作这个步骤12CREATE USER canal IDENTIFIED BY 'canal'; GRANT SELECT, SHOW VIEW, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'canal'@'%';FLUSH PRIVILEGES; 创建canal server 服务端需要提前安装好Docker，如果不会安装，可以参考我之前写的文章 CentOS7 安装 Docker 1docker run -p 11111:11111 -e canal.auto.scan=false -e canal.instance.master.address=127.0.0.1:3306 -e canal.instance.dbUsername=test -e canal.instance.dbPassword=test -e canal.instance.connectionCharset=UTF-8 -e canal.instance.tsdb.enable=true -e canal.instance.gtidon=false -e canal.instance.filter.regex=.*\\\\..* -e canal.destinations=test -d canal/canal-server 需要替换以下参数 canal.instance.master.address=127.0.0.1:3306 地址ip更换（尽量用内网） canal.instance.dbUsername=test 数据库账户 canal.instance.dbPassword=test 数据库密码 canal.destinations=test test为名称 可以修改 11111:11111 服务器端口：docker端口 需要注意的是，所填写的数据库账户必须拥有数据库的操作权限，如果不知道权限如何配置，则建议直接使用root用户 canal 客户端我们这里使用Go客户端，因为Go语言的特性，可以很好的运行在Docker上 canal-go 文档: withlin/canal-go 开发过程可以参照文档 Docker启动canal客户端推荐使用Jenkins配置 canal-go构建成功后执行shell 12docker build -t canal_prod:v1 $&#123;WORKSPACE&#125;docker service update --image canal_prod:v1 --force --no-resolve-image canal_prod 如果看过我之前的 代码架构文章，可以在Portainer中看到打印在控制台的文字，也可以看到运行状态 FAQ问题解决Q:如果服务停止了，如何解决A:链接到canal-server的Docker内部，查看 canal-server - logs 中的日志 Q:如果数据同步失败了如何解决A:很大可能是由于改变了数据库结构导致的，需要重启客户端和服务端尝试 Q:一开始数据就不同步A:查看你的数据库账户是否有权限，如无权限则修改服务端启动时附带的数据库账户参数","categories":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/categories/优化/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://sbcoder.cn/tags/数据库/"},{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/tags/优化/"}]},{"title":"ThinkPHP使用RabbitMQ进行数据解耦 从安装到监听完全版","slug":"ThinkPHP使用RabbitMQ进行数据解耦-从安装到监听完全版","date":"2020-01-07T15:32:40.000Z","updated":"2020-01-07T15:33:42.000Z","comments":true,"path":"2020/01/07/rabbitmq_thinkphp.html","link":"","permalink":"https://sbcoder.cn/2020/01/07/rabbitmq_thinkphp.html","excerpt":"","text":"介绍分布式部署，RabbitMQ(简称MQ)作为消息中间件是一个非常不错的选择，可以实现异步互不干扰的解耦操作。 解决需求当有两套系统分别部署时，需要同步一部分数据，或者需要互不干扰解决异步独立运行时，可以使用RebbitMQ来给两套系统解耦，使用RebbitMQ作为中间件，只做消息传输使用，当系统A宕机或者因故障无法使用时，不会影响到系统B的正常运行！ 部署MQ使用Docker部署，安装Docker可以参照之前写的 CentOS7 安装 Docker，或者Ubuntu16.04/Ubuntu18.04 安装 Docker。 下载镜像镜像地址 rabbitmq1docker pull rabbitmq:management 1.png 1234# 创建容器并运行docker run -d -p 5672:5672 -p 15672:15672 --name rabbitmq rabbitmq:management# 查看 当前运行的容器docker ps 2.png 配置MQ安装MQ打开 http://IP:15672 3.png 使用默认用户名密码登录username:guest password:guest 4.png 红框内为你的rabbitmq版本号，我这里是3.8.2 创建一个管理员用户 5.png 修改guest的密码，请将123456修改为你需要修改的密码123docker exec -it rabbitmq /bin/bashrabbitmqctl list_usersrabbitmqctl change_password guest &apos;123456&apos; 修改guest默认密码以防止被人恶意利用 6.png 创建队列及交换机创建队列可以在mq页端创建也可以在代码中自动创建，我这里直接在页端创建 创建Queen 创建交换机，也在页端创建好 创建Exchange ThinkPHP实现过程Composer安装php-amqplib略 生产者实现 创建一个生产者类放置于 common 目录下，方便调用 123456789101112131415161718192021222324252627282930313233343536class RabbitMq&#123; protected $connection; protected $channel; //protected $exchange = 'router'; // //protected $queue = 'msgs'; public function __construct()&#123; $this-&gt;connection = new AMQPStreamConnection(config('rabbit_mq.host'), config('rabbit_mq.port'), config('rabbit_mq.user'), config('rabbit_mq.password')); $this-&gt;channel = $this-&gt;connection-&gt;channel(); &#125; /* * 向队列发送信息（生产者） * $data 向队列发送参数 * $code 路由名 * $queue 主题 * */ public function send($data,$exchange,$routing_key='order')&#123;// $this-&gt;channel-&gt;queue_declare($this-&gt;queue, false, true, false, false);// $this-&gt;channel-&gt;exchange_declare($this-&gt;exchange, AMQPExchangeType::DIRECT, false, true, false);// $this-&gt;channel-&gt;queue_bind($this-&gt;queue, $this-&gt;exchange); $messageBody = json_encode($data);//将要发送数据变为json字符串 $message = new AMQPMessage($messageBody, array('content_type' =&gt; 'text/plain', 'delivery_mode' =&gt; AMQPMessage::DELIVERY_MODE_PERSISTENT)); $this-&gt;channel-&gt;basic_publish($message,$exchange,$routing_key); $this-&gt;stop(); &#125; //关闭进程 public function stop()&#123; $this-&gt;channel-&gt;close(); $this-&gt;connection-&gt;close(); &#125;&#125; 实现过程如下 123456789101112131415161718192021222324252627class RabbitMq extends controller&#123; private $rabbitMq; /** * Unit constructor. * @param Request $request * @throws \\think\\db\\exception\\DataNotFoundException * @throws \\think\\db\\exception\\ModelNotFoundException * @throws \\think\\exception\\DbException */ public function __construct(Request $request)&#123; parent::__construct(); $this-&gt;rabbitMq = new \\app\\common\\RabbitMq(); &#125; /** * 添加 * @throws \\think\\db\\exception\\DataNotFoundException * @throws \\think\\db\\exception\\ModelNotFoundException * @throws \\think\\exception\\DbException */ public function add()&#123; $params = $this-&gt;request-&gt;param(); $this-&gt;rabbitMq-&gt;send($params,'testMq'); &#125;&#125; 消费者实现 创建一个RabbitMq类,方便之后调用 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768class RabbitMq extends controller&#123; protected $connection; protected $channel; protected $exchange; // protected $queue; protected $vhost; protected $consumerTag; protected $routeKey; // 此处使用配置文件配置，具体可自行配置 public function __construct() &#123; //连接RabbitMQ $this-&gt;queue = Config::get('database.RabbitMQ')['queue']; $this-&gt;exchange = Config::get('database.RabbitMQ')['exchange']; $this-&gt;vhost = Config::get('database.RabbitMQ')['vhost']; $this-&gt;consumerTag = 'AgentOrder'; $this-&gt;routeKey = 'addOrderAndSub'; $host = Config::get('database.RabbitMQ')['host']; $port = Config::get('database.RabbitMQ')['port']; $username = Config::get('database.RabbitMQ')['username']; $password = Config::get('database.RabbitMQ')['password']; $this-&gt;connection = new AMQPStreamConnection($host, $port, $username, $password); $this-&gt;channel = $this-&gt;connection-&gt;channel(); $this-&gt;logMqWright('MQ已连接'); &#125; // 消费信息 public function getMessage($callback) &#123; // 队列声明，创建队列，如果不存在则自动创建，如已创建则不需要使用 // $this-&gt;channel-&gt;queue_declare($this-&gt;queue, false, true, false, false); // 绑定交换机 $this-&gt;channel-&gt;exchange_declare($this-&gt;exchange, 'direct', false, true, false); $this-&gt;logMqWright('---MQ交换机绑定完成---'); // 绑定队列 $this-&gt;channel-&gt;queue_bind($this-&gt;queue, $this-&gt;exchange, $this-&gt;routeKey); $this-&gt;logMqWright('---MQ队列绑定完成---'); // 信息消费，no_ack 为true时为自动应答 $this-&gt;channel-&gt;basic_consume($this-&gt;queue, $this-&gt;consumerTag, false, true, false, false, $callback); $i = 0; while (count($this-&gt;channel-&gt;callbacks)) &#123; $this-&gt;logMqWright('---MQ执行次数统计[' . $i . ']---'); $i++; $this-&gt;channel-&gt;wait(); &#125; &#125; // 日志写入函数 目录/runtime/agent_log/当前年月/当前日期MQ.txt protected function logMqWright($msg) &#123; $val = \"\"; $currentDateTime = date('Y-m-d H:i:s', time()); $currentDate = date('Ymd', time()); $fileDir = __DIR__ . '/../../runtime/' . 'agentlog/' . date('Ym', time()); if (!file_exists($fileDir)) &#123; mkdir($fileDir, 0777, true); &#125; $fileName = $fileDir . '/' . $currentDate . \"MQ.txt\";//文件名称 $data = fopen($fileName, 'a+');//添加不覆盖，首先会判断这个文件是否存在，如果不存在，则会创建该文件，即每天都会创建一个新的文件记录的信息 $val = '[' . $currentDateTime . ']:' . $msg; $val .= \"\\n\"; fwrite($data, $val);//写入文本中 &#125; //关闭进程 public function stop() &#123; $this-&gt;channel-&gt;close(); $this-&gt;connection-&gt;close(); &#125;&#125; 消费者消费过程 1234567891011// CLI接口,需要开启守护进程 public function catch() &#123; //连接RabbitMQ $RabbitMq = new \\app\\common\\RabbitMq();//队列 $this-&gt;logAgentWrite('------------------MQ链接成功 开始整理MQ消息------------------'); $callback = function ($msg) &#123; echo $msg; // msg为队列内的信息流，在此处填写消费过程即可 &#125;; $RabbitMq-&gt;getMessage($callback); &#125; 消费者创建监听接口，用于守护进程调用 12345678class MqService&#123; public function __construct() &#123; &#125; public function mqAction() &#123; $this-&gt;catch(); // 调用上面的catch函数，自行修改 &#125;&#125; 至此所需要的代码就完成了 消费者脚本守护进程tips:只适用于Linux 我们在使用PHP作为消费者时，一般是使用PHP直接执行文件，使用nohup守护进程调用，但是当系统不稳定时，可能会出现各种问题导致mq队列失效，这时候就需要使用脚本监听，如果守护进程不存在，则自动重启守护进程 首先测试时可以先执行守护进程命令，例如1nohup /usr/bin/php7.2 /alidata/workspace/test/public/index.php /api_comm/mq_service/mqAction &amp; 路径请自行修改 监听信息编写Shell如下 1234567891011121314151617181920#!/bin/shfile_name=\"/root/restartMqService.log\" #重启脚本的日志，保证可写入，保险一点执行 chmod 777 restartMqService.logpid=0proc_num() &#123; num=`ps -ef | grep '/usr/bin/php7.2 /alidata/workspace/test/public/index.php /api_comm/mq_service/mqAction' | grep -v grep | wc -l` #此处'nohup /usr/bin/php7.2 /alidata/workspace/test/public/index.php /api_comm/mq_service/mqAction &amp;'替代为实际的，尽量准确，避免误kill return $num &#125;proc_id()&#123; pid=`ps -ef | grep '/usr/bin/php7.2 /alidata/workspace/test/public/index.php /api_comm/mq_service/mqAction' | grep -v grep | awk '&#123;print $2&#125;'` #此处'nohup /usr/bin/php7.2 /alidata/workspace/test/public/index.php /api_comm/mq_service/mqAction &amp;'也替代为实际的&#125; proc_num #执行proc_num()，获取进程数number=$? #获取上一函数返回值if [ $number -eq 0 ] #如果没有该进程，则重启then nohup /usr/bin/php7.2 /alidata/workspace/test/public/index.php /api_comm/mq_service/mqAction &amp; #启动程序的命令 proc_id echo $&#123;pid&#125;, `date` &gt;&gt; $file_name #把重启的进程号、时间 写入日志fi 将该脚本重命名为 mqMonitor.sh 配置Crontab在crontab配置文件下加上一行1*/2 * * * * sh /root/mqMonitor.sh 保存后重启生效，大致是2分钟监测一次，可自行修改","categories":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/categories/优化/"}],"tags":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/tags/优化/"},{"name":"消息队列","slug":"消息队列","permalink":"https://sbcoder.cn/tags/消息队列/"},{"name":"解耦","slug":"解耦","permalink":"https://sbcoder.cn/tags/解耦/"}]},{"title":"公司代码架构 - Docker + Jenkins + Gogs + Portainer(四)","slug":"公司代码架构-Docker-Jenkins-Gogs-Portainer-四","date":"2019-12-13T23:35:13.000Z","updated":"2019-12-18T12:51:18.000Z","comments":true,"path":"2019/12/14/docker_swarm.html","link":"","permalink":"https://sbcoder.cn/2019/12/14/docker_swarm.html","excerpt":"","text":"Portainer + Swarm 管理Docker集群介绍Portainer是一个Docker管理工具，它支持多种方式，我们这里只写，远程链接形式和本地形式 搭建环境 服务器1 ：Virmach 水牛城 RAM1.8G 2C 10GSSD（黑五机器） 操作系统 ：Ubuntu16.04 部署环境 ：LNMP1.6 （我是军哥铁粉） 服务器1：搭建Jenkins中转服务器，做代码自动构建使用服务器2：生产环境服务器，实则测试服务器，部署代码使用服务器3：Gogs服务器，Git版本库服务器，做代码版本控制使用 配置Portainer开放DockerAPI端口将需要加入Portainer管理的服务器（需要安装过Docker），打开2375端口，方便管理 创建一个备份，并编辑配置文件12cp /lib/systemd/system/docker.service /lib/systemd/system/docker.service.bak vi /lib/systemd/system/docker.service 方法一：在ExecStart整行后面添加 -H tcp://0.0.0.0:2375，有的时候他可能不止一行，则在最后面增加这一段即可，如下 2.png :wq 保存退出 方法二（推荐）：本方法并不适用于所有的Docker版本1vi /etc/docker/daemon.json 复制以下内容123456&#123; \"hosts\": [ \"tcp://0.0.0.0:2375\", \"unix:///var/run/docker.sock\" ]&#125; 配置完后重启Docker12systemctl daemon-reload systemctl restart docker 这里推荐大家使用iptables防火墙限制一下2375端口的访问，如果将2375暴露在公网则可能出现一系列安全问题，如果是国内的腾讯或者阿里，则可以直接在后台配置安全组，安全组里限制 指定IP访问指定端口即可，如果将2375暴露在外，则可能受到黑客恶意攻击！ 如果不是国内机器，也可以通过iptables限制访问1234iptables -I INPUT -s 107.173.XXX.XXX -p tcp --dport 2375 -j ACCEPTsystemctl iptables.service savesystemctl restart iptables.service# systemctl stop iptables.service 如果配置有误可以停止iptables尝试 非常不推荐直接将2375暴露在公网，秒被黑~ 配置后的效果如下图 3.png 安装Portainer创建数据1docker volume create portainer_data 创建Portainer并运行1docker run -d -p 8000:8000 -p 9000:9000 -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer 执行后访问 http://ip:9000即可看到 1.png 刚创建完会提示创建一个管理员用户，按照提示创建即可 选择创建Docker时使用Remote，远程连接，按下图填写 4.png 添加完成后如下图，点击访问创建好的节点则可以操作里面的内容 5.png 创建Swarm集群在管理节点上增加Swarm集群manager节点12docker swarm init --advertise-addr [IP ADDRESS]# 例如 docker swarm init --advertise-addr 107.173.XXX.XXX 返回结果如下，为了安全，关键位置已打码1234567Swarm initialized: current node (mjjrpuemaukx5a185iqd54mka) is now a manager.To add a worker to this swarm, run the following command: docker swarm join --token SWMTKN-1-1zd********2oci43nbf1jjhlng8k********fhfzqw2-1ywv79qnvmlb*******h3gs35r 107.173.XXX.XXX:2377To add a manager to this swarm, run &apos;docker swarm join-token manager&apos; and follow the instructions. 当Manager节点增加完成后，可以在子节点中输入上面提示的命令以worker形式加入集群1docker swarm join --token SWMTKN-1-1zd********2oci43nbf1jjhlng8k********fhfzqw2-1ywv79qnvmlb*******h3gs35r 107.173.XXX.XXX:2377 子节点加入成功后可以在父节点中查看子节点信息1docker node ls 6.png 如果在Portainer增加manager节点，则会自动出现 Swarm 和 Service选项，如图 7.png 结语本次搭建过程就基本完成了，我们可以通过Portainer管理之前搭建的一系列环境，至此，一套简单的公司架构就完成了，生产环境也可以做到实时构建，只需要在Gogs上面发布版本就可以了，选择手动构建，构建时选择版本号即可，这样做的好处是如果正式环境有bug时可以随时回滚到稳定版本，当然，发布版本也是建立在测试完后的场景！","categories":[{"name":"架构","slug":"架构","permalink":"https://sbcoder.cn/categories/架构/"}],"tags":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/tags/优化/"},{"name":"版本控制","slug":"版本控制","permalink":"https://sbcoder.cn/tags/版本控制/"},{"name":"架构","slug":"架构","permalink":"https://sbcoder.cn/tags/架构/"}]},{"title":"公司代码架构 - Docker + Jenkins + Gogs + Portainer(三)","slug":"公司代码架构-Docker-Jenkins-Gogs-Portainer-三","date":"2019-12-11T11:09:38.000Z","updated":"2019-12-11T11:10:26.000Z","comments":true,"path":"2019/12/11/jenkins_docker.html","link":"","permalink":"https://sbcoder.cn/2019/12/11/jenkins_docker.html","excerpt":"","text":"配置Jenkins实现自动构建介绍前面已经搭建好了基本环境，剩下的就是自动构建了，这里就需要使用我们的构建工具Jenkins，Jenkins是一个非常牛逼的东西，它可以实现代码同步构建，当你修改你的代码并传到git时，Jenkins可以自动将你的代码同步到服务器上面，当然这只是Jenkins的基本功能之一，他还有非常多的东西值得我们学习~ 搭建环境 服务器2 ：Pacificrack 洛杉矶 RAM2G 2C 35GSSD（圣诞机器）18刀 操作系统 ：CentOS7.5 部署环境 ：LNMP1.6 （我是军哥铁粉） + Java8 服务器1：搭建Jenkins中转服务器，做代码自动构建使用服务器2：生产环境服务器，实则测试服务器，部署代码使用服务器3：Gogs服务器，Git版本库服务器，做代码版本控制使用 生产环境搭建服务器2的生产环境搭建。 生产环境，主要就是LNMP和Java8，LNMP是可选的，看需要部署的程序环境，例如需要部署node.js则只需要node.js环境即可，其他同理，我这边是准备自动部署PHP程序，因此就还是使用LNMP； Java8是必须的，Jenkins使用SSH连接到服务器时是需要源服务器有Java环境的 安装LNMPLNMP环境安装教程 : LNMP一键安装包 - 安装教程 安装Java8Jenkins连接节点的服务器必须安装！其他服务器无需安装！ 首先更新 yum 源1yum update 安装 jdk1.81yum install java-1.8.0-openjdk java-1.8.0-openjdk-devel 这里注意，是可以选择Java版本的，我这里使用了8所以按照8的方式安装的 可以搜索yum选择需要安装的版本1yum search java | grep jdk 一般 使用上面方法安装的Java配置文件都在 /etc/profile 编辑配置1vi /etc/profile 在末尾添加 环境变量，注意修改自己的版本号12345JAVA_HOME=/user/lib/jvm/java-1.8.0-openjdk-1.8.0.191.b12-1.el7_6.x86_64JRE_HOME=$JAVA_HOME/jreCLASS_PATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libPATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binexport JAVA_HOME JRE_HOME CLASS_PATH PATH 重置 profile1source /etc/profile 查看Java版本1java -version Jenkins配置安装必要的插件打开Jenkins登录后 打开 系统管理 - 插件管理 - 可选插件 搜索 安装 以下插件 汉化语言包(可选) Locale plugin Localization: Chinese (Simplified) Docker容器(可选) Docker Pipeline 远程连接(必须) SSH plugin SSH Slaves plugin Oracle Java SE Development Kit Installer Plugin Git服务(推荐) GitHub plugin Gogs plugin 推荐安装(可选) bouncycastle API Plugin Branch API Plugin Command Agent Launcher Plugin 插件属于按需配置，不适合自己的插件无需安装 增加节点增加节点必须要先在节点服务器配置Java环境，参照上面的配置Java8环境配置！如果没有配置Java环境则会报错！ 增加节点必须要有SSH插件，因此如果界面与我不一样请检查自己是否安装了上面的插件 打开Jenkins 系统管理 - 节点管理 - 新建节点 1.png 新建节点页面如下 2.png 如果没有设置过凭证则选择添加，界面如下 3.png 全部设置完点保存，他会自动启动代理节点 首页左下角会显示状态 4.png 或者在节点管理里面也可以看到 配置Gogs WebHook根据上一节我们配置好的Gogs，新建一个仓库，这里不多说，直接点加号就行，用过Github的都懂 可以选择公有仓库或者私有仓库，我这里都是私有仓库，也可以使用Gogs的迁移外部仓库功能直接迁移，迁移时可能会出现504错误，这是因为Nginx的反向代理时有超时设置，超过指定时间则直接504，我们在迁移仓库时经常会超时，因此建议修改一下默认超时时间，具体配置可以自行搜索，不多赘述。 找到需要自动构建的仓库，选择 仓库设置 - 管理 Web 钩子 - 添加Web钩子 6.png 注意：图中红框处的test需要跟后面配置的Jenkins对应，例如我创建的Jenkins任务名为 test 则此处填写test，修改域名为你的Jenkins域名，其他格式一致 注意：图中秘钥可随便填写，记录下来，配置Jenkins任务时会用到 配置Jenkins任务打开 Jenkins 新建任务，如果以前没有任务则首页会显示 创建一个新任务 5.png 配置Jenkins任务 7.png 描述部分可随便填写，这里主要配置一下 Gogs Webhook 勾选 Use Gogs secret，Secret填写上面创建Gogs WebHook时的秘钥 勾选 限制项目的运行节点 ，标签表达式填写你的节点名字，例如我这里的节点名字就是我的服务器ip地址，直接填写ip地址即可 8.png 源码管理选择Git，Repository URL选择需要自动构建的Git项目地址，http形式的，Credentials处为验证，如果是公共仓库则无需配置，如果是私有库则需要填写登录到 Gogs 的账户和密码，配置与之前的节点配置凭据一样，不多赘述 指定分支填写需要自动构建的分支，我这里填写的是dev分支，用来做开发版测试使用，根据自己情况来即可 配置上线Nginx配置由于我创建的节点 目录地址是 /home/wwwroot 在项目自动构建时，则会自动创建目录 /home/wwwroot/workspace/[JOB NAME]JOB NAME 为 任务名，例如我的 test 则自动创建目录 /home/wwwroot/workspace/test Nginx则只需要配置 域名解析即可 1lnmp vhost add 9.png 按图上配置即可，建议增加SSL证书，增加证书前记得先把域名解析到指定服务器IP上，否则会生成证书失败 记得给文件夹加上权限，755 构建返回Jenkins，点击立即构建，第一次构建时间可能会长一些，等待即可! 构建完成后则会在 配置的目录下创建workspace目录，并将代码放入 /home/wwwroot/workspace/test 目录中，根据自己的配置自行修改目录 由于我的程序涉及到跨目录访问，因此需要更改 fastcgi.conf 文件，与本文无关这里不多说~ 附一张成功截图，由于我这是前后端分离项目，因此没有界面~ 10.png 自动构建上面已经配置好了自动构建，我们每次合并代码或者提交代码变更到dev分支时，Gogs则会以Webhook的形式将内容推送到Jenkins上面去，实现每次更新代码自动构建服务器代码。 结语目前搭建好的架构，适合还在开发测试程序的开发小组，配合测试人员使用，也能让产品们在汇报工作进度的时候更得心应手，了解开发进度，当然也不是特别准确的开发进度，摸鱼还是要摸的。后面应该会写一下 Portainer + Swarm 管理Docker集群，慢慢写~","categories":[{"name":"架构","slug":"架构","permalink":"https://sbcoder.cn/categories/架构/"}],"tags":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/tags/优化/"},{"name":"版本控制","slug":"版本控制","permalink":"https://sbcoder.cn/tags/版本控制/"},{"name":"架构","slug":"架构","permalink":"https://sbcoder.cn/tags/架构/"}]},{"title":"公司代码架构 - Docker + Jenkins + Gogs + Portainer(二)","slug":"公司代码架构-Docker-Jenkins-Gogs-Portainer-二","date":"2019-12-10T11:05:36.000Z","updated":"2019-12-10T11:07:02.000Z","comments":true,"path":"2019/12/10/gogs_docker.html","link":"","permalink":"https://sbcoder.cn/2019/12/10/gogs_docker.html","excerpt":"","text":"安装 Gogs + Docker常用命令介绍本节主要写一下Jenkins的配置与自动构建过程，包括使用Gogs作为git服务器，配置自动构建等。本节需要配合上一节的内容使用，即 安装 Docker + Jenkins 的服务器一台 搭建环境 服务器3 ：TencentCloud 北京 RAM4G 2C 40GSSD（新用户机器）998RMB/3Year 操作系统 ：CentOS7.5 部署环境 ：LNMP1.6 （我是军哥铁粉） 服务器1：搭建Jenkins中转服务器，做代码自动构建使用服务器2：生产环境服务器，实则测试服务器，部署代码使用服务器3：Gogs服务器，Git版本库服务器，做代码版本控制使用 配置无需对标，都是低配置小鸡，唯一一个腾讯云 2C4G 的机器是我之前放其他业务的机器，由于git经常需要使用因此搭建在国内套CloudFlare使用，实则Gogs只需要 2C1G 机器即可，官方推荐配置是2C512M，是一个不吃内存的程序，目前腾讯云的 1C2G 只需要99/年，属于大众所承受的起的价格，由于我不是专职AFFMAN，因此不贴链接 CentOS7 安装 Docker1yum -y install docker 1.png 12start dockerenable docker 2.png 查看版本号，查看是否安装成功！1docker -v 3.png Docker 常用命令记录一下安装时可能会出现的问题，以及常用的Docker命令 查看当前运行的容器1docker ps 查看所有容器1docker ps -a 停止容器12docker stop [DOCKER NAME] # 例如：docker stop gogs 删除容器(必须在Stop之后才可以删除)12docker rm [DOCKER NAME] # 例如：docker rm gogs 进入容器1234docker attach [DOCKER NAME] # 例如： docker attach gogsdocker exec -it [DOCKER IMAGE ID] /bin/bash# 例如： docker exec -it ef5cb0692b57 /bin/bash 退出容器1exit 查看容器变动日志12docker diff [DOCKER NAME]# 例如：docker diff gogs 查看容器或者镜像详细信息12sudo docker inspect [IMAGE NAME]:0.1 # 例如： sudo docker inspect gogs 向容器内部发送指令12docker exec [DOCKER NAME] [COMMAND]# 例如 docker exec gogs ls 安装 Gogs安装下载镜像 Gogs1docker pull gogs/gogs 4.png 创建目录12mkdir -p /home/Gogscd /home/Gogs 5.png 开启Docker1234# 直接启动docker run --name=gogs -p 10022:22 -p 10080:3000 -v /home/Gogs:/data gogs/gogs# 后台启动docker run --name=gogs -d -p 10022:22 -p 10080:3000 -v /home/Gogs:/data gogs/gogs 配置正常启动后直接打开 http://ip:10080即可 如图： 6.png 接下来按照提示配置即可，我们这里使用SQLite3 应用配置需要注意一下 域名填写你的服务器公网IP SSH端口号填写 映射的端口号 10022 HTTP端口号填写 3000 应用URL填写 ip + 映射的端口号 10080 访问 7.png 配置完成后如果设置好管理员账户的会自动登录进去，如果没有设置的可以自行注册。 注意：数据库中第一个用户就是管理员账户 8.png Tips：Gogs的配置文件存放在 Docker中的 /data/gogs/conf/app.ini 如果想要更改可以 反向代理绑定域名同 公司代码架构 - Docker + Jenkins + Gogs + Portainer(一)一样，在应用配置阶段修改或者修改配置文件都可以 结语Gogs 是一个轻量级的 Git服务器，适用于一些小公司小团队使用，大公司使用Gitlab的情况可能更多一些，但是东西实际都是差不多的，为了占用资源更小一些，我这里还是选用了比较轻量级的Gogs","categories":[{"name":"架构","slug":"架构","permalink":"https://sbcoder.cn/categories/架构/"}],"tags":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/tags/优化/"},{"name":"版本控制","slug":"版本控制","permalink":"https://sbcoder.cn/tags/版本控制/"},{"name":"架构","slug":"架构","permalink":"https://sbcoder.cn/tags/架构/"}]},{"title":"公司代码架构 - Docker + Jenkins + Gogs + Portainer(一)","slug":"公司代码架构 - Docker + Jenkins + Gogs + Portainer(一)","date":"2019-12-09T11:47:26.000Z","updated":"2019-12-10T11:07:37.000Z","comments":true,"path":"2019/12/09/code_build.html","link":"","permalink":"https://sbcoder.cn/2019/12/09/code_build.html","excerpt":"","text":"公司代码架构 - Docker + Jenkins + Gogs + Portainer(一)介绍公司研发项目时，遇到git作为版本控制时，很常见的问题是部署比较麻烦（相比较麻烦），需要先克隆在拉到服务器部署，代码提交频率过高时，就会出现一天很多次提交代码，部署代码，浪费了大量的人力物力，于是乎大量的架构师技术总监们开始研究各类解决方案，各种上线前review代码，这是一件非常痛苦的事情，这里简单记录一下公司代码架构的部署，来解决公司代码架构上的诸多问题，也是自己做一个笔记，文章内如有错误，还请各位指出。 Tips：该环境并不适用于个人用户以及小微企业，适用于项目众多且开发人员大于30人的公司 搭建环境 服务器1 ：Virmach 水牛城 RAM1.8G 2C 10GSSD（黑五机器） 操作系统 ：Ubuntu16.04 部署环境 ：LNMP1.6 （我是军哥铁粉） 这里说明一下，多台服务器是为了解耦，说是解耦，实则认为承受不住，且大部分公司已经有一套完整的git服务器了，本节要做的就是加个自动构建而已，git服务器可自选环境，后面会讲如何搭建Gogs，如果有高配置服务器的公司或个人，可以尝试使用单服务器多部署，本文所需共三台服务器。 服务器1：搭建Jenkins中转服务器，做代码自动构建使用服务器2：生产环境服务器，实则测试服务器，部署代码使用服务器3：Gogs服务器，Git版本库服务器，做代码版本控制使用 服务器1的配置属于中下配置，该机型一年 13刀，属于大部分人都承受的起的价格，请注意，本文标注的配置仅用于配置自动构建服务器，并不用于部署代码以及Git服务，个人用户小鸡多的可以尝试 Ubuntu16.04/Ubuntu18.04 安装 DockerDocker可以说是非常的牛X了，关于他的概念不多说，牛就牛在管理太方便了，就好像是 WHMCS 用母鸡开小鸡一样，母鸡永远不考虑小鸡的运作，只需要配合就好，Docker也一样，我们只需要创建容器，管理容器就够了，剩下的交给Docker来处理，且Docker可以做负载均衡，后续做架构的时候可以开多个Docker做集群，按需来做 安装删除旧版本，更新apt-get，安装docker123sudo apt-get remove docker docker-engine docker-ce docker.iosudo apt-get updatesudo apt install docker.io 启动Docker并查看版本启动docker123systemctl start dockersystemctl enable dockerdocker --version 我这里安装的是 18.09版本 Docker1.png 安装Jenkins安装安装Jenkins可以选择多种方式安装，我这里采用的是Docker的方式安装的，由于我们上面已经安装过Docker，按照Jenkins官方给的安装方案就可以了，首先pull一个稳定版本的 Jenkins 镜像镜像地址 : jenkinsci/blueocean12docker pull jenkinsci/blueoceandocker images Docker2.png 查看当前Jenkins版本1docker inspect [IMAGE ID] 这里的 IMAGE ID 则是上面 查看镜像的 IMAGE ID Jenkins1.png 红框内则是 对应版本号 123456# 创建一个存放Jenkins Docker的目录mkdir /home/root/Jenkins# 启动一个Dockerdocker run -d --name jenkins -p 8081:8080 -v /home/jenkins:/home/jenkins jenkins/jenkins:lts# 查看jenkins服务docker ps | grep jenkins Jenkins2.png 打开 http://IP:8081 Jenkins3.png 输入命令进入 Docker内部123docker exec -it jenkins bash# 获取密码cat /var/jenkins_home/secrets/initialAdminPassword 重启Docker1docker restart [CONTAINER ID] [CONTAINER ID] 为当前Jenkins的版本号 例如 2.164.3 则输入 docker restart 2.164.3 Nginx反代Jenkins，绑定域名由于众所周知的水牛城服务器卡，国内环境必须搭配CloudFlare才可以使用，否则太卡了，因此安装LNMP环境，后续自动构建时也可以构建到这里 安装方法一： LNMP环境安装教程 : LNMP一键安装包 - 安装教程 懒得打开的话，可以直接输入1wget http://soft.vpser.net/lnmp/lnmp1.6.tar.gz -cO lnmp1.6.tar.gz &amp;&amp; tar zxf lnmp1.6.tar.gz &amp;&amp; cd lnmp1.6 &amp;&amp; ./install.sh lnmp 我这里安装的是 1.6稳定版，需要其他版本的可以自行修改版本号安装 安装方法二： apt-get安装，建议先更新apt-get1apt-get install nginx 打开NGINX配置文件目录，创建一个新的配置文件(这里是lnmp环境的配置文件地址，apt-get安装的nginx配置文件存放于 /etc/nginx/conf.d 中) 1vi /usr/local/nginx/conf/vhost/jenkins.conf 输入以下内容，请注意替换掉下面的 jenkins.0161.org1234567891011121314server &#123; listen 80; server_name jenkins.0161.org; client_max_body_size 60M; client_body_buffer_size 512k; location / &#123; proxy_pass http://localhost:8081; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;&#125; 重启lnmp使配置生效1lnmp reload 打开CloudFlare绑定域名，增加CDN支持，此处比较简单，不多赘述 结语一个完整的架构，需要很多的付出，并非一朝一夕，本文所属架构并不适用于所有公司或者个人，大型公司还需要K8s集群，承受多少并发取决于很多因素，任何架构都不能通杀所有类型的公司","categories":[{"name":"架构","slug":"架构","permalink":"https://sbcoder.cn/categories/架构/"}],"tags":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/tags/优化/"},{"name":"版本控制","slug":"版本控制","permalink":"https://sbcoder.cn/tags/版本控制/"},{"name":"架构","slug":"架构","permalink":"https://sbcoder.cn/tags/架构/"}]},{"title":"开发中常见的MySQL数据库优化细节","slug":"开发中常见的MySQL数据库优化细节","date":"2019-06-20T10:17:03.000Z","updated":"2019-12-09T11:51:26.000Z","comments":true,"path":"2019/06/20/mysql_optimize.html","link":"","permalink":"https://sbcoder.cn/2019/06/20/mysql_optimize.html","excerpt":"","text":"前言以我的习惯来讲，每开始一个新的项目都需要先把思路完善，紧接着就需要建立数据库，在码代码的时候，就一般不会在修改数据库的构造了，因此，数据库的结构通常关乎着查询的速度以及程序的完善程度，一个好的结构可以让你少写很多代码，也能让程序的运行速度更加快，通常在大公司都是由DBA来做这件事，但是事无绝对，作为一名合格的后端，掌握一些少量的数据库优化也是很需要的。 MySQL优化 - 数据类型及CURDPROCEDURE ANALYSE()PROCEDURE ANALYSE() [prəˈsējər ˈænəlaɪz]是一个MySQL自带的给我们提供数据库优化建议的函数，他可以直接运行在MySQL中，直接在执行语句中加上这个函数即可1SELECT * FROM `list` WHERE 1 PROCEDURE ANALYSE ( ) 这段SQL执行过后，将会把list表中的数据分析一遍，并把他的分析结果展示出来 Field_nameMin_valueMax_valueMin_lengthMax_lengthEmpties_or_zerosNullsAvg_value_oravg_lengthstdOptimal_fieldtype 他将会把分析出来的 字段名 最短值 最大值 以及最后一列就是MySQL给出的分析结果，我们可以在有一定数据的时候使用这个函数来分析，这样给出的结果会更精确一些，只需要查看最后一列Optimal_fieldtype的值即可，这个函数并不适用于数据库设计阶段，它适用于后期使用 EXPLAINEXPLAIN是一个非常好用的MySQL语法，在我们功能测试阶段，如果发现某页面非常慢，排除静态资源问题后就可以试试使用EXPLAIN，我们可以在执行语句前面加上 EXPLAIN 来获得执行过程，通过该结果我们可以看到SQL如何改变会减少查询时间和次数。1EXPLAIN SELECT * FROM `list` WHERE 1 这段SQL执行后，将会返回如下格式的分析结果 idselect_typetabletypepossible_keyskeykey_lenrefrowsExtra 我们主要看rows就行，为了得到想要的结果，rows的值越小越好，使用EXPLAIN来调试简直是再好不过了！ ENUM(枚举)类型很多程序员往往喜欢统一一个数据类型，比如说 ‘varchar’ ，这可能是我见过最多的数据类型了，早些时期，的确是有很多的公司或者程序都是大面积使用，随着MySQL的革新换代，很多的类型都可以避免使用它。我在很多得程序上测试过（有数据）PROCEDURE ANALYSE()方法，他给出了很多 ‘varchar’ 替换为 ‘enum’ 的建议，这说明，enum类型的确是一个应该被重视的数据类型，但由于他是一个枚举类型，我们在定义数据类型的时候并不适合直接上手定义，所以很多时候都是在有一定的数据量的时候才想要换数据类型的。可以理解为枚举即时索引，枚举就相当于给这个字段的可能值都加上了一个索引，与我们为了优化查询加索引是一样的概念。enum更适用于选项卡类字段，例如性别，订单状态等，如果您字段中只有几个重复的值也是非常推荐使用的。 JOIN链接查询，这是我们在开发中非常常用的查询方式，首先要知道，我们在学校里学习的大多数是 AND 链接多表查询，虽然能够将结果无误的查询出来，但是速度就影响的非常多了，这里还是推荐大家使用JOIN来连接查询有些同学可能不太理解JOIN，简单说一下JOIN的内连接和外链接，左外链接和右外链接吧 内连接即是A B两表链接，只取两表共有的数据，假设 B 中 有的数据 A 表内没有对应的数据则无法查询到 1SELECT * FROM list1 INNER JOIN list2 on list1.id = list2.id 外连接（FULL JOIN 也称作全连接）即是A B两表链接，取两表所有的数据，即使 B 表中的某些数据无法匹配链接条件时，也正常链接 1SELECT * FROM list1 FULL JOIN list2 on list1.id = list2.id 左外连接，即是 A B两表链接，取两表所有数据，若A表中有B表不匹配的数据，同样展示出来，B表如果有A不匹配的数据，则不展示 1SELECT * FROM list1 LEFT OUTER JOIN list2 on list1.id = list2.id 右外连接，即是 A B两表链接，取两表所有数据，若B表中有A表不匹配的数据，同样展示出来，A表如果有B不匹配的数据，则不展示，与左外连接相反 VvmQFU.png MySQL优化 - 结构FULLTEXT INDEXFULLTEXT INDEX(全文索引)，更适用于文章内容搜索的索引，我们在作搜索功能的时候，很多人喜欢将文章内容(content)建立普通索引，但是实际上，这种做法并不会增加查询速度，通常我们做搜索的时候，执行下列语句。 1SELECT content FROM `list` WHERE content LIKE '%风向标%' 如果搜索功能权重比较高的网站，就需要将content这个字段建立索引。 1ALTER TABLE `list` ADD FULLTEXT (`content`) 如果是phpmyadmin用户，在phpmyadmin中直接点击’全文搜索’即可。 MyISAM OR InnoDB？就我现阶段写出来的东西来看（数据量小，查询次数少，用户量较少），MyISAM肯定是最适合我的，它更适用于小型网站，以及事务处理较少的网站InnoDB则与之相反，如果你的业务比较复杂，针对数据库的操作较多的时候，InnoDB就会更适合一些。使用INSERT插入数据时 MyISAM 就比 InnoDB 更快一些，而 UPDATE 时 InnoDB 就会比 MyISAM 快一些 如果您是轻度SQL用户，重功能不重视业务的项目，那么我个人以为 MyISAM 更适合一些如果您感觉业务逻辑复杂，经常使用SQL，那么可以尝试使用 InnoDB 最后也是见仁见智，没有好坏，如果您希望测试，也是可以通过直接修改数据库引擎来测试速度的 MySQL优化 - 小知识点 不要使用 SELECT * 查询 不要使用 NULL 频繁查询的字段建立索引 索引过多时会影响 UPDATE 和 INSERT 的执行速度 避免在 WHERE 时使用 != &lt;&gt; 等操作符，MySQL会自动放弃索引，直接全表扫描 避免使用 IN 和 NOT IN，尽量使用BETWEEN，MySQL会自动放弃索引，直接全表扫描 可以使用 EXISTS 来代替 IN 使用 某些情况下可以使用强制使用索引查询 SELECT * FROM list with(index(索引名)) WHERE …. 避免使用 OR 作为调件，可以使用 UNION 并集查询将两次查询结果合并 尽可能将表内容长度固定 查询时如果只查询一条信息，就使用 LIMIT 1 避免使用比较表达式 如 10000+1 = id 可以使用 id = 10000+1 记得将查询链接即时关闭掉 使用变量来给MySQL开启查询缓存，避免使用MySQL内置变量函数 设置的主键尽量使用长度短且最好是int类型 垂直分割，将大量的字段的表优化成多个少字段的表 INSERT 和 DELETE 是一个可以锁定数据表的SQL语句，必须等待执行完毕后才会解除锁定，如果这条语句执行起来过于缓慢，请谨慎使用 Object Relational Mapper Prepared Statements 参考: Top 20+ MySQL Best Practices参考: 廖雪峰的个人网站 - 链接查询","categories":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/categories/优化/"}],"tags":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/tags/优化/"},{"name":"MySQL","slug":"MySQL","permalink":"https://sbcoder.cn/tags/MySQL/"}]},{"title":"mm131全栈多线程爬虫","slug":"mm131全栈多线程爬虫","date":"2019-06-19T14:34:31.000Z","updated":"2019-06-19T14:56:33.000Z","comments":true,"path":"2019/06/19/mm131_spider.html","link":"","permalink":"https://sbcoder.cn/2019/06/19/mm131_spider.html","excerpt":"","text":"起因LOC的大佬们最近开始疯狂的爬取mm131，作为一个Python初心者，作为技术上的学习，也要与时俱进，简单写了一个图片下载爬虫，看到大佬们似乎是做了一个typechoo的对接接口，我这边回头有空也搞一个wordpress的接口（只在博客内发布），之前写过一个新浪远程上传的接口，由于种种原因，新浪已经不支持外链了，因此这个wordpress接口可能就有时间再做了，不然做出来也是个摆设，没地方放。 代码解析网址不发了，直接讲，或者大家直接百度谷歌都可以搜得到。打开网站,总共有如下六个分类 mm131.jpg 每个分类下面都有一堆的图集，有N个分页的图集，但是第一页跟第二页的地址还不太一样，这点跟192tt做的很相似，感觉这几个站长是不是都是用的同一套程序，如果是的话可以通杀了。。。首先遍历图集的地址，到目前更新文章截止，一共大概5000多套按分类给他搞一个分类循环 1234list = &#123;'xinggan':6,'qingchun':1,'xiaohua':2,'chemo':3,'qipao':4,'mingxing':5&#125; # list = &#123;'mingxing':5&#125; for key in list: getPageUrl(key,list[key]) 解析图片url，用正则获取就行，用bs4取到末页的地址，然后遍历循环取图集地址 1234567try: i.find('img').get('src')except Exception as e: for s in i.find_all('a'): endPage = s.get('href') endPage = rex('list_%s_(\\d+).html'%num,endPage) continue 获取图集地址12345678910nextUrl = \"%s/list_%s_%s.html\"%(url,num,i+2)response = requests.get(nextUrl, headers=headers)response.encoding = 'gb2312'soup = BeautifulSoup(response.text, 'html.parser')for i in soup.find('dl', &#123;'class': 'public-box'&#125;).find_all('dd'): try: i.find('img').get('src') except Exception as e: continue print(i.find('a').get('href')) 需要注意的是，mm131的图片是有防盗链的，根据referer判断，随便找一个图集的地址设置上即可1234headers = &#123; \"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36\", 'referer': \"http://www.mm131.com/xinggan/4995.html\",&#125; 线程池应用之前的爬虫除了Scrapy搞出来的之外都是单线程的爬虫，优点是比较稳定，但是缺点也很明显，太慢了，mm131这个站的图大都比较小，如果是一张一张下载确实是不太划算，于是搞了个线程池。Python的线程池很简单，只需要引入 threadpool 即可，如果报错，请 pip install threadpool,12345678910# 引入threadpoolimport threadpool# 创建线程池，设置为12线程，可以根据自身情况修改pool = threadpool.ThreadPool(12)# 创建callback函数，参数1 getSingleData 是需要调用的函数名，list是函数getSingleData的参数，该方法适用于单个参数的函数，list是一个一维数组或对象pageTask = threadpool.makeRequests(getSingleData, list)# 执行线程池[pool.putRequest(req) for req in pageTask]# 等待完成后退出pool.wait() 演示和下载演示图 多线程演示.jpg 下载结果.jpg 下载演示代码不全，直接上地址https://github.com/ai0by/ai0by-spider/tree/master/mm131","categories":[{"name":"Python","slug":"Python","permalink":"https://sbcoder.cn/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://sbcoder.cn/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://sbcoder.cn/tags/爬虫/"},{"name":"福利","slug":"福利","permalink":"https://sbcoder.cn/tags/福利/"}]},{"title":"Redis/Redis集群以及在Laravel中的使用方法","slug":"Redis-Redis集群以及在Laravel中的使用方法","date":"2019-06-17T13:19:37.000Z","updated":"2019-06-17T13:21:08.000Z","comments":true,"path":"2019/06/17/Redis_laravel_PHP.html","link":"","permalink":"https://sbcoder.cn/2019/06/17/Redis_laravel_PHP.html","excerpt":"","text":"Redis的数据类型Redis也算是一种数据的容器，承载在内存上，因此它的各方面性能都比较快，且作为非关系型数据库，面对各种索引也比普通的数据库查询快，不同的场景下使用不同的数据类型，适用于很多地方 字符串类型 String一一对应，使用场景比较多 key:value 形式 命令 描述 set key value 设置指定key值 get key 获取指定key的value值 mget key1 key2 获取多个key 的 value，按顺序返回value值 mset key1 ‘value1’ key2 ‘value2’ 批量设置多个key的value strlen key 返回对应value长度 getrange key start end 截取字符串 append key value 追加key关联的value值，返回长度 getset key value 设置key的value并返回原value值 setex key time value 设置value值，并加上一个过期时间，使用ttl key查看过期时间，秒为单位 setnx key value 当key不存在时，设置value msetnx key1 ‘value1’ key2 ‘value2’ 当所有的key都不存在时，批量设置多个key的value incr key 将key关联value的值加一，仅对数字有效 incrby key num 将key关联value的值加num，例如 10，仅对数字有效 incrbyflout key num 将key关联value的值加num，浮点类型 decr key 将key关联value的值减一，仅对数字有效 decrby key num 将key关联value的值减num，例如 10，仅对数字有效 哈希类型 Hash一对一对多，类似字符串，但又区别于字符串，它比字符串复杂一些，同样是key:value，但是他的value可以是一个map，同时，它也无法给单个属性赋予过期时间，但可以给单个属性设置值，某些情况下比String占用资源少，当需要缓存整张表时推荐使用 命令 描述 hset key field value 设置key关联的value hkeys key 获取所有的key hgetall key 获取key的所有对应field hvals key 获取hash表中所有的value hlen key 获取keyd的长度 hmget key field1 field2 获取多个field的值 hmset key field1 value1 field2 value2 设置多个field的值 hdel key field 删除单个field的单个属性 hsetnx key field value 当field不存在时存储数值 hincrby key field num 给指定字段增加数值，整数 hincrbyfloat key field num 给指定字段增加浮点数 列表类型 List类似栈，拥有栈的特性，也有链表的特性，亦可用作消息队列等场景，使用场景很广 命令 描述 lpush key value1 value2 将多个value插入到关联的key里面 头部 lpushx key value 将value插入到key中，需要key已经存在 头部 lpop key 删除并获取当前key里面的第一个元素 llen key 获取当前key关联的list长度 rpush key value1 value2 将多个value插入到关联的key里面 尾部 rpop key 删除并获取列表内的最后一个元素 rpushx key value 将value插入到key中，需要key已经存在 尾部 blpop key1 key2 timeout 删除并获取列表的第一个元素，key1存在时不执行key2，如果没有会一直阻塞到弹出为止，建议添加延时 brpop key1 key2 timeout 删除并获取列表的最后一个元素，key1存在时不执行key2，如果没有会一直阻塞到弹出为止，建议添加延时 lindex key 通过索引来获取list中的元素 lset key index value 通过索引来设置相应元素的值 lrange key start end 截取指定列表内元素 ltrim key start end 只保留开始和结束内的元素 集合 set数据池，无序，可计算差集交集等，之前写爬虫时用集合做过去重，Python使用redis也是非常方便的 命令 描述 sadd key member1 member2 向集合内添加元素 scard key 获取集合内元素数量 smembers key 获取集合内所有的元素 sismember key member 判断member是否是key集合的子元素 sdiff key1 key2 获取给定集合的差集 sinter key1 key2 获取给定集合的交集 sunion key1 key2 获取给定集合的并集 spop key 随机删除一个集合内元素并返回 srandmember key num 返回集合内的一个或者多个随机元素 srem key member1 member2 删除集合中一个或者多个指定元素 其他剩下的数据类型确实是没用过，这里不便多说 Laravel使用redis流程简单来说如下图所示 Laravel使用redis 程序将数据存储请求发送给Laravel内置的redis模块（PHPRedis，Predis等），并在config/database.php中配置好redis的端口密码等信息，通过内置模块调用已经安装好的redis即可使用redis存储使用数据了，然后redis内部处理数据我们如果不做底层的话，正常存储使用，只需要处理好程序与Laravel之间的过程就可以了，也就是说，了解PHPRedis和Predis就可以了，目前似乎大多数人使用的都是这两种，也不仅限于Laravel，原生PHP以及像Swoole这种的也是可以使用的。 关于Laravel中的Redis配置使用 可以参考 Laravel中文文档5.8 - redis 1234567// laravel 简单调用示例use Illuminate\\Support\\Facades\\Redis;class testRedis()&#123; Redis::set('username','风向标'); $username = Redis::get('username'); return $username;&#125; Laravel使用Redis集群仍然是在 config/database 中配置 clusters123456789101112131415161718192021222324252627282930313233'redis' =&gt; [ 'client' =&gt; env('REDIS_CLIENT', 'predis'), 'options' =&gt; [ 'cluster' =&gt; env('REDIS_CLUSTER', 'predis'), // 'cluster' =&gt; env('redis'), ], 'clusters' =&gt; [ 'vaneCache' =&gt; [ [ 'host' =&gt; env('REDIS_HOST', '127.0.0.1'), 'password' =&gt; env('REDIS_PASSWORD', null), 'port' =&gt; env('REDIS_PORT', 6379), 'database' =&gt; 1, ], [ 'host' =&gt; env('REDIS_HOST', '127.0.0.1'), 'password' =&gt; env('REDIS_PASSWORD', null), 'port' =&gt; env('REDIS_PORT', 6379), 'database' =&gt; 2, ], [ 'host' =&gt; env('REDIS_HOST', '127.0.0.1'), 'password' =&gt; env('REDIS_PASSWORD', null), 'port' =&gt; env('REDIS_PORT', 6379), 'database' =&gt; 3, ], ], ], ], 在使用时仅需要 使用 connection 即可 1234$redis1 = Redis::connection('vaneCache');$redis1-&gt;set('username','风向标');$username = $redis1-&gt;get('username');echo $username;","categories":[{"name":"PHP","slug":"PHP","permalink":"https://sbcoder.cn/categories/PHP/"}],"tags":[{"name":"优化","slug":"优化","permalink":"https://sbcoder.cn/tags/优化/"},{"name":"PHP","slug":"PHP","permalink":"https://sbcoder.cn/tags/PHP/"},{"name":"Laravel","slug":"Laravel","permalink":"https://sbcoder.cn/tags/Laravel/"},{"name":"Redis","slug":"Redis","permalink":"https://sbcoder.cn/tags/Redis/"}]},{"title":"tuwan（兔玩）全站妹子图爬虫可多窗口","slug":"tuwan全站妹子图爬虫可多窗口","date":"2019-05-13T15:01:00.000Z","updated":"2019-05-13T15:29:23.000Z","comments":true,"path":"2019/05/13/tuwan_spider.html","link":"","permalink":"https://sbcoder.cn/2019/05/13/tuwan_spider.html","excerpt":"","text":"前言兔玩是一个非常不错的妹子图网站，跟曾经的PR社有异曲同工之处，花少量的钱可以看Coser的图片，但是tuwan的妹子还是很正经的哟~兔玩官网 tuwanjun.com以下是网站截图 tuwan 兔玩的更新速度还是不错的呢~ 破解看到官网的套图打开后，一般是有几张可以看得图，也有一堆尺寸小的预览图，地址很相似，例如这张1http://img4.tuwandata.com/v3/thumb/jpg/YjAzYiwxNTgsMTU4LDksMywxLC0xLE5PTkUsLCw5MA==/u/GLDM9lMIBglnFv7YKftLBuvzpwYbEIoBh8ap84BsgXdniTdx80UqsXLdP5yaJZklUj09PvGO8IYpAC3nOanE0EHpB9bCnRKUnvdbAJH6CcXC.jpg YjAzYiwxNTgsMTU4LDksMywxLC0xLE5PTkUsLCw5MA==这一串很容易看的出是base64加密过的串，经过解密获得12base64.b64decode(imgurl)# b03b,158,158,9,3,1,-1,NONE,,,90 这里的158,158就是缩略图的尺寸了，我们尝试修改缩略图尺寸然后在base64加密后就可以取得地址，经过尝试，修改为 0，0即可还原原图尺寸~12base64.b64encode(base64.b64decode(imgurl.encode('utf-8')).replace('158','0'))# YjAzYiwwLDAsOSwzLDEsLTEsTk9ORSwsLDkw 组合成原图地址：1http://img4.tuwandata.com/v3/thumb/jpg/YjAzYiwwLDAsOSwzLDEsLTEsTk9ORSwsLDkw/u/GLDM9lMIBglnFv7YKftLBuvzpwYbEIoBh8ap84BsgXdniTdx80UqsXLdP5yaJZklUj09PvGO8IYpAC3nOanE0EHpB9bCnRKUnvdbAJH6CcXC.jpg 下载源代码已经开源到Github上了上一张测试图 测试图 下载地址：tuwan_spider","categories":[{"name":"Python","slug":"Python","permalink":"https://sbcoder.cn/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://sbcoder.cn/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://sbcoder.cn/tags/爬虫/"},{"name":"福利","slug":"福利","permalink":"https://sbcoder.cn/tags/福利/"}]},{"title":"Discuz会员数据与Wordpress互通","slug":"Discuz会员数据与Wordpress互通","date":"2019-04-11T12:06:06.000Z","updated":"2019-05-13T14:57:58.000Z","comments":true,"path":"2019/04/11/Discuz-Userinfo-To-Wordpress.html","link":"","permalink":"https://sbcoder.cn/2019/04/11/Discuz-Userinfo-To-Wordpress.html","excerpt":"","text":"情景这个情景可能遇到的也不在少数，不想舍弃用户数据，还想让用户无需注册在新站保留账号。实际当我们在迁移的时候，稍微了解数据库的同学应该明白想要迁移用户数据只需要迁移用户数据表即可。实际上我也是这么做的，但是中途遇到了几个小问题，这里我总结一下！ Discuz用户密码加密算法Discuz的用户信息都存放在 ‘pre_common_member‘ 表里，包含了我们需要转移的 邮箱,用户名,密码,积分,ip 等各类信息那么很简单了，便利这个表再插入到Wordpress表内即可但在导入表之前需要先测试一下用户数据是否匹配以示严谨~当我测试密码匹配的时候发现，这里的密码似乎并不匹配，首先我想到的就是应该是加盐了，但是纵观整个 ‘pre_common_member‘ 表，似乎并没有该有的字段网上找了一圈发现Discuz的用户真实密码是存在 ‘pre_ucenter_members‘ 表内的，’pre_common_member‘ 表内的密码我现在还不知道有什么用处，但至少跟我们需要迁移的数据没什么关联。从 ‘pre_ucenter_members‘ 表中找到了我们需要的 ‘salt‘ 字段，经过测试得出Discuz的密码加密算法为1md5(md5('password').'salt'); tips: Discuz里面的salt是一个6位的 数字+字母 随机数 Wordpress用户密码加密算法搞定了DZ的加密算法后，那么如何将DZ的用户信息插入到WP里面就很重要了，打开 Wordpress 的数据库找到 ‘wp-user‘表，找到 ‘user_pass‘ 字段，发现里面加密的内容似乎无迹可寻。实际上，Wordpress的加密是使用了 phpass 类来加密的，由 phpass 加密的密码具有不可逆性，所以想要破解是不可能了，这里简单说一下 phpass 的加密算法目前我们的PHP版本应该都在5以上，所以前缀是一样的 $P$B 大致写出来如下：12345$count = rand(1,8);$hash = md5($salt . $password, TRUE);while($count--)&#123; $hash = md5($hash . $password, TRUE);&#125; 看起来是不是很强，我们无法破解这样的密码，实际使用中，我们也可以使用 phpass 来做密码加密，让我们的数据库更加的安全~然而我们数据迁移时其实完全可以避免这种问题，Wordpress是保留了md5加密的形式的，如果 ‘user_pass‘ 字段里面存储的是md5加密的32值，wordpress也可以登录成功，并且再登陆后会将 ‘user_pass‘ 字段修改为 phpass 加密的格式，是不是很人性化呢。综上所述，我们无需解出来wordpress的加密算法，我们也解不出来~ 开始迁移用户数据关于迁移有很多细节，本来是打算写出来的，后来发现没什么技术含量，都是流水账，直接开源到github好了需要的朋友请直接点击 D2W - Github","categories":[{"name":"PHP","slug":"PHP","permalink":"https://sbcoder.cn/categories/PHP/"}],"tags":[{"name":"Discuz","slug":"Discuz","permalink":"https://sbcoder.cn/tags/Discuz/"},{"name":"Wordpress","slug":"Wordpress","permalink":"https://sbcoder.cn/tags/Wordpress/"}]},{"title":"192TT(192tb)套图吧整站爬虫","slug":"192TT-192tb-套图吧整站爬虫","date":"2019-03-28T08:15:16.000Z","updated":"2020-05-17T05:22:15.811Z","comments":true,"path":"2019/03/28/192tt_Spider.html","link":"","permalink":"https://sbcoder.cn/2019/03/28/192tt_Spider.html","excerpt":"","text":"观察目录结构目标网站：192tb.com网站结构复杂，但也不是太复杂，总体来说都写在导航栏上面了，本以为是new分类下就是所有的文章了，后来发现不是，需要遍历整个导航分类，由于每个分类都有很庞大的资源，因此我决定写成配置文件的形式，建立config.py 1234567891011121314# -*- coding: utf-8 -*-mt = 'https://www.192tb.com/listinfo-1-1.html' # 美图mt1 = 'https://www.192tb.com/meitu/xingganmeinv/' # 性感美女mt2 = 'https://www.192tb.com/meitu/siwameitui/' # 丝袜美腿mt3 = 'https://www.192tb.com/meitu/weimeixiezhen/' # 唯美写真mt4 = 'https://www.192tb.com/meitu/wangluomeinv/' # 网络美女mt5 = 'https://www.192tb.com/meitu/gaoqingmeinv/' # 高清美女mt6 = 'https://www.192tb.com/meitu/motemeinv/' # 模特美女mt7 = 'https://www.192tb.com/meitu/tiyumeinv/' # 体育美女mt8 = 'https://www.192tb.com/meitu/dongmanmeinv/' # 动漫美女mt9 = 'https://www.192tb.com/new/ugirlapp/' # 爱尤物APP/尤果网gc = 'https://www.192tb.com/gc/' # 国产gc1 = 'https://www.192tb.com/gc/bl/' # beautyleg1 顶级分类和二级分类不便多说，这里只是测试并没有收录所有的分类，有兴趣可以自己添加 进入分类页后既是套图封面，从这里可以爬取套图的链接，分类页的底部也是有下一页的选项，可以根据下一页来获取下一个分类页的链接，以此递归，并获取链接 获取到套图链接后发现每个单页面都是需要点击下一张图片来做的，单页面中的图片，使用BeautifulSoup即可轻松获取，由于不知道一套图里面有多少张，我这边使用递归的方式，走到最后一张，即退出递归。 核心代码获取单个套图并下载1234567891011121314151617def getSingleData(url,singleTitle,i = 1): response = requests.get(url) soup = BeautifulSoup(response.text,\"html.parser\") imgUrl = soup.find(id = 'p').find('center').find('img').get('lazysrc') print imgUrl try: j = i + 1 result = '_%s.html'%i in url if result: nextImg = response.url.replace('_%s.html'%i, '_%s.html'%j) else: nextImg = response.url.replace('.html', '_%s.html'%j) # print nextImg downImg(imgUrl,singleTitle,i) getSingleData(nextImg,j) except Exception,e: return 0 获取下一页页面信息123456789101112131415161718192021222324def getPage(url,new = 1,i = 1): print '开始采集第%s页'%i print url response = requests.get(url) soup = BeautifulSoup(response.text,\"html.parser\") for dataUrl in soup.find('div',&#123;'class':'piclist'&#125;).find('ul').find_all('li'): singleDataUrl = 'https://www.192tb.com/'+dataUrl.find('a').get('href') print singleDataUrl try: singleTitle = dataUrl.find('a').find('img').get('alt') except Exception,e: continue print singleTitle getSingleData(singleDataUrl,singleTitle) result = '_%s.html' % i in url j = i + 1 if new != 1: nextPageUrl = url.replace('listinfo-1-%s.html' % i, 'listinfo-1-%s.html' % j) else: if result: nextPageUrl = url.replace('index_%s.html' % i, 'index_%s.html' % j) else: nextPageUrl = url.replace(url, url+'/index_%s.html' % j) getPage(nextPageUrl,new,j) 演示及下载下载地址：Github 192tt演示图","categories":[{"name":"Python","slug":"Python","permalink":"https://sbcoder.cn/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://sbcoder.cn/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://sbcoder.cn/tags/爬虫/"},{"name":"福利","slug":"福利","permalink":"https://sbcoder.cn/tags/福利/"}]},{"title":"正则表达式应用，常用取值表（记录）","slug":"正则表达式应用，常用取值表（记录）","date":"2019-03-26T08:11:06.000Z","updated":"2019-03-27T03:50:12.000Z","comments":true,"path":"2019/03/26/Regex_match_note.html","link":"","permalink":"https://sbcoder.cn/2019/03/26/Regex_match_note.html","excerpt":"","text":"正则表达式 查询表 字符 描述 场景 \\ 转义 转义场景 \\ ^ 匹配输入字符串的开始位置。如果设置了 RegExp 对象的 Multiline 属性，^ 也匹配 ‘\\n’ 或 ‘\\r’ 之后的位置。 取a开头的字符串 ^a.* $ 匹配输入字符串的结束位置。如果设置了RegExp 对象的 Multiline 属性，$ 也匹配 ‘\\n’ 或 ‘\\r’ 之前的位置。 取a开头b结尾 ^a.*b$ * 匹配前面的子表达式零次或多次。 zo 能匹配 “z” 以及 “zoo”。 等价于{0,} + 匹配前面的子表达式一次或多次。 ‘zo+’ 能匹配 “zo” 以及 “zoo”，但不能匹配 “z”。+ 等价于 {1,} ? 匹配前面的子表达式零次或一次. “do(es)?” 可以匹配 “do” 或 “does” 中的”do” 。? 等价于 {0,1}。 {n} n 是一个非负整数。匹配确定的 n 次。 ‘o{2}’ 不能匹配 “Bob” 中的 ‘o’，但是能匹配 “food” 中的两个 o。 {n,} n 是一个非负整数。至少匹配n 次。 ‘o{2,}’ 不能匹配 “Bob” 中的 ‘o’，但能匹配 “foooood” 中的所有 o。’o{1,}’ 等价于 ‘o+’。’o{0,}’ 则等价于 ‘o*’ {n,m} m 和 n 均为非负整数，其中n &lt;= m。最少匹配 n 次且最多匹配 m 次。 “o{1,3}” 将匹配 “fooooood” 中的前三个 o。’o{0,1}’ 等价于 ‘o?’。请注意在逗号和两个数之间不能有空格。 ? 当 该字符紧跟在任何一个其他限制符 (*, +, ?, {n}, {n,}, {n,m}) 后面时，匹配模式是非贪婪的。 非贪婪模式尽可能少的匹配所搜索的字符串，而默认的贪婪模式则尽可能多的匹配所搜索的字符串。对于字符串 “oooo”，’o+?’ 将匹配单个 “o”，而 ‘o+’ 将匹配所有 ‘o’。 . 匹配除 “\\n” 之外的任何单个字符。 要匹配包括 ‘\\n’ 在内的任何字符，请使用象 ‘[.\\n]’ 的模式。 x&#124;y 匹配 x 或 y。 ‘z&#124;food’ 能匹配 “z” 或 “food”。’(z&#124;f)ood’ 则匹配 “zood” 或 “food”。 [xyz] 字符集合。匹配所包含的任意一个字符。 ‘[abc]’可以匹配 “plain” 中的 ‘a’。 [^xyz] 取反，匹配未包含的任意字符。 ‘?[^abc]’ 可以匹配 “plain” 中的’p’。 [a-z] 字符范围。匹配指定范围内的任意字符。 ‘[a-z]’ 可以匹配 ‘a’ 到 ‘z’ 范围内的任意小写字母字符。 \\b 匹配一个单词边界，也就是指单词和空格间的位置。 ‘er\\b’ 可以匹配”never” 中的 ‘er’，但不能匹配 “verb” 中的 ‘er’。 \\B 匹配非单词边界 ‘er\\B’ 能匹配 “verb” 中的 ‘er’，但不能匹配 “never” 中的 ‘er’。 \\cx 匹配由 x 指明的控制字符。 \\cM 匹配一个 Control-M 或回车符。x 的值必须为 A-Z 或 a-z 之一。否则，将 c 视为一个原义的 ‘c’ 字符。 \\d 匹配一个数字字符 等价于 [0-9]。 \\D 匹配一个非数字字符。 等价于 [^0-9]。 \\f 匹配一个换页符。 等价于 \\x0c 和 \\cL。 \\n 匹配一个换行符。 等价于 \\x0a 和 \\cJ。 \\r 匹配一个回车符。 等价于 \\x0d 和 \\cM。 \\s 匹配任何空白字符，包括空格、制表符、换页符等等。 等价于 [ \\f\\n\\r\\t\\v]。 \\S 匹配任何非空白字符。 等价于 [^ \\f\\n\\r\\t\\v]。 \\t 匹配一个制表符。 等价于 \\x09 和 \\cI。 \\v 匹配一个垂直制表符。 等价于 \\x0b 和 \\cK。 \\w 匹配包括下划线的任何单词字符。 等价于’[A-Za-z0-9_]’。 \\W 匹配任何非单词字符。 等价于 ‘[^A-Za-z0-9_]’。 \\xn 匹配十六进制数 ‘\\x41’ 匹配 “A”。’\\x041’ 则等价于 ‘\\x04’ &amp; “1”。正则表达式中可以使用 ASCII 编码。. \\num 匹配 一个正整数。对所获取的匹配的引用。 ‘(.)\\1’ 匹配两个连续的相同字符。 \\n 标识一个八进制转义值或一个向后引用。 如果 \\n 之前至少 n 个获取的子表达式，则 n 为向后引用。否则，如果 n 为八进制数字 (0-7)，则 n 为一个八进制转义值。 \\nm 标 识一个八进制转义值或一个向后引用。 如果 \\nm 之前至少有 nm 个获得子表达式，则 nm 为向后引用。如果 \\nm 之前至少有 n 个获取，则 n 为一个后跟文字 m 的向后引用。如果前面的条件都不满足，若 n 和 m 均为八进制数字 (0-7)，则 \\nm 将匹配八进制转义值 nm。 \\nml 匹配八进制数 如果 n 为八进制数字 (0-3)，且 m 和 l 均为八进制数字 (0-7)，则匹配八进制转义值 nml。 \\un 匹配 n，其中 n 是一个用四个十六进制数字表示的 Unicode 字符。 \\u00A9 匹配版权符号 。 常用案例演示123# -*- coding:utf-8 -*-import restr1 = 'ai0by123' 提取a开头的字符串1regexStr = \"^a.*\" 提取a开头b结尾字符串1regexStr = \"^a.*3$\" 提取最右边符合条件的值,贪婪1regexStr = \".*(a.*b).*\" # 贪婪，取a到b之间，右边开始取，取最右边符合条件的 提取最左边符合条件的值，非贪婪1regexStr = \".*?(a.*?b).*\" # 非贪婪，取a到b之间的值含a和b，从左往右只取一次 提取符合集合内的值，或运算1regexStr = \"((ai00000by|ai0by)123)\" # 或运算，符合其中一种即可 提取出生日期123456str1 = 'XXX 出生于2008年12月6日'str1 = 'XXX 出生于2008/12/6'str1 = 'XXX 出生于2008-12-6'str1 = 'XXX 出生于2008-12-06'str1 = 'XXX 出生于2008-12'regexStr = \".*出生于(\\d&#123;4&#125;[年/-]\\d&#123;1,2&#125;([月/-]\\d&#123;1,2&#125;|[月/-]$|$))\" 提取图片url,其他网站同理1234567str1 = '地址：https://www.ttbcdn.com/d/file/p/2018-02-17/g4edlvxmmyi9627.jpg'# 取整串地址regexStr = \".*https.*jpg$\"# 取XXX.jpg png gif 等regexStr = \".*/(.*.(jpg|gif|png))$\"# 取2018-02-17/g4edlvxmmyi9627.jpg png gif等regexStr = \".*/(\\d&#123;4&#125;-\\d&#123;2&#125;-\\d&#123;2&#125;/(.*.(jpg|gif|png)))$\" 收尾提取字符串12345reMatch = re.match(regexStr,str1)if reMatch: print (reMatch.group(1))else: print('No')","categories":[{"name":"note","slug":"note","permalink":"https://sbcoder.cn/categories/note/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"https://sbcoder.cn/tags/笔记/"},{"name":"正则表达式","slug":"正则表达式","permalink":"https://sbcoder.cn/tags/正则表达式/"}]},{"title":"博客迁移说明","slug":"博客迁移说明","date":"2019-03-25T05:12:58.000Z","updated":"2019-04-12T14:57:49.000Z","comments":true,"path":"2019/03/25/Hello_world.html","link":"","permalink":"https://sbcoder.cn/2019/03/25/Hello_world.html","excerpt":"","text":"关于迁移博客总是在起起伏伏，关了又开，开了又关中反复，这一次，我将风向标博客放在了Github Page上。程序采用了当下比较流行的静态博客程序 Hexo ，Hexo其实是一个非常好的程序，但由于我经常换电脑，以前用hexo搭建的博客数据丢失了很多次，后经过更换为Wordpress，Typecho之类的开源博客程序后，我又回到了 Hexo 的怀抱，可能是真的懒得折腾了，上了年纪？这次我将源代码都备份好了，应该会长期更新，有什么好的东西我应该会分享出来，主打原创~可能之前认识我的人也很少，但我这个域名还是很好记的，sb coder 也是一种自嘲吧，有想跟我交流技术或者有外包工作介绍给我的，我的微信与域名同号~多的不说了，我将尽我所能，一周至少写一篇文章，可能有时候晚上回家写一点，一天写一点，一周下来也能写不少，希望各位监督~ 关于我我是谁，职业是PHP，爱好Python，云服务器爱好者支付接口对接，可以定制各类免签约支付接口，微信支付宝，有想法的朋友可以联系我 Telegram : ai0by 承接业务支付相关业务，爬虫(几乎不要钱，练手)，PHP程序开发服务器环境配置，PHP程序修改，PHP BUG排查","categories":[],"tags":[{"name":"ai0by","slug":"ai0by","permalink":"https://sbcoder.cn/tags/ai0by/"}]},{"title":"岛国推特妹子图爬虫","slug":"岛国推特妹子图爬虫","date":"2019-03-22T03:54:58.000Z","updated":"2020-05-17T05:22:04.930Z","comments":true,"path":"2019/03/22/Japan_Twitter_Spider.html","link":"","permalink":"https://sbcoder.cn/2019/03/22/Japan_Twitter_Spider.html","excerpt":"","text":"LOC的大佬们分享了一个网站，收集了很多岛国的妹子图和她们的推特地址：岛国妹子推特推特不是很感兴趣，就爬一下图片好了~ 爬虫介绍爬虫环境： Python2.7.9 可更替为3，自行更替 BeautifulSoup4 requests 代码：12345678910111213141516171819202122232425262728293031323334# -*- coding: utf-8 -*-from bs4 import BeautifulSoupimport requestsimport urllib2import randomdef spy(url): req = urllib2.Request(url) req = urllib2.urlopen(req) page = req.read() soup = BeautifulSoup(page, \"html.parser\") for imgSoup in soup.find_all('div', &#123;\"class\": \"row\"&#125;): for i in imgSoup.find_all('div', &#123;'class': 'photo'&#125;): for j in i.find('div', &#123;'class': 'photo-link-outer'&#125;).find('a').find_all('img'): img = j.get(\"src\") print img str = random.sample('zyxwvutsrqponmlkjihgfedcba', 6) downImg(img, str) nexturl = soup.find('p',&#123;'class':'go-to-next-page'&#125;) nexturl = nexturl.find('a').get('href') pageurl = \"http://jigadori.fkoji.com\"+nexturl spy(pageurl)def downImg(img,m): try: r = requests.get(img) except Exception , e: print \"图片获取失败\" return with open('./img/good%s.jpg' % m, 'wb') as f: f.write(r.content)if __name__ == '__main__': url = \"http://jigadori.fkoji.com\" spy(url) 整体思路看一下，网页构造，发现首页底部有下一页标签，BeautifulSoup取Class取值递归获取下一页地址图片同上整体难度不高，有兴趣的可以拿这个网站练练手~ 演示截图 演示数据1 演示数据2","categories":[{"name":"Python","slug":"Python","permalink":"https://sbcoder.cn/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://sbcoder.cn/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://sbcoder.cn/tags/爬虫/"},{"name":"福利","slug":"福利","permalink":"https://sbcoder.cn/tags/福利/"}]},{"title":"Python+selenium针对网银控件过登录取数据","slug":"Python-selenium针对网银控件过登录取数据","date":"2019-03-21T08:53:30.000Z","updated":"2020-05-17T05:21:49.068Z","comments":true,"path":"2019/03/21/Python_WY_Spider.html","link":"","permalink":"https://sbcoder.cn/2019/03/21/Python_WY_Spider.html","excerpt":"","text":"Python获取WY数据的方法总结： 由于WY控件加密方式相比较一般网站比较特殊，需在驱动层进行操作 由于WY控件的特殊性，获取交易数据的时候需要传递KEY (以CCB为例) 由于取数据时的问题，所有操作均应该在驱动层完成 要想实现实时更新数据，需要不断地登录，大部分WY都有强制退出操作 理清思路登录的过程中，由于安全控件的限制，需要绕过登录限制，此处思路借鉴了 爬虫应对银行安全控件，由此可知，需要绕过登陆限制需从驱动层入手 两种方案 Python可以使用 Win32api 模块来模拟键盘指令，类似于按键精灵的概念 Python使用 Photomjs 无界面浏览器配合Selenium Webdirver 尝试使用Win32api时，由于需要配合鼠标操作，需要获取句柄坐标，且开发难度较高，尝试更换另一种方式更换 Photomjs ，模拟登录时发现 Photomjs 并没有附带安全控件，所传输的值不会自动加密，尝试更换为 ChromDriver使用 ChromDriver 尝试模拟登陆 123456username = browser.find_element_by_name('USERID')username.send_keys(username)password = browser.find_element_by_name('LOGPASS')password.send_keys(password)tjButton = browser.find_element_by_id('loginButton')tjButton.click() 登录成功！ 当越过了登录后就需要获取交易信息，交易信息这一块，CCB的查询地址附带了一个SKEY，每次查询信息的时候都需要一个SKEY验证，如果不正确将不会返回正确的结果！如何获取SKEY，涉及到WY的信息，这里不便细说（PS：细心地同学一定可以找到） 取到SKEY后即可构造查询地址，然后使用WebDriver模拟访问需要注意的一点是，WY的大部分数据均是用iframe嵌套的，因此需要多处过iframe 演示代码1234# 定位到iframeiframe = browser.find_element_by_id(\"iframe\")# 切换到iframebrowser.switch_to_frame(iframe) 取数据这一块不多说，每个WY也都不同获取到数据后就是数据处理了，根据系统不同，我这里直接使用Python向固定地址POST传值 取数据后为了获取实时数据，需要定时向固定地址提交数据，大部分的WY都有长时间自动登出的骚操作，对此，思路也很多 大致几个想法 自动刷新，保持登录状态 重复登录，更换SKEY，反复操作 模拟点击，保持登录状态 自动刷新方案在一开始就失败了，多次频繁的刷新，会导致弹出手机验证码重复登录，由于上次的失败，设置了延时，效果还可以，只是数据总会有延迟模拟点击，无效，仍然会自动登出 采用重复登录的方式，递归实现！ 综上所述，我们可以将交易流程如此划分： WY数据.jpg 成果演示 WY演示.jpg Tips:本文仅做思路分享，切勿用在实际生产环境！","categories":[{"name":"Python","slug":"Python","permalink":"https://sbcoder.cn/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://sbcoder.cn/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://sbcoder.cn/tags/爬虫/"},{"name":"网银","slug":"网银","permalink":"https://sbcoder.cn/tags/网银/"},{"name":"selenium","slug":"selenium","permalink":"https://sbcoder.cn/tags/selenium/"}]}]}