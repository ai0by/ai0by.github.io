<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>风向标 | 分享与创造</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://sbcoder.cn/"/>
  <updated>2019-06-20T10:21:49.000Z</updated>
  <id>https://sbcoder.cn/</id>
  
  <author>
    <name>ai0by</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>开发中常见的MySQL数据库优化细节</title>
    <link href="https://sbcoder.cn/2019/06/20/tuwan_spider.html"/>
    <id>https://sbcoder.cn/2019/06/20/tuwan_spider.html</id>
    <published>2019-06-20T10:17:03.000Z</published>
    <updated>2019-06-20T10:21:49.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>以我的习惯来讲，每开始一个新的项目都需要先把思路完善，紧接着就需要建立数据库，在码代码的时候，就一般不会在修改数据库的构造了，因此，数据库的结构通常关乎着查询的速度以及程序的完善程度，一个好的结构可以让你少写很多代码，也能让程序的运行速度更加快，通常在大公司都是由DBA来做这件事，但是事无绝对，作为一名合格的后端，掌握一些少量的数据库优化也是很需要的。</p><h1 id="MySQL优化-数据类型及CURD"><a href="#MySQL优化-数据类型及CURD" class="headerlink" title="MySQL优化 - 数据类型及CURD"></a>MySQL优化 - 数据类型及CURD</h1><h2 id="PROCEDURE-ANALYSE"><a href="#PROCEDURE-ANALYSE" class="headerlink" title="PROCEDURE ANALYSE()"></a>PROCEDURE ANALYSE()</h2><p>PROCEDURE ANALYSE() [prəˈsējər ˈænəlaɪz]是一个MySQL自带的给我们提供数据库优化建议的函数，他可以直接运行在MySQL中，直接在执行语句中加上这个函数即可<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span>  <span class="string">`list`</span> <span class="keyword">WHERE</span> <span class="number">1</span> <span class="keyword">PROCEDURE</span> ANALYSE ( );</span><br></pre></td></tr></table></figure></p><p>这段SQL执行过后，将会把list表中的数据分析一遍，并把他的分析结果展示出来</p><table><thead><tr><th>Field_name</th><th>Min_value</th><th>Max_value</th><th>Min_length</th><th>Max_length</th><th>Empties_or_zeros</th><th>Nulls</th><th>Avg_value_oravg_length</th><th>std</th><th>Optimal_fieldtype</th></tr></thead><tbody><tr><td></td></tr></tbody></table><p>他将会把分析出来的 字段名 最短值 最大值 以及最后一列就是MySQL给出的分析结果，我们可以在有一定数据的时候使用这个函数来分析，这样给出的结果会更精确一些，只需要查看最后一列Optimal_fieldtype的值即可，这个函数并不适用于数据库设计阶段，它适用于后期使用</p><h2 id="EXPLAIN"><a href="#EXPLAIN" class="headerlink" title="EXPLAIN"></a>EXPLAIN</h2><p>EXPLAIN是一个非常好用的MySQL语法，在我们功能测试阶段，如果发现某页面非常慢，排除静态资源问题后就可以试试使用EXPLAIN，我们可以在执行语句前面加上 EXPLAIN 来获得执行过程，通过该结果我们可以看到SQL如何改变会减少查询时间和次数。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">EXPLAIN</span> <span class="keyword">SELECT</span> * <span class="keyword">FROM</span>  <span class="string">`list`</span> <span class="keyword">WHERE</span> <span class="number">1</span></span><br></pre></td></tr></table></figure></p><p>这段SQL执行后，将会返回如下格式的分析结果</p><table><thead><tr><th>id</th><th>select_type</th><th>table</th><th>type</th><th>possible_keys</th><th>key</th><th>key_len</th><th>ref</th><th>rows</th><th>Extra</th></tr></thead><tbody><tr><td></td></tr></tbody></table><p>我们主要看rows就行，为了得到想要的结果，rows的值越小越好，使用EXPLAIN来调试简直是再好不过了！</p><h2 id="ENUM-枚举-类型"><a href="#ENUM-枚举-类型" class="headerlink" title="ENUM(枚举)类型"></a>ENUM(枚举)类型</h2><p>很多程序员往往喜欢统一一个数据类型，比如说 ‘varchar’ ，这可能是我见过最多的数据类型了，早些时期，的确是有很多的公司或者程序都是大面积使用，随着MySQL的革新换代，很多的类型都可以避免使用它。<br>我在很多得程序上测试过（有数据）PROCEDURE ANALYSE()方法，他给出了很多 ‘varchar’ 替换为 ‘enum’ 的建议，这说明，enum类型的确是一个应该被重视的数据类型，但由于他是一个枚举类型，我们在定义数据类型的时候并不适合直接上手定义，所以很多时候都是在有一定的数据量的时候才想要换数据类型的。<br>可以理解为枚举即时索引，枚举就相当于给这个字段的可能值都加上了一个索引，与我们为了优化查询加索引是一样的概念。<br>enum更适用于选项卡类字段，例如性别，订单状态等，如果您字段中只有几个重复的值也是非常推荐使用的。</p><h2 id="JOIN"><a href="#JOIN" class="headerlink" title="JOIN"></a>JOIN</h2><p>链接查询，这是我们在开发中非常常用的查询方式，首先要知道，我们在学校里学习的大多数是 AND 链接多表查询，虽然能够将结果无误的查询出来，但是速度就影响的非常多了，这里还是推荐大家使用JOIN来连接查询<br>有些同学可能不太理解JOIN，简单说一下JOIN的内连接和外链接，左外链接和右外链接吧</p><p>内连接即是A B两表链接，只取两表共有的数据，假设 B 中 有的数据 A 表内没有对应的数据则无法查询到</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> list1 <span class="keyword">INNER</span> <span class="keyword">JOIN</span> list2 <span class="keyword">on</span> list1.id = list2.id;</span><br><span class="line">```</span><br><span class="line"></span><br><span class="line">外连接（FULL JOIN 也称作全连接）即是A B两表链接，取两表所有的数据，即使 B 表中的某些数据无法匹配链接条件时，也正常链接</span><br><span class="line"></span><br><span class="line">```sql</span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> list1 <span class="keyword">FULL</span> <span class="keyword">JOIN</span> list2 <span class="keyword">on</span> list1.id = list2.id;</span><br><span class="line">```</span><br><span class="line"></span><br><span class="line">左外连接，即是 A B两表链接，取两表所有数据，若A表中有B表不匹配的数据，同样展示出来，B表如果有A不匹配的数据，则不展示</span><br><span class="line"></span><br><span class="line">```sql</span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> list1 <span class="keyword">LEFT</span> <span class="keyword">OUTER</span> <span class="keyword">JOIN</span> list2 <span class="keyword">on</span> list1.id = list2.id;</span><br><span class="line">```</span><br><span class="line"></span><br><span class="line">右外连接，即是 A B两表链接，取两表所有数据，若B表中有A表不匹配的数据，同样展示出来，A表如果有B不匹配的数据，则不展示，与左外连接相反</span><br><span class="line"></span><br><span class="line">![VvmQFU.png](https://s2.ax1x.com/2019/06/20/VvmQFU.png)</span><br><span class="line"></span><br><span class="line"><span class="comment"># MySQL优化 - 结构</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## FULLTEXT INDEX</span></span><br><span class="line">FULLTEXT INDEX(全文索引)，更适用于文章内容搜索的索引，我们在作搜索功能的时候，很多人喜欢将文章内容(content)建立普通索引，但是实际上，这种做法并不会增加查询速度，通常我们做搜索的时候，执行下列语句。</span><br><span class="line"></span><br><span class="line">```sql</span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">content</span> <span class="keyword">FROM</span>  <span class="string">`list`</span> <span class="keyword">WHERE</span> <span class="keyword">content</span> <span class="keyword">LIKE</span> <span class="string">'%风向标%'</span>;</span><br></pre></td></tr></table></figure><p>如果搜索功能权重比较高的网站，就需要将content这个字段建立索引。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span>  <span class="string">`list`</span> <span class="keyword">ADD</span> FULLTEXT (<span class="string">`content`</span>);</span><br></pre></td></tr></table></figure><p>如果是phpmyadmin用户，在phpmyadmin中直接点击’全文搜索’即可。</p><h2 id="MyISAM-OR-InnoDB？"><a href="#MyISAM-OR-InnoDB？" class="headerlink" title="MyISAM OR InnoDB？"></a>MyISAM OR InnoDB？</h2><p>就我现阶段写出来的东西来看（数据量小，查询次数少，用户量较少），MyISAM肯定是最适合我的，它更适用于小型网站，以及事务处理较少的网站<br>InnoDB则与之相反，如果你的业务比较复杂，针对数据库的操作较多的时候，InnoDB就会更适合一些。<br>使用INSERT插入数据时 MyISAM 就比 InnoDB 更快一些，而 UPDATE 时 InnoDB 就会比 MyISAM 快一些</p><p>如果您是轻度SQL用户，重功能不重视业务的项目，那么我个人以为 MyISAM 更适合一些<br>如果您感觉业务逻辑复杂，经常使用SQL，那么可以尝试使用 InnoDB</p><p>最后也是见仁见智，没有好坏，如果您希望测试，也是可以通过直接修改数据库引擎来测试速度的</p><h1 id="MySQL优化-小知识点"><a href="#MySQL优化-小知识点" class="headerlink" title="MySQL优化 - 小知识点"></a>MySQL优化 - 小知识点</h1><ul><li>不要使用 SELECT * 查询</li><li>不要使用 NULL</li><li>频繁查询的字段建立索引</li><li>索引过多时会影响 UPDATE 和 INSERT 的执行速度</li><li>避免在 WHERE 时使用 != &lt;&gt; 等操作符，MySQL会自动放弃索引，直接全表扫描</li><li>避免使用 IN 和 NOT IN，尽量使用BETWEEN，MySQL会自动放弃索引，直接全表扫描</li><li>可以使用 EXISTS 来代替 IN 使用</li><li>某些情况下可以使用强制使用索引查询 SELECT * FROM list with(index(索引名)) WHERE ….</li><li>避免使用 OR 作为调件，可以使用 UNION 并集查询将两次查询结果合并</li><li>尽可能将表内容长度固定</li><li>查询时如果只查询一条信息，就使用 LIMIT 1</li><li>避免使用比较表达式 如 10000+1 = id 可以使用 id = 10000+1</li><li>记得将查询链接即时关闭掉</li><li>使用变量来给MySQL开启查询缓存，避免使用MySQL内置变量函数</li><li>设置的主键尽量使用长度短且最好是int类型</li><li>垂直分割，将大量的字段的表优化成多个少字段的表</li><li>INSERT 和 DELETE 是一个可以锁定数据表的SQL语句，必须等待执行完毕后才会解除锁定，如果这条语句执行起来过于缓慢，请谨慎使用</li><li>Object Relational Mapper</li><li>Prepared Statements</li></ul><p>参考:  <a href="https://code.tutsplus.com/tutorials/top-20-mysql-best-practices--net-7855" target="_blank" rel="noopener">Top 20+ MySQL Best Practices</a><br>参考:  <a href="https://www.liaoxuefeng.com/wiki/1177760294764384/1179610888796448" target="_blank" rel="noopener">廖雪峰的个人网站 - 链接查询</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;以我的习惯来讲，每开始一个新的项目都需要先把思路完善，紧接着就需要建立数据库，在码代码的时候，就一般不会在修改数据库的构造了，因此，数据库的
      
    
    </summary>
    
      <category term="优化" scheme="https://sbcoder.cn/categories/%E4%BC%98%E5%8C%96/"/>
    
    
      <category term="MySQL" scheme="https://sbcoder.cn/tags/MySQL/"/>
    
      <category term="优化" scheme="https://sbcoder.cn/tags/%E4%BC%98%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>mm131全栈多线程爬虫</title>
    <link href="https://sbcoder.cn/2019/06/19/mm131_spider.html"/>
    <id>https://sbcoder.cn/2019/06/19/mm131_spider.html</id>
    <published>2019-06-19T14:34:31.000Z</published>
    <updated>2019-06-19T14:56:33.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="起因"><a href="#起因" class="headerlink" title="起因"></a>起因</h1><p>LOC的大佬们最近开始疯狂的爬取mm131，作为一个Python初心者，作为技术上的学习，也要与时俱进，简单写了一个图片下载爬虫，看到大佬们似乎是做了一个typechoo的对接接口，我这边回头有空也搞一个wordpress的接口（只在博客内发布），之前写过一个新浪远程上传的接口，由于种种原因，新浪已经不支持外链了，因此这个wordpress接口可能就有时间再做了，不然做出来也是个摆设，没地方放。</p><h1 id="代码解析"><a href="#代码解析" class="headerlink" title="代码解析"></a>代码解析</h1><p>网址不发了，直接讲，或者大家直接百度谷歌都可以搜得到。<br>打开网站,总共有如下六个分类<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/06/18/VLAght.jpg" alt="mm131.jpg" title>                </div>                <div class="image-caption">mm131.jpg</div>            </figure><br>每个分类下面都有一堆的图集，有N个分页的图集，但是第一页跟第二页的地址还不太一样，这点跟192tt做的很相似，感觉这几个站长是不是都是用的同一套程序，如果是的话可以通杀了。。。<br>首先遍历图集的地址，到目前更新文章截止，一共大概5000多套<br>按分类给他搞一个分类循环</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">list = &#123;<span class="string">'xinggan'</span>:<span class="number">6</span>,<span class="string">'qingchun'</span>:<span class="number">1</span>,<span class="string">'xiaohua'</span>:<span class="number">2</span>,<span class="string">'chemo'</span>:<span class="number">3</span>,<span class="string">'qipao'</span>:<span class="number">4</span>,<span class="string">'mingxing'</span>:<span class="number">5</span>&#125;</span><br><span class="line">    <span class="comment"># list = &#123;'mingxing':5&#125;</span></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> list:</span><br><span class="line">        getPageUrl(key,list[key])</span><br></pre></td></tr></table></figure><p>解析图片url，用正则获取就行，用bs4取到末页的地址，然后遍历循环取图集地址</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    i.find(<span class="string">'img'</span>).get(<span class="string">'src'</span>)</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    <span class="keyword">for</span> s <span class="keyword">in</span> i.find_all(<span class="string">'a'</span>):</span><br><span class="line">        endPage = s.get(<span class="string">'href'</span>)</span><br><span class="line">    endPage = rex(<span class="string">'list_%s_(\d+).html'</span>%num,endPage)</span><br><span class="line">    <span class="keyword">continue</span></span><br></pre></td></tr></table></figure><p>获取图集地址<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">nextUrl = <span class="string">"%s/list_%s_%s.html"</span>%(url,num,i+<span class="number">2</span>)</span><br><span class="line">response = requests.get(nextUrl, headers=headers)</span><br><span class="line">response.encoding = <span class="string">'gb2312'</span></span><br><span class="line">soup = BeautifulSoup(response.text, <span class="string">'html.parser'</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> soup.find(<span class="string">'dl'</span>, &#123;<span class="string">'class'</span>: <span class="string">'public-box'</span>&#125;).find_all(<span class="string">'dd'</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        i.find(<span class="string">'img'</span>).get(<span class="string">'src'</span>)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    print(i.find(<span class="string">'a'</span>).get(<span class="string">'href'</span>))</span><br></pre></td></tr></table></figure></p><p>需要注意的是，mm131的图片是有防盗链的，根据referer判断，随便找一个图集的地址设置上即可<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">"User-Agent"</span>: <span class="string">"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36"</span>,</span><br><span class="line">    <span class="string">'referer'</span>: <span class="string">"http://www.mm131.com/xinggan/4995.html"</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h1 id="线程池应用"><a href="#线程池应用" class="headerlink" title="线程池应用"></a>线程池应用</h1><p>之前的爬虫除了Scrapy搞出来的之外都是单线程的爬虫，优点是比较稳定，但是缺点也很明显，太慢了，mm131这个站的图大都比较小，如果是一张一张下载确实是不太划算，于是搞了个线程池。<br>Python的线程池很简单，只需要引入 threadpool 即可，如果报错，请 pip install threadpool,<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 引入threadpool</span></span><br><span class="line"><span class="keyword">import</span> threadpool</span><br><span class="line"><span class="comment"># 创建线程池，设置为12线程，可以根据自身情况修改</span></span><br><span class="line">pool = threadpool.ThreadPool(<span class="number">12</span>)</span><br><span class="line"><span class="comment"># 创建callback函数，参数1 getSingleData 是需要调用的函数名，list是函数getSingleData的参数，该方法适用于单个参数的函数，list是一个一维数组或对象</span></span><br><span class="line">pageTask = threadpool.makeRequests(getSingleData, list)</span><br><span class="line"><span class="comment"># 执行线程池</span></span><br><span class="line">[pool.putRequest(req) <span class="keyword">for</span> req <span class="keyword">in</span> pageTask]</span><br><span class="line"><span class="comment"># 等待完成后退出</span></span><br><span class="line">pool.wait()</span><br></pre></td></tr></table></figure></p><h1 id="演示和下载"><a href="#演示和下载" class="headerlink" title="演示和下载"></a>演示和下载</h1><h3 id="演示图"><a href="#演示图" class="headerlink" title="演示图"></a>演示图</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/06/18/VLE8v8.jpg" alt="多线程演示.jpg" title>                </div>                <div class="image-caption">多线程演示.jpg</div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/06/18/VLEhP1.jpg" alt="下载结果.jpg" title>                </div>                <div class="image-caption">下载结果.jpg</div>            </figure><h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><p>演示代码不全，直接上地址<br><a href="https://github.com/ai0by/ai0by-spider/tree/master/mm131" target="_blank" rel="noopener">https://github.com/ai0by/ai0by-spider/tree/master/mm131</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;起因&quot;&gt;&lt;a href=&quot;#起因&quot; class=&quot;headerlink&quot; title=&quot;起因&quot;&gt;&lt;/a&gt;起因&lt;/h1&gt;&lt;p&gt;LOC的大佬们最近开始疯狂的爬取mm131，作为一个Python初心者，作为技术上的学习，也要与时俱进，简单写了一个图片下载爬虫，看到大佬们
      
    
    </summary>
    
      <category term="Python" scheme="https://sbcoder.cn/categories/Python/"/>
    
    
      <category term="Python" scheme="https://sbcoder.cn/tags/Python/"/>
    
      <category term="爬虫" scheme="https://sbcoder.cn/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="福利" scheme="https://sbcoder.cn/tags/%E7%A6%8F%E5%88%A9/"/>
    
  </entry>
  
  <entry>
    <title>Redis/Redis集群以及在Laravel中的使用方法</title>
    <link href="https://sbcoder.cn/2019/06/17/Redis_laravel_PHP.html"/>
    <id>https://sbcoder.cn/2019/06/17/Redis_laravel_PHP.html</id>
    <published>2019-06-17T13:19:37.000Z</published>
    <updated>2019-06-17T13:21:08.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Redis的数据类型"><a href="#Redis的数据类型" class="headerlink" title="Redis的数据类型"></a>Redis的数据类型</h2><p>Redis也算是一种数据的容器，承载在内存上，因此它的各方面性能都比较快，且作为非关系型数据库，面对各种索引也比普通的数据库查询快，不同的场景下使用不同的数据类型，适用于很多地方</p><h3 id="字符串类型-String"><a href="#字符串类型-String" class="headerlink" title="字符串类型 String"></a>字符串类型 String</h3><p>一一对应，使用场景比较多 key:value 形式</p><table><thead><tr><th>命令</th><th>描述 </th></tr></thead><tbody><tr><td>set key value</td><td>设置指定key值</td></tr><tr><td>get key</td><td>获取指定key的value值</td></tr><tr><td>mget key1 key2</td><td>获取多个key 的 value，按顺序返回value值</td></tr><tr><td>mset key1 ‘value1’ key2 ‘value2’</td><td>批量设置多个key的value</td></tr><tr><td>strlen key</td><td>返回对应value长度</td></tr><tr><td>getrange key start end</td><td>截取字符串</td></tr><tr><td>append key value</td><td>追加key关联的value值，返回长度</td></tr><tr><td>getset key value</td><td>设置key的value并返回原value值</td></tr><tr><td>setex key time value</td><td>设置value值，并加上一个过期时间，使用ttl key查看过期时间，秒为单位</td></tr><tr><td>setnx key value</td><td>当key不存在时，设置value</td></tr><tr><td>msetnx key1 ‘value1’ key2 ‘value2’</td><td>当所有的key都不存在时，批量设置多个key的value</td></tr><tr><td>incr key</td><td>将key关联value的值加一，仅对数字有效</td></tr><tr><td>incrby key num</td><td>将key关联value的值加num，例如 10，仅对数字有效</td></tr><tr><td>incrbyflout key num</td><td>将key关联value的值加num，浮点类型</td></tr><tr><td>decr key</td><td>将key关联value的值减一，仅对数字有效</td></tr><tr><td>decrby key num</td><td>将key关联value的值减num，例如 10，仅对数字有效</td></tr></tbody></table><h3 id="哈希类型-Hash"><a href="#哈希类型-Hash" class="headerlink" title="哈希类型 Hash"></a>哈希类型 Hash</h3><p>一对一对多，类似字符串，但又区别于字符串，它比字符串复杂一些，同样是key:value，但是他的value可以是一个map，同时，它也无法给单个属性赋予过期时间，但可以给单个属性设置值，某些情况下比String占用资源少，当需要缓存整张表时推荐使用</p><table><thead><tr><th>命令</th><th>描述 </th></tr></thead><tbody><tr><td>hset key field value</td><td>设置key关联的value</td></tr><tr><td>hkeys key</td><td>获取所有的key</td></tr><tr><td>hgetall key</td><td>获取key的所有对应field</td></tr><tr><td>hvals key</td><td>获取hash表中所有的value</td></tr><tr><td>hlen key</td><td>获取keyd的长度</td></tr><tr><td>hmget key field1 field2</td><td>获取多个field的值</td></tr><tr><td>hmset key field1 value1 field2 value2</td><td>设置多个field的值</td></tr><tr><td>hdel key field</td><td>删除单个field的单个属性</td></tr><tr><td>hsetnx key field value</td><td>当field不存在时存储数值</td></tr><tr><td>hincrby key field num</td><td>给指定字段增加数值，整数</td></tr><tr><td>hincrbyfloat key field num</td><td>给指定字段增加浮点数</td></tr></tbody></table><h3 id="列表类型-List"><a href="#列表类型-List" class="headerlink" title="列表类型 List"></a>列表类型 List</h3><p>类似栈，拥有栈的特性，也有链表的特性，亦可用作消息队列等场景，使用场景很广</p><table><thead><tr><th>命令</th><th>描述 </th></tr></thead><tbody><tr><td>lpush key value1 value2</td><td>将多个value插入到关联的key里面 头部</td></tr><tr><td>lpushx key value</td><td>将value插入到key中，需要key已经存在 头部</td></tr><tr><td>lpop key</td><td>删除并获取当前key里面的第一个元素</td></tr><tr><td>llen key</td><td>获取当前key关联的list长度</td></tr><tr><td>rpush key value1 value2</td><td>将多个value插入到关联的key里面 尾部</td></tr><tr><td>rpop key</td><td>删除并获取列表内的最后一个元素</td></tr><tr><td>rpushx key value</td><td>将value插入到key中，需要key已经存在 尾部</td></tr><tr><td>blpop key1 key2    timeout</td><td>删除并获取列表的第一个元素，key1存在时不执行key2，如果没有会一直阻塞到弹出为止，建议添加延时</td></tr><tr><td>brpop key1 key2    timeout</td><td>删除并获取列表的最后一个元素，key1存在时不执行key2，如果没有会一直阻塞到弹出为止，建议添加延时</td></tr><tr><td>lindex key</td><td>通过索引来获取list中的元素</td></tr><tr><td>lset key index value</td><td>通过索引来设置相应元素的值</td></tr><tr><td>lrange key start end</td><td>截取指定列表内元素</td></tr><tr><td>ltrim key start end</td><td>只保留开始和结束内的元素</td></tr></tbody></table><h3 id="集合-set"><a href="#集合-set" class="headerlink" title="集合 set"></a>集合 set</h3><p>数据池，无序，可计算差集交集等，之前写爬虫时用集合做过去重，Python使用redis也是非常方便的</p><table><thead><tr><th>命令</th><th>描述 </th></tr></thead><tbody><tr><td>sadd key member1 member2</td><td>向集合内添加元素</td></tr><tr><td>scard key</td><td>获取集合内元素数量</td></tr><tr><td>smembers key</td><td>获取集合内所有的元素</td></tr><tr><td>sismember key member</td><td>判断member是否是key集合的子元素</td></tr><tr><td>sdiff key1 key2</td><td>获取给定集合的差集</td></tr><tr><td>sinter key1 key2</td><td>获取给定集合的交集</td></tr><tr><td>sunion key1 key2</td><td>获取给定集合的并集</td></tr><tr><td>spop key</td><td>随机删除一个集合内元素并返回</td></tr><tr><td>srandmember key num</td><td>返回集合内的一个或者多个随机元素</td></tr><tr><td>srem key member1 member2</td><td>删除集合中一个或者多个指定元素</td></tr></tbody></table><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p>剩下的数据类型确实是没用过，这里不便多说</p><h2 id="Laravel使用redis流程"><a href="#Laravel使用redis流程" class="headerlink" title="Laravel使用redis流程"></a>Laravel使用redis流程</h2><p>简单来说如下图所示<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://i.loli.net/2019/06/17/5d07545d4a38c24666.jpg" alt="Laravel使用redis" title>                </div>                <div class="image-caption">Laravel使用redis</div>            </figure></p><p>程序将数据存储请求发送给Laravel内置的redis模块（PHPRedis，Predis等），并在config/database.php中配置好redis的端口密码等信息，通过内置模块调用已经安装好的redis即可使用redis存储使用数据了，然后redis内部处理数据<br>我们如果不做底层的话，正常存储使用，只需要处理好程序与Laravel之间的过程就可以了，也就是说，了解PHPRedis和Predis就可以了，目前似乎大多数人使用的都是这两种，也不仅限于Laravel，原生PHP以及像Swoole这种的也是可以使用的。</p><p>关于Laravel中的Redis配置使用 可以参考 <a href="https://learnku.com/docs/laravel/5.8/redis/3930" target="_blank" rel="noopener">Laravel中文文档5.8 - redis</a></p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// laravel 简单调用示例</span></span><br><span class="line"><span class="keyword">use</span> <span class="title">Illuminate</span>\<span class="title">Support</span>\<span class="title">Facades</span>\<span class="title">Redis</span>;</span><br><span class="line">class testRedis()&#123;</span><br><span class="line">Redis::set(<span class="string">'username'</span>,<span class="string">'风向标'</span>);</span><br><span class="line">$username = Redis::get(<span class="string">'username'</span>);</span><br><span class="line"><span class="keyword">return</span> $username;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Laravel使用Redis集群"><a href="#Laravel使用Redis集群" class="headerlink" title="Laravel使用Redis集群"></a>Laravel使用Redis集群</h2><p>仍然是在 config/database 中配置 clusters<br><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'redis'</span> =&gt; [</span><br><span class="line"></span><br><span class="line">        <span class="string">'client'</span> =&gt; env(<span class="string">'REDIS_CLIENT'</span>, <span class="string">'predis'</span>),</span><br><span class="line"></span><br><span class="line">        <span class="string">'options'</span> =&gt; [</span><br><span class="line">            <span class="string">'cluster'</span> =&gt; env(<span class="string">'REDIS_CLUSTER'</span>, <span class="string">'predis'</span>),</span><br><span class="line">            <span class="comment">// 'cluster' =&gt; env('redis'),</span></span><br><span class="line">        ],</span><br><span class="line"></span><br><span class="line">        <span class="string">'clusters'</span> =&gt; [                                                                             </span><br><span class="line">        <span class="string">'vaneCache'</span> =&gt; [                                                                       </span><br><span class="line">            [                                                                                   </span><br><span class="line">                <span class="string">'host'</span> =&gt; env(<span class="string">'REDIS_HOST'</span>, <span class="string">'127.0.0.1'</span>),                                       </span><br><span class="line">                <span class="string">'password'</span> =&gt; env(<span class="string">'REDIS_PASSWORD'</span>, <span class="keyword">null</span>),                                      </span><br><span class="line">                <span class="string">'port'</span> =&gt; env(<span class="string">'REDIS_PORT'</span>, <span class="number">6379</span>),                                              </span><br><span class="line">                <span class="string">'database'</span> =&gt; <span class="number">1</span>,                                                                </span><br><span class="line">            ],                                                                                  </span><br><span class="line">            [                                                                                   </span><br><span class="line">                <span class="string">'host'</span> =&gt; env(<span class="string">'REDIS_HOST'</span>, <span class="string">'127.0.0.1'</span>),                                       </span><br><span class="line">                <span class="string">'password'</span> =&gt; env(<span class="string">'REDIS_PASSWORD'</span>, <span class="keyword">null</span>),                                      </span><br><span class="line">                <span class="string">'port'</span> =&gt; env(<span class="string">'REDIS_PORT'</span>, <span class="number">6379</span>),                                              </span><br><span class="line">                <span class="string">'database'</span> =&gt; <span class="number">2</span>,                                                                </span><br><span class="line">            ],</span><br><span class="line">            [                                                                                   </span><br><span class="line">                <span class="string">'host'</span> =&gt; env(<span class="string">'REDIS_HOST'</span>, <span class="string">'127.0.0.1'</span>),                                       </span><br><span class="line">                <span class="string">'password'</span> =&gt; env(<span class="string">'REDIS_PASSWORD'</span>, <span class="keyword">null</span>),                                      </span><br><span class="line">                <span class="string">'port'</span> =&gt; env(<span class="string">'REDIS_PORT'</span>, <span class="number">6379</span>),                                              </span><br><span class="line">                <span class="string">'database'</span> =&gt; <span class="number">3</span>,                                                                </span><br><span class="line">            ], </span><br><span class="line">       ],</span><br><span class="line">   ],</span><br><span class="line"></span><br><span class="line">    ],</span><br></pre></td></tr></table></figure></p><p>在使用时仅需要 使用 connection 即可</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$redis1 = Redis::connection(<span class="string">'vaneCache'</span>);</span><br><span class="line">$redis1-&gt;set(<span class="string">'username'</span>,<span class="string">'风向标'</span>);</span><br><span class="line">$username = $redis1-&gt;get(<span class="string">'username'</span>);</span><br><span class="line"><span class="keyword">echo</span> $username;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Redis的数据类型&quot;&gt;&lt;a href=&quot;#Redis的数据类型&quot; class=&quot;headerlink&quot; title=&quot;Redis的数据类型&quot;&gt;&lt;/a&gt;Redis的数据类型&lt;/h2&gt;&lt;p&gt;Redis也算是一种数据的容器，承载在内存上，因此它的各方面性能都比较快，且
      
    
    </summary>
    
      <category term="PHP" scheme="https://sbcoder.cn/categories/PHP/"/>
    
    
      <category term="优化" scheme="https://sbcoder.cn/tags/%E4%BC%98%E5%8C%96/"/>
    
      <category term="PHP" scheme="https://sbcoder.cn/tags/PHP/"/>
    
      <category term="Laravel" scheme="https://sbcoder.cn/tags/Laravel/"/>
    
      <category term="Redis" scheme="https://sbcoder.cn/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>tuwan（兔玩）全站妹子图爬虫可多窗口</title>
    <link href="https://sbcoder.cn/2019/05/13/tuwan_spider.html"/>
    <id>https://sbcoder.cn/2019/05/13/tuwan_spider.html</id>
    <published>2019-05-13T15:01:00.000Z</published>
    <updated>2019-05-13T15:29:23.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>兔玩是一个非常不错的妹子图网站，跟曾经的PR社有异曲同工之处，花少量的钱可以看Coser的图片，但是tuwan的妹子还是很正经的哟~<br>兔玩官网 <a href="https://www.tuwanjun.com/" target="_blank" rel="noopener">tuwanjun.com</a><br>以下是网站截图<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://i.loli.net/2019/05/13/5cd987f05d3b167053.jpg" alt="tuwan" title>                </div>                <div class="image-caption">tuwan</div>            </figure><br>兔玩的更新速度还是不错的呢~</p><h2 id="破解"><a href="#破解" class="headerlink" title="破解"></a>破解</h2><p>看到官网的套图打开后，一般是有几张可以看得图，也有一堆尺寸小的预览图，地址很相似，例如这张<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://img4.tuwandata.com/v3/thumb/jpg/YjAzYiwxNTgsMTU4LDksMywxLC0xLE5PTkUsLCw5MA==/u/GLDM9lMIBglnFv7YKftLBuvzpwYbEIoBh8ap84BsgXdniTdx80UqsXLdP5yaJZklUj09PvGO8IYpAC3nOanE0EHpB9bCnRKUnvdbAJH6CcXC.jpg</span><br></pre></td></tr></table></figure></p><p><font color="#FF0000">YjAzYiwxNTgsMTU4LDksMywxLC0xLE5PTkUsLCw5MA==</font>这一串很容易看的出是base64加密过的串，经过解密获得<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">base64.b64decode(imgurl)</span><br><span class="line"><span class="comment"># b03b,158,158,9,3,1,-1,NONE,,,90</span></span><br></pre></td></tr></table></figure></p><p>这里的158,158就是缩略图的尺寸了，我们尝试修改缩略图尺寸然后在base64加密后就可以取得地址，经过尝试，修改为 0，0即可还原原图尺寸~<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">base64.b64encode(base64.b64decode(imgurl.encode(<span class="string">'utf-8'</span>)).replace(<span class="string">'158'</span>,<span class="string">'0'</span>))</span><br><span class="line"><span class="comment"># YjAzYiwwLDAsOSwzLDEsLTEsTk9ORSwsLDkw</span></span><br></pre></td></tr></table></figure></p><p>组合成原图地址：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://img4.tuwandata.com/v3/thumb/jpg/YjAzYiwwLDAsOSwzLDEsLTEsTk9ORSwsLDkw/u/GLDM9lMIBglnFv7YKftLBuvzpwYbEIoBh8ap84BsgXdniTdx80UqsXLdP5yaJZklUj09PvGO8IYpAC3nOanE0EHpB9bCnRKUnvdbAJH6CcXC.jpg</span><br></pre></td></tr></table></figure></p><h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><p>源代码已经开源到Github上了<br>上一张测试图<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://i.loli.net/2019/05/13/5cd98d4c726e038815.jpeg" alt="测试图" title>                </div>                <div class="image-caption">测试图</div>            </figure></p><p>下载地址：<a href="https://github.com/ai0by/ai0by-spider/tree/master/tuwan" target="_blank" rel="noopener">tuwan_spider</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;兔玩是一个非常不错的妹子图网站，跟曾经的PR社有异曲同工之处，花少量的钱可以看Coser的图片，但是tuwan的妹子还是很正经的哟~&lt;br&gt;
      
    
    </summary>
    
      <category term="Python" scheme="https://sbcoder.cn/categories/Python/"/>
    
    
      <category term="Python" scheme="https://sbcoder.cn/tags/Python/"/>
    
      <category term="爬虫" scheme="https://sbcoder.cn/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="福利" scheme="https://sbcoder.cn/tags/%E7%A6%8F%E5%88%A9/"/>
    
  </entry>
  
  <entry>
    <title>Discuz会员数据与Wordpress互通</title>
    <link href="https://sbcoder.cn/2019/04/11/Discuz-Userinfo-To-Wordpress.html"/>
    <id>https://sbcoder.cn/2019/04/11/Discuz-Userinfo-To-Wordpress.html</id>
    <published>2019-04-11T12:06:06.000Z</published>
    <updated>2019-05-13T14:57:58.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="情景"><a href="#情景" class="headerlink" title="情景"></a>情景</h2><p>这个情景可能遇到的也不在少数，不想舍弃用户数据，还想让用户无需注册在新站保留账号。<br>实际当我们在迁移的时候，稍微了解数据库的同学应该明白想要迁移用户数据只需要迁移用户数据表即可。<br>实际上我也是这么做的，但是中途遇到了几个小问题，这里我总结一下！</p><h2 id="Discuz用户密码加密算法"><a href="#Discuz用户密码加密算法" class="headerlink" title="Discuz用户密码加密算法"></a>Discuz用户密码加密算法</h2><p>Discuz的用户信息都存放在 ‘<font color="#FF0000">pre_common_member</font>‘  表里，包含了我们需要转移的 邮箱,用户名,密码,积分,ip 等各类信息<br>那么很简单了，便利这个表再插入到Wordpress表内即可<br>但在导入表之前需要先测试一下用户数据是否匹配以示严谨~<br>当我测试密码匹配的时候发现，这里的密码似乎并不匹配，首先我想到的就是应该是加盐了，但是纵观整个 ‘<font color="#FF0000">pre_common_member</font>‘ 表，似乎并没有该有的字段<br>网上找了一圈发现Discuz的用户真实密码是存在 ‘<font color="#FF0000">pre_ucenter_members</font>‘ 表内的，’<font color="#FF0000">pre_common_member</font>‘ 表内的密码我现在还不知道有什么用处，但至少跟我们需要迁移的数据没什么关联。<br>从  ‘<font color="#FF0000">pre_ucenter_members</font>‘ 表中找到了我们需要的 ‘<font color="#FF0000">salt</font>‘ 字段，经过测试得出Discuz的密码加密算法为<br><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">md5(md5(<span class="string">'password'</span>).<span class="string">'salt'</span>);</span><br></pre></td></tr></table></figure></p><p>tips: Discuz里面的salt是一个6位的 数字+字母 随机数</p><h2 id="Wordpress用户密码加密算法"><a href="#Wordpress用户密码加密算法" class="headerlink" title="Wordpress用户密码加密算法"></a>Wordpress用户密码加密算法</h2><p>搞定了DZ的加密算法后，那么如何将DZ的用户信息插入到WP里面就很重要了，打开 Wordpress 的数据库找到 ‘<font color="#FF0000">wp-user</font>‘表，找到 ‘<font color="#FF0000">user_pass</font>‘ 字段，发现里面加密的内容似乎无迹可寻。<br>实际上，Wordpress的加密是使用了 phpass 类来加密的，由 phpass 加密的密码具有不可逆性，所以想要破解是不可能了，这里简单说一下 phpass 的加密算法<br>目前我们的PHP版本应该都在5以上，所以前缀是一样的 $P$B 大致写出来如下：<br><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$count = rand(<span class="number">1</span>,<span class="number">8</span>);</span><br><span class="line">$hash = md5($salt . $password, <span class="keyword">TRUE</span>);</span><br><span class="line"><span class="keyword">while</span>($count--)&#123;</span><br><span class="line">$hash = md5($hash . $password, <span class="keyword">TRUE</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>看起来是不是很强，我们无法破解这样的密码，实际使用中，我们也可以使用 phpass 来做密码加密，让我们的数据库更加的安全~<br>然而我们数据迁移时其实完全可以避免这种问题，Wordpress是保留了md5加密的形式的，如果 ‘<font color="#FF0000">user_pass</font>‘ 字段里面存储的是md5加密的32值，wordpress也可以登录成功，并且再登陆后会将 ‘<font color="#FF0000">user_pass</font>‘ 字段修改为 phpass 加密的格式，是不是很人性化呢。<br>综上所述，我们无需解出来wordpress的加密算法，我们也解不出来~</p><h2 id="开始迁移用户数据"><a href="#开始迁移用户数据" class="headerlink" title="开始迁移用户数据"></a>开始迁移用户数据</h2><p>关于迁移有很多细节，本来是打算写出来的，后来发现没什么技术含量，都是流水账，直接开源到github好了<br>需要的朋友请直接点击 <a href="https://github.com/ai0by/D2W" target="_blank" rel="noopener">D2W - Github</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;情景&quot;&gt;&lt;a href=&quot;#情景&quot; class=&quot;headerlink&quot; title=&quot;情景&quot;&gt;&lt;/a&gt;情景&lt;/h2&gt;&lt;p&gt;这个情景可能遇到的也不在少数，不想舍弃用户数据，还想让用户无需注册在新站保留账号。&lt;br&gt;实际当我们在迁移的时候，稍微了解数据库的同学应该明
      
    
    </summary>
    
      <category term="PHP" scheme="https://sbcoder.cn/categories/PHP/"/>
    
    
      <category term="Discuz" scheme="https://sbcoder.cn/tags/Discuz/"/>
    
      <category term="Wordpress" scheme="https://sbcoder.cn/tags/Wordpress/"/>
    
  </entry>
  
  <entry>
    <title>192TT(192tb)套图吧整站爬虫</title>
    <link href="https://sbcoder.cn/2019/03/28/192tt_Spider.html"/>
    <id>https://sbcoder.cn/2019/03/28/192tt_Spider.html</id>
    <published>2019-03-28T08:15:16.000Z</published>
    <updated>2019-03-29T06:33:44.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="观察目录结构"><a href="#观察目录结构" class="headerlink" title="观察目录结构"></a>观察目录结构</h2><p>目标网站：192tb.com<br>网站结构复杂，但也不是太复杂，总体来说都写在导航栏上面了，本以为是new分类下就是所有的文章了，后来发现不是，需要遍历整个导航分类，由于每个分类都有很庞大的资源，因此我决定写成配置文件的形式，建立config.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line">mt  = <span class="string">'https://www.192tb.com/listinfo-1-1.html'</span>                  <span class="comment"># 美图</span></span><br><span class="line">mt1 = <span class="string">'https://www.192tb.com/meitu/xingganmeinv/'</span>  <span class="comment"># 性感美女</span></span><br><span class="line">mt2 = <span class="string">'https://www.192tb.com/meitu/siwameitui/'</span>    <span class="comment"># 丝袜美腿</span></span><br><span class="line">mt3 = <span class="string">'https://www.192tb.com/meitu/weimeixiezhen/'</span> <span class="comment"># 唯美写真</span></span><br><span class="line">mt4 = <span class="string">'https://www.192tb.com/meitu/wangluomeinv/'</span>  <span class="comment"># 网络美女</span></span><br><span class="line">mt5 = <span class="string">'https://www.192tb.com/meitu/gaoqingmeinv/'</span>  <span class="comment"># 高清美女</span></span><br><span class="line">mt6 = <span class="string">'https://www.192tb.com/meitu/motemeinv/'</span>     <span class="comment"># 模特美女</span></span><br><span class="line">mt7 = <span class="string">'https://www.192tb.com/meitu/tiyumeinv/'</span>     <span class="comment"># 体育美女</span></span><br><span class="line">mt8 = <span class="string">'https://www.192tb.com/meitu/dongmanmeinv/'</span>  <span class="comment"># 动漫美女</span></span><br><span class="line">mt9 = <span class="string">'https://www.192tb.com/new/ugirlapp/'</span>        <span class="comment"># 爱尤物APP/尤果网</span></span><br><span class="line"></span><br><span class="line">gc  = <span class="string">'https://www.192tb.com/gc/'</span>                   <span class="comment"># 国产</span></span><br><span class="line">gc1 = <span class="string">'https://www.192tb.com/gc/bl/'</span> <span class="comment"># beautyleg1</span></span><br></pre></td></tr></table></figure><p>顶级分类和二级分类不便多说，这里只是测试并没有收录所有的分类，有兴趣可以自己添加</p><p>进入分类页后既是套图封面，从这里可以爬取套图的链接，分类页的底部也是有下一页的选项，可以根据下一页来获取下一个分类页的链接，以此递归，并获取链接</p><p>获取到套图链接后发现每个单页面都是需要点击下一张图片来做的，单页面中的图片，使用BeautifulSoup即可轻松获取，由于不知道一套图里面有多少张，我这边使用递归的方式，走到最后一张，即退出递归。</p><h2 id="核心代码"><a href="#核心代码" class="headerlink" title="核心代码"></a>核心代码</h2><h3 id="获取单个套图并下载"><a href="#获取单个套图并下载" class="headerlink" title="获取单个套图并下载"></a>获取单个套图并下载</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getSingleData</span><span class="params">(url,singleTitle,i = <span class="number">1</span>)</span>:</span></span><br><span class="line">    response = requests.get(url)</span><br><span class="line">    soup = BeautifulSoup(response.text,<span class="string">"html.parser"</span>)</span><br><span class="line">    imgUrl = soup.find(id = <span class="string">'p'</span>).find(<span class="string">'center'</span>).find(<span class="string">'img'</span>).get(<span class="string">'lazysrc'</span>)</span><br><span class="line">    <span class="keyword">print</span> imgUrl</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        j = i + <span class="number">1</span></span><br><span class="line">        result = <span class="string">'_%s.html'</span>%i <span class="keyword">in</span> url</span><br><span class="line">        <span class="keyword">if</span> result:</span><br><span class="line">            nextImg = response.url.replace(<span class="string">'_%s.html'</span>%i, <span class="string">'_%s.html'</span>%j)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            nextImg = response.url.replace(<span class="string">'.html'</span>, <span class="string">'_%s.html'</span>%j)</span><br><span class="line">        <span class="comment"># print nextImg</span></span><br><span class="line">        downImg(imgUrl,singleTitle,i)</span><br><span class="line">        getSingleData(nextImg,j)</span><br><span class="line">    <span class="keyword">except</span> Exception,e:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure><h3 id="获取下一页页面信息"><a href="#获取下一页页面信息" class="headerlink" title="获取下一页页面信息"></a>获取下一页页面信息</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getPage</span><span class="params">(url,new = <span class="number">1</span>,i = <span class="number">1</span>)</span>:</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">'开始采集第%s页'</span>%i</span><br><span class="line">    <span class="keyword">print</span> url</span><br><span class="line">    response = requests.get(url)</span><br><span class="line">    soup = BeautifulSoup(response.text,<span class="string">"html.parser"</span>)</span><br><span class="line">    <span class="keyword">for</span> dataUrl <span class="keyword">in</span> soup.find(<span class="string">'div'</span>,&#123;<span class="string">'class'</span>:<span class="string">'piclist'</span>&#125;).find(<span class="string">'ul'</span>).find_all(<span class="string">'li'</span>):</span><br><span class="line">        singleDataUrl = <span class="string">'https://www.192tb.com/'</span>+dataUrl.find(<span class="string">'a'</span>).get(<span class="string">'href'</span>)</span><br><span class="line">        <span class="keyword">print</span> singleDataUrl</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            singleTitle = dataUrl.find(<span class="string">'a'</span>).find(<span class="string">'img'</span>).get(<span class="string">'alt'</span>)</span><br><span class="line">        <span class="keyword">except</span> Exception,e:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">print</span> singleTitle</span><br><span class="line">        getSingleData(singleDataUrl,singleTitle)</span><br><span class="line">    result = <span class="string">'_%s.html'</span> % i <span class="keyword">in</span> url</span><br><span class="line">    j = i + <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> new != <span class="number">1</span>:</span><br><span class="line">        nextPageUrl = url.replace(<span class="string">'listinfo-1-%s.html'</span> % i, <span class="string">'listinfo-1-%s.html'</span> % j)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">if</span> result:</span><br><span class="line">            nextPageUrl = url.replace(<span class="string">'index_%s.html'</span> % i, <span class="string">'index_%s.html'</span> % j)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            nextPageUrl = url.replace(url, url+<span class="string">'/index_%s.html'</span> % j)</span><br><span class="line">    getPage(nextPageUrl,new,j)</span><br></pre></td></tr></table></figure><h2 id="演示及下载"><a href="#演示及下载" class="headerlink" title="演示及下载"></a>演示及下载</h2><p>下载地址：<a href="https://github.com/ai0by/ai0by-spider/tree/master/192tt" target="_blank" rel="noopener">Github</a></p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="http://fulicos.sbcoder.cn/2019/03/29/5c9dba3205190.png" alt="192tt演示图" title>                </div>                <div class="image-caption">192tt演示图</div>            </figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;观察目录结构&quot;&gt;&lt;a href=&quot;#观察目录结构&quot; class=&quot;headerlink&quot; title=&quot;观察目录结构&quot;&gt;&lt;/a&gt;观察目录结构&lt;/h2&gt;&lt;p&gt;目标网站：192tb.com&lt;br&gt;网站结构复杂，但也不是太复杂，总体来说都写在导航栏上面了，本以为是new
      
    
    </summary>
    
      <category term="Python" scheme="https://sbcoder.cn/categories/Python/"/>
    
    
      <category term="Python" scheme="https://sbcoder.cn/tags/Python/"/>
    
      <category term="爬虫" scheme="https://sbcoder.cn/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="福利" scheme="https://sbcoder.cn/tags/%E7%A6%8F%E5%88%A9/"/>
    
  </entry>
  
  <entry>
    <title>正则表达式应用，常用取值表（记录）</title>
    <link href="https://sbcoder.cn/2019/03/26/Regex_match_note.html"/>
    <id>https://sbcoder.cn/2019/03/26/Regex_match_note.html</id>
    <published>2019-03-26T08:11:06.000Z</published>
    <updated>2019-03-27T03:50:12.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="正则表达式-查询表"><a href="#正则表达式-查询表" class="headerlink" title="正则表达式 查询表"></a>正则表达式 查询表</h2><table><thead><tr><th>字符</th><th>描述</th><th>场景  </th></tr></thead><tbody><tr><td> \</td><td>转义</td><td>转义场景 \</td></tr><tr><td>^</td><td>匹配输入字符串的开始位置。如果设置了 RegExp 对象的 Multiline 属性，^ 也匹配 ‘\n’ 或 ‘\r’ 之后的位置。</td><td>取a开头的字符串 ^a.*</td></tr><tr><td>$</td><td>匹配输入字符串的结束位置。如果设置了RegExp 对象的 Multiline 属性，$ 也匹配 ‘\n’ 或 ‘\r’ 之前的位置。</td><td>取a开头b结尾 ^a.*b$</td></tr><tr><td>*</td><td>匹配前面的子表达式零次或多次。</td><td>zo<em> 能匹配 “z” 以及 “zoo”。</em> 等价于{0,}</td></tr><tr><td>+</td><td>匹配前面的子表达式一次或多次。</td><td>‘zo+’ 能匹配 “zo” 以及 “zoo”，但不能匹配 “z”。+ 等价于 {1,}</td></tr><tr><td>?</td><td>匹配前面的子表达式零次或一次.</td><td>“do(es)?” 可以匹配 “do” 或 “does” 中的”do” 。? 等价于 {0,1}。</td></tr><tr><td>{n}</td><td>n 是一个非负整数。匹配确定的 n 次。</td><td>‘o{2}’ 不能匹配 “Bob” 中的 ‘o’，但是能匹配 “food” 中的两个 o。</td></tr><tr><td>{n,}</td><td>n 是一个非负整数。至少匹配n 次。</td><td>‘o{2,}’ 不能匹配 “Bob” 中的 ‘o’，但能匹配 “foooood” 中的所有 o。’o{1,}’ 等价于 ‘o+’。’o{0,}’ 则等价于 ‘o*’</td></tr><tr><td>{n,m}</td><td>m 和 n 均为非负整数，其中n &lt;= m。最少匹配 n 次且最多匹配 m 次。</td><td>“o{1,3}” 将匹配 “fooooood” 中的前三个 o。’o{0,1}’ 等价于 ‘o?’。请注意在逗号和两个数之间不能有空格。</td></tr><tr><td>?</td><td>当 该字符紧跟在任何一个其他限制符 (*, +, ?, {n}, {n,}, {n,m}) 后面时，匹配模式是非贪婪的。</td><td>非贪婪模式尽可能少的匹配所搜索的字符串，而默认的贪婪模式则尽可能多的匹配所搜索的字符串。对于字符串 “oooo”，’o+?’ 将匹配单个 “o”，而 ‘o+’ 将匹配所有 ‘o’。</td></tr><tr><td>.</td><td>匹配除 “\n” 之外的任何单个字符。</td><td>要匹配包括 ‘\n’ 在内的任何字符，请使用象 ‘[.\n]’ 的模式。</td></tr><tr><td>x&#124;y</td><td>匹配 x 或 y。</td><td>‘z&#124;food’ 能匹配 “z” 或 “food”。’(z&#124;f)ood’ 则匹配 “zood” 或 “food”。</td></tr><tr><td>[xyz]</td><td>字符集合。匹配所包含的任意一个字符。</td><td>‘[abc]’可以匹配 “plain” 中的 ‘a’。</td></tr><tr><td>[^xyz]</td><td>取反，匹配未包含的任意字符。</td><td>‘?[^abc]’ 可以匹配 “plain” 中的’p’。</td></tr><tr><td>[a-z]</td><td>字符范围。匹配指定范围内的任意字符。</td><td>‘[a-z]’ 可以匹配 ‘a’ 到 ‘z’ 范围内的任意小写字母字符。</td></tr><tr><td>\b</td><td>匹配一个单词边界，也就是指单词和空格间的位置。</td><td>‘er\b’ 可以匹配”never” 中的 ‘er’，但不能匹配 “verb” 中的 ‘er’。</td></tr><tr><td>\B</td><td>匹配非单词边界</td><td>‘er\B’ 能匹配 “verb” 中的 ‘er’，但不能匹配 “never” 中的 ‘er’。</td></tr><tr><td>\cx</td><td>匹配由 x 指明的控制字符。</td><td>\cM 匹配一个 Control-M 或回车符。x 的值必须为 A-Z 或 a-z 之一。否则，将 c 视为一个原义的 ‘c’ 字符。</td></tr><tr><td>\d</td><td>匹配一个数字字符</td><td>等价于 [0-9]。</td></tr><tr><td>\D</td><td>匹配一个非数字字符。</td><td>等价于 [^0-9]。</td></tr><tr><td>\f</td><td>匹配一个换页符。</td><td>等价于 \x0c 和 \cL。</td></tr><tr><td>\n</td><td>匹配一个换行符。</td><td>等价于 \x0a 和 \cJ。</td></tr><tr><td>\r</td><td>匹配一个回车符。</td><td>等价于 \x0d 和 \cM。</td></tr><tr><td>\s</td><td>匹配任何空白字符，包括空格、制表符、换页符等等。</td><td>等价于 [ \f\n\r\t\v]。</td></tr><tr><td>\S</td><td>匹配任何非空白字符。</td><td>等价于 [^ \f\n\r\t\v]。</td></tr><tr><td>\t</td><td>匹配一个制表符。</td><td>等价于 \x09 和 \cI。</td></tr><tr><td>\v</td><td>匹配一个垂直制表符。</td><td>等价于 \x0b 和 \cK。</td></tr><tr><td>\w</td><td>匹配包括下划线的任何单词字符。</td><td>等价于’[A-Za-z0-9_]’。</td></tr><tr><td>\W</td><td>匹配任何非单词字符。</td><td>等价于 ‘[^A-Za-z0-9_]’。</td></tr><tr><td>\xn</td><td>匹配十六进制数</td><td>‘\x41’ 匹配 “A”。’\x041’ 则等价于 ‘\x04’ &amp; “1”。正则表达式中可以使用 ASCII 编码。.</td></tr><tr><td>\num</td><td>匹配 一个正整数。对所获取的匹配的引用。</td><td>‘(.)\1’ 匹配两个连续的相同字符。</td></tr><tr><td>\n</td><td>标识一个八进制转义值或一个向后引用。</td><td>如果 \n 之前至少 n 个获取的子表达式，则 n 为向后引用。否则，如果 n 为八进制数字 (0-7)，则 n 为一个八进制转义值。</td></tr><tr><td>\nm</td><td>标 识一个八进制转义值或一个向后引用。</td><td>如果 \nm 之前至少有 nm 个获得子表达式，则 nm 为向后引用。如果 \nm 之前至少有 n 个获取，则 n 为一个后跟文字 m 的向后引用。如果前面的条件都不满足，若 n 和 m 均为八进制数字 (0-7)，则 \nm 将匹配八进制转义值 nm。</td></tr><tr><td>\nml</td><td>匹配八进制数</td><td>如果 n 为八进制数字 (0-3)，且 m 和 l 均为八进制数字 (0-7)，则匹配八进制转义值 nml。</td></tr><tr><td>\un</td><td>匹配 n，其中 n 是一个用四个十六进制数字表示的 Unicode 字符。</td><td>\u00A9 匹配版权符号 。</td></tr></tbody></table><h2 id="常用案例演示"><a href="#常用案例演示" class="headerlink" title="常用案例演示"></a>常用案例演示</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line">str1 = <span class="string">'ai0by123'</span></span><br></pre></td></tr></table></figure><p>提取a开头的字符串<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">regexStr = <span class="string">"^a.*"</span></span><br></pre></td></tr></table></figure></p><p>提取a开头b结尾字符串<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">regexStr = <span class="string">"^a.*3$"</span></span><br></pre></td></tr></table></figure></p><p>提取最右边符合条件的值,贪婪<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">regexStr = <span class="string">".*(a.*b).*"</span>             <span class="comment"># 贪婪，取a到b之间，右边开始取，取最右边符合条件的</span></span><br></pre></td></tr></table></figure></p><p>提取最左边符合条件的值，非贪婪<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">regexStr = <span class="string">".*?(a.*?b).*"</span>           <span class="comment"># 非贪婪，取a到b之间的值含a和b，从左往右只取一次</span></span><br></pre></td></tr></table></figure></p><p>提取符合集合内的值，或运算<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">regexStr = <span class="string">"((ai00000by|ai0by)123)"</span> <span class="comment"># 或运算，符合其中一种即可</span></span><br></pre></td></tr></table></figure></p><p>提取出生日期<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">str1 = <span class="string">'XXX 出生于2008年12月6日'</span></span><br><span class="line">str1 = <span class="string">'XXX 出生于2008/12/6'</span></span><br><span class="line">str1 = <span class="string">'XXX 出生于2008-12-6'</span></span><br><span class="line">str1 = <span class="string">'XXX 出生于2008-12-06'</span></span><br><span class="line">str1 = <span class="string">'XXX 出生于2008-12'</span></span><br><span class="line">regexStr = <span class="string">".*出生于(\d&#123;4&#125;[年/-]\d&#123;1,2&#125;([月/-]\d&#123;1,2&#125;|[月/-]$|$))"</span></span><br></pre></td></tr></table></figure></p><p>提取图片url,其他网站同理<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">str1 = <span class="string">'地址：https://www.ttbcdn.com/d/file/p/2018-02-17/g4edlvxmmyi9627.jpg'</span></span><br><span class="line"><span class="comment"># 取整串地址</span></span><br><span class="line">regexStr = <span class="string">".*https.*jpg$"</span></span><br><span class="line"><span class="comment"># 取XXX.jpg png gif 等</span></span><br><span class="line">regexStr = <span class="string">".*/(.*.(jpg|gif|png))$"</span></span><br><span class="line"><span class="comment"># 取2018-02-17/g4edlvxmmyi9627.jpg png gif等</span></span><br><span class="line">regexStr = <span class="string">".*/(\d&#123;4&#125;-\d&#123;2&#125;-\d&#123;2&#125;/(.*.(jpg|gif|png)))$"</span></span><br></pre></td></tr></table></figure></p><h2 id="收尾提取字符串"><a href="#收尾提取字符串" class="headerlink" title="收尾提取字符串"></a>收尾提取字符串</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">reMatch = re.match(regexStr,str1)</span><br><span class="line"><span class="keyword">if</span> reMatch:</span><br><span class="line"><span class="keyword">print</span> (reMatch.group(<span class="number">1</span>))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">print(<span class="string">'No'</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;正则表达式-查询表&quot;&gt;&lt;a href=&quot;#正则表达式-查询表&quot; class=&quot;headerlink&quot; title=&quot;正则表达式 查询表&quot;&gt;&lt;/a&gt;正则表达式 查询表&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字符&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;

      
    
    </summary>
    
      <category term="note" scheme="https://sbcoder.cn/categories/note/"/>
    
    
      <category term="正则表达式" scheme="https://sbcoder.cn/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
    
      <category term="笔记" scheme="https://sbcoder.cn/tags/%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>博客迁移说明</title>
    <link href="https://sbcoder.cn/2019/03/25/Hello_world.html"/>
    <id>https://sbcoder.cn/2019/03/25/Hello_world.html</id>
    <published>2019-03-25T05:12:58.000Z</published>
    <updated>2019-04-12T14:57:49.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="关于迁移"><a href="#关于迁移" class="headerlink" title="关于迁移"></a>关于迁移</h2><p>博客总是在起起伏伏，关了又开，开了又关中反复，这一次，我将风向标博客放在了Github Page上。<br>程序采用了当下比较流行的静态博客程序 Hexo ，Hexo其实是一个非常好的程序，但由于我经常换电脑，以前用hexo搭建的博客数据丢失了很多次，后经过更换为Wordpress，Typecho之类的开源博客程序后，我又回到了 Hexo 的怀抱，可能是真的懒得折腾了，上了年纪？<br>这次我将源代码都备份好了，应该会长期更新，有什么好的东西我应该会分享出来，主打原创~<br>可能之前认识我的人也很少，但我这个域名还是很好记的，sb coder 也是一种自嘲吧，有想跟我交流技术或者有外包工作介绍给我的，我的微信与域名同号~<br>多的不说了，我将尽我所能，一周至少写一篇文章，可能有时候晚上回家写一点，一天写一点，一周下来也能写不少，希望各位监督~</p><h2 id="关于我"><a href="#关于我" class="headerlink" title="关于我"></a>关于我</h2><p>我是谁，职业是PHP，爱好Python，云服务器爱好者<br>支付接口对接，可以定制各类免签约支付接口，微信支付宝，有想法的朋友可以联系我 Telegram : ai0by</p><h2 id="承接业务"><a href="#承接业务" class="headerlink" title="承接业务"></a>承接业务</h2><p>支付相关业务，爬虫(几乎不要钱，练手)，PHP程序开发<br>服务器环境配置，PHP程序修改，PHP BUG排查</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;关于迁移&quot;&gt;&lt;a href=&quot;#关于迁移&quot; class=&quot;headerlink&quot; title=&quot;关于迁移&quot;&gt;&lt;/a&gt;关于迁移&lt;/h2&gt;&lt;p&gt;博客总是在起起伏伏，关了又开，开了又关中反复，这一次，我将风向标博客放在了Github Page上。&lt;br&gt;程序采用了当下比
      
    
    </summary>
    
    
      <category term="ai0by" scheme="https://sbcoder.cn/tags/ai0by/"/>
    
  </entry>
  
  <entry>
    <title>岛国推特妹子图爬虫</title>
    <link href="https://sbcoder.cn/2019/03/22/Japan_Twitter_Spider.html"/>
    <id>https://sbcoder.cn/2019/03/22/Japan_Twitter_Spider.html</id>
    <published>2019-03-22T03:54:58.000Z</published>
    <updated>2019-03-22T05:11:10.000Z</updated>
    
    <content type="html"><![CDATA[<p>LOC的大佬们分享了一个网站，收集了很多岛国的妹子图和她们的推特<br>地址：<a href="http://jigadori.fkoji.com" target="_blank" rel="noopener">岛国妹子推特</a><br>推特不是很感兴趣，就爬一下图片好了~</p><h2 id="爬虫介绍"><a href="#爬虫介绍" class="headerlink" title="爬虫介绍"></a>爬虫介绍</h2><h3 id="爬虫环境："><a href="#爬虫环境：" class="headerlink" title="爬虫环境："></a>爬虫环境：</h3><ul><li>Python2.7.9 可更替为3，自行更替</li><li>BeautifulSoup4</li><li>requests</li></ul><h3 id="代码："><a href="#代码：" class="headerlink" title="代码："></a>代码：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">spy</span><span class="params">(url)</span>:</span></span><br><span class="line">    req = urllib2.Request(url)</span><br><span class="line">    req = urllib2.urlopen(req)</span><br><span class="line">    page = req.read()</span><br><span class="line">    soup = BeautifulSoup(page, <span class="string">"html.parser"</span>)</span><br><span class="line">    <span class="keyword">for</span> imgSoup <span class="keyword">in</span> soup.find_all(<span class="string">'div'</span>, &#123;<span class="string">"class"</span>: <span class="string">"row"</span>&#125;):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> imgSoup.find_all(<span class="string">'div'</span>, &#123;<span class="string">'class'</span>: <span class="string">'photo'</span>&#125;):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> i.find(<span class="string">'div'</span>, &#123;<span class="string">'class'</span>: <span class="string">'photo-link-outer'</span>&#125;).find(<span class="string">'a'</span>).find_all(<span class="string">'img'</span>):</span><br><span class="line">                img = j.get(<span class="string">"src"</span>)</span><br><span class="line">                <span class="keyword">print</span> img</span><br><span class="line">                str = random.sample(<span class="string">'zyxwvutsrqponmlkjihgfedcba'</span>, <span class="number">6</span>)</span><br><span class="line">                downImg(img, str)</span><br><span class="line">    nexturl = soup.find(<span class="string">'p'</span>,&#123;<span class="string">'class'</span>:<span class="string">'go-to-next-page'</span>&#125;)</span><br><span class="line">    nexturl = nexturl.find(<span class="string">'a'</span>).get(<span class="string">'href'</span>)</span><br><span class="line">    pageurl = <span class="string">"http://jigadori.fkoji.com"</span>+nexturl</span><br><span class="line">    spy(pageurl)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">downImg</span><span class="params">(img,m)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(img)</span><br><span class="line">    <span class="keyword">except</span> Exception , e:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">"图片获取失败"</span></span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'./img/good%s.jpg'</span> % m, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(r.content)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    url = <span class="string">"http://jigadori.fkoji.com"</span></span><br><span class="line">    spy(url)</span><br></pre></td></tr></table></figure><h2 id="整体思路"><a href="#整体思路" class="headerlink" title="整体思路"></a>整体思路</h2><p>看一下，网页构造，发现首页底部有下一页标签，BeautifulSoup取Class取值递归获取下一页地址<br>图片同上<br>整体难度不高，有兴趣的可以拿这个网站练练手~</p><h2 id="演示截图"><a href="#演示截图" class="headerlink" title="演示截图"></a>演示截图</h2><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="http://fulicos.sbcoder.cn/2019/03/21/5c92e798d4689.png" alt="演示数据1" title>                </div>                <div class="image-caption">演示数据1</div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="http://fulicos.sbcoder.cn/2019/03/21/5c92e794e9827.png" alt="演示数据2" title>                </div>                <div class="image-caption">演示数据2</div>            </figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;LOC的大佬们分享了一个网站，收集了很多岛国的妹子图和她们的推特&lt;br&gt;地址：&lt;a href=&quot;http://jigadori.fkoji.com&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;岛国妹子推特&lt;/a&gt;&lt;br&gt;推特不是很感兴趣，就爬一下图片好了
      
    
    </summary>
    
      <category term="Python" scheme="https://sbcoder.cn/categories/Python/"/>
    
    
      <category term="Python" scheme="https://sbcoder.cn/tags/Python/"/>
    
      <category term="爬虫" scheme="https://sbcoder.cn/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="福利" scheme="https://sbcoder.cn/tags/%E7%A6%8F%E5%88%A9/"/>
    
  </entry>
  
  <entry>
    <title>Python+selenium针对网银控件过登录取数据</title>
    <link href="https://sbcoder.cn/2019/03/21/Python_WY_Spider.html"/>
    <id>https://sbcoder.cn/2019/03/21/Python_WY_Spider.html</id>
    <published>2019-03-21T08:53:30.000Z</published>
    <updated>2019-03-22T03:10:52.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Python获取WY数据的方法总结："><a href="#Python获取WY数据的方法总结：" class="headerlink" title="Python获取WY数据的方法总结："></a>Python获取WY数据的方法总结：</h2><ul><li>由于WY控件加密方式相比较一般网站比较特殊，需在驱动层进行操作</li><li>由于WY控件的特殊性，获取交易数据的时候需要传递KEY (以CCB为例)</li><li>由于取数据时的问题，所有操作均应该在驱动层完成</li><li>要想实现实时更新数据，需要不断地登录，大部分WY都有强制退出操作</li></ul><h2 id="理清思路"><a href="#理清思路" class="headerlink" title="理清思路"></a>理清思路</h2><p>登录的过程中，由于安全控件的限制，需要绕过登录限制，此处思路借鉴了 <a href="https://blog.csdn.net/Bone_ACE/article/details/80765299" target="_blank" rel="noopener">爬虫应对银行安全控件</a>，由此可知，需要绕过登陆限制需从驱动层入手</p><p>两种方案</p><ul><li>Python可以使用 Win32api 模块来模拟键盘指令，类似于按键精灵的概念</li><li>Python使用 Photomjs 无界面浏览器配合Selenium Webdirver</li></ul><p>尝试使用Win32api时，由于需要配合鼠标操作，需要获取句柄坐标，且开发难度较高，尝试更换另一种方式<br>更换 Photomjs ，模拟登录时发现 Photomjs 并没有附带安全控件，所传输的值不会自动加密，尝试更换为 ChromDriver<br>使用 ChromDriver 尝试模拟登陆</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">username = browser.find_element_by_name(<span class="string">'USERID'</span>)</span><br><span class="line">username.send_keys(username)</span><br><span class="line">password = browser.find_element_by_name(<span class="string">'LOGPASS'</span>)</span><br><span class="line">password.send_keys(password)</span><br><span class="line">tjButton = browser.find_element_by_id(<span class="string">'loginButton'</span>)</span><br><span class="line">tjButton.click()</span><br></pre></td></tr></table></figure><p>登录成功！</p><p>当越过了登录后就需要获取交易信息，交易信息这一块，CCB的查询地址附带了一个SKEY，每次查询信息的时候都需要一个SKEY验证，如果不正确将不会返回正确的结果！<br>如何获取SKEY，涉及到WY的信息，这里不便细说（PS：细心地同学一定可以找到）</p><p>取到SKEY后即可构造查询地址，然后使用WebDriver模拟访问<br>需要注意的一点是，WY的大部分数据均是用iframe嵌套的，因此需要多处过iframe</p><p>演示代码<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定位到iframe</span></span><br><span class="line">iframe = browser.find_element_by_id(<span class="string">"iframe"</span>)</span><br><span class="line"><span class="comment"># 切换到iframe</span></span><br><span class="line">browser.switch_to_frame(iframe)</span><br></pre></td></tr></table></figure></p><p>取数据这一块不多说，每个WY也都不同<br>获取到数据后就是数据处理了，根据系统不同，我这里直接使用Python向固定地址POST传值</p><p>取数据后为了获取实时数据，需要定时向固定地址提交数据，大部分的WY都有长时间自动登出的骚操作，对此，思路也很多</p><p>大致几个想法</p><ul><li>自动刷新，保持登录状态</li><li>重复登录，更换SKEY，反复操作</li><li>模拟点击，保持登录状态</li></ul><p>自动刷新方案在一开始就失败了，多次频繁的刷新，会导致弹出手机验证码<br>重复登录，由于上次的失败，设置了延时，效果还可以，只是数据总会有延迟<br>模拟点击，无效，仍然会自动登出</p><p>采用重复登录的方式，递归实现！</p><h2 id="综上所述，我们可以将交易流程如此划分："><a href="#综上所述，我们可以将交易流程如此划分：" class="headerlink" title="综上所述，我们可以将交易流程如此划分："></a>综上所述，我们可以将交易流程如此划分：</h2><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="http://fulicos.sbcoder.cn/2019/03/22/5c9438269d9c1.jpg" alt="WY数据.jpg" title>                </div>                <div class="image-caption">WY数据.jpg</div>            </figure><h2 id="成果演示"><a href="#成果演示" class="headerlink" title="成果演示"></a>成果演示</h2><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="http://fulicos.sbcoder.cn/2019/03/22/5c944f127c9cc.jpg" alt="WY演示.jpg" title>                </div>                <div class="image-caption">WY演示.jpg</div>            </figure><p>Tips:本文仅做思路分享，切勿用在实际生产环境！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Python获取WY数据的方法总结：&quot;&gt;&lt;a href=&quot;#Python获取WY数据的方法总结：&quot; class=&quot;headerlink&quot; title=&quot;Python获取WY数据的方法总结：&quot;&gt;&lt;/a&gt;Python获取WY数据的方法总结：&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;
      
    
    </summary>
    
      <category term="Python" scheme="https://sbcoder.cn/categories/Python/"/>
    
    
      <category term="Python" scheme="https://sbcoder.cn/tags/Python/"/>
    
      <category term="爬虫" scheme="https://sbcoder.cn/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="网银" scheme="https://sbcoder.cn/tags/%E7%BD%91%E9%93%B6/"/>
    
      <category term="selenium" scheme="https://sbcoder.cn/tags/selenium/"/>
    
  </entry>
  
</feed>
